<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Private · CTBenchmarks</title><meta name="title" content="Private · CTBenchmarks"/><meta property="og:title" content="Private · CTBenchmarks"/><meta property="twitter:title" content="Private · CTBenchmarks"/><meta name="description" content="Documentation for CTBenchmarks."/><meta property="og:description" content="Documentation for CTBenchmarks."/><meta property="twitter:description" content="Documentation for CTBenchmarks."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://control-toolbox.org/assets/css/documentation.css" rel="stylesheet" type="text/css"/><script src="https://control-toolbox.org/assets/js/documentation.js"></script><script src="../assets/js/ctbenchmarks-details.js"></script><link href="../assets/css/ctbenchmarks-details.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">CTBenchmarks</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Introduction</a></li><li><a class="tocitem" href="../performance_profile.html">Performance Profile</a></li><li><span class="tocitem">Core benchmarks</span><ul><li><a class="tocitem" href="../core/cpu.html">CPU</a></li><li><a class="tocitem" href="../core/gpu.html">GPU</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Problems</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../core/problems/beam.html">beam</a></li><li><a class="tocitem" href="../core/problems/chain.html">chain</a></li><li><a class="tocitem" href="../core/problems/double_oscillator.html">double_oscillator</a></li><li><a class="tocitem" href="../core/problems/electric_vehicle.html">electric_vehicle</a></li><li><a class="tocitem" href="../core/problems/glider.html">glider</a></li><li><a class="tocitem" href="../core/problems/insurance.html">insurance</a></li><li><a class="tocitem" href="../core/problems/jackson.html">jackson</a></li><li><a class="tocitem" href="../core/problems/robbins.html">robbins</a></li><li><a class="tocitem" href="../core/problems/robot.html">robot</a></li><li><a class="tocitem" href="../core/problems/rocket.html">rocket</a></li><li><a class="tocitem" href="../core/problems/space_shuttle.html">space_shuttle</a></li><li><a class="tocitem" href="../core/problems/steering.html">steering</a></li><li><a class="tocitem" href="../core/problems/vanderpol.html">vanderpol</a></li></ul></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="public.html">Public</a></li><li class="is-active"><a class="tocitem" href="private.html">Private</a><ul class="internal"><li><a class="tocitem" href="#ComboPerformance"><span><code>ComboPerformance</code></span></a></li><li><a class="tocitem" href="#ITERATION"><span><code>ITERATION</code></span></a></li><li><a class="tocitem" href="#PerformanceProfile"><span><code>PerformanceProfile</code></span></a></li><li><a class="tocitem" href="#PerformanceProfileConfig"><span><code>PerformanceProfileConfig</code></span></a></li><li><a class="tocitem" href="#PerformanceProfilePlotConfig"><span><code>PerformanceProfilePlotConfig</code></span></a></li><li><a class="tocitem" href="#PerformanceProfileRegistry"><span><code>PerformanceProfileRegistry</code></span></a></li><li><a class="tocitem" href="#ProfileAnalysis"><span><code>ProfileAnalysis</code></span></a></li><li><a class="tocitem" href="#ProfileCriterion"><span><code>ProfileCriterion</code></span></a></li><li><a class="tocitem" href="#ProfileStats"><span><code>ProfileStats</code></span></a></li><li><a class="tocitem" href="#_add_combo_series!"><span><code>_add_combo_series!</code></span></a></li><li><a class="tocitem" href="#_add_reference_lines!"><span><code>_add_reference_lines!</code></span></a></li><li><a class="tocitem" href="#_aggregate_metrics"><span><code>_aggregate_metrics</code></span></a></li><li><a class="tocitem" href="#_compute_curve_points"><span><code>_compute_curve_points</code></span></a></li><li><a class="tocitem" href="#_compute_dolan_more_ratios"><span><code>_compute_dolan_more_ratios</code></span></a></li><li><a class="tocitem" href="#_compute_profile_metadata"><span><code>_compute_profile_metadata</code></span></a></li><li><a class="tocitem" href="#_extract_benchmark_metrics"><span><code>_extract_benchmark_metrics</code></span></a></li><li><a class="tocitem" href="#_filter_benchmark_data"><span><code>_filter_benchmark_data</code></span></a></li><li><a class="tocitem" href="#_format_analysis_markdown"><span><code>_format_analysis_markdown</code></span></a></li><li><a class="tocitem" href="#_init_profile_plot"><span><code>_init_profile_plot</code></span></a></li><li><a class="tocitem" href="#_marker_indices_for_curve"><span><code>_marker_indices_for_curve</code></span></a></li><li><a class="tocitem" href="#_nearest_index"><span><code>_nearest_index</code></span></a></li><li><a class="tocitem" href="#_plot_font_settings"><span><code>_plot_font_settings</code></span></a></li><li><a class="tocitem" href="#_validate_benchmark_df"><span><code>_validate_benchmark_df</code></span></a></li><li><a class="tocitem" href="#benchmark_data"><span><code>benchmark_data</code></span></a></li><li><a class="tocitem" href="#build_payload"><span><code>build_payload</code></span></a></li><li><a class="tocitem" href="#compute_profile_stats"><span><code>compute_profile_stats</code></span></a></li><li><a class="tocitem" href="#costate_multiplier"><span><code>costate_multiplier</code></span></a></li><li><a class="tocitem" href="#create_jump_layout"><span><code>create_jump_layout</code></span></a></li><li><a class="tocitem" href="#default_plot_config"><span><code>default_plot_config</code></span></a></li><li><a class="tocitem" href="#filter_models_for_backend"><span><code>filter_models_for_backend</code></span></a></li><li><a class="tocitem" href="#format_solution_label"><span><code>format_solution_label</code></span></a></li><li><a class="tocitem" href="#generate_metadata"><span><code>generate_metadata</code></span></a></li><li><a class="tocitem" href="#get_color"><span><code>get_color</code></span></a></li><li><a class="tocitem" href="#get_config"><span><code>get_config</code></span></a></li><li><a class="tocitem" href="#get_dimensions"><span><code>get_dimensions</code></span></a></li><li><a class="tocitem" href="#get_left_margin"><span><code>get_left_margin</code></span></a></li><li><a class="tocitem" href="#get_marker_indices"><span><code>get_marker_indices</code></span></a></li><li><a class="tocitem" href="#get_marker_style"><span><code>get_marker_style</code></span></a></li><li><a class="tocitem" href="#get_solution_dimensions"><span><code>get_solution_dimensions</code></span></a></li><li><a class="tocitem" href="#is_cuda_on"><span><code>is_cuda_on</code></span></a></li><li><a class="tocitem" href="#list_profiles"><span><code>list_profiles</code></span></a></li><li><a class="tocitem" href="#plot_jump_group"><span><code>plot_jump_group</code></span></a></li><li><a class="tocitem" href="#plot_jump_solution"><span><code>plot_jump_solution</code></span></a></li><li><a class="tocitem" href="#plot_jump_solution!"><span><code>plot_jump_solution!</code></span></a></li><li><a class="tocitem" href="#plot_ocp_group"><span><code>plot_ocp_group</code></span></a></li><li><a class="tocitem" href="#plot_ocp_solution"><span><code>plot_ocp_solution</code></span></a></li><li><a class="tocitem" href="#plot_ocp_solution!"><span><code>plot_ocp_solution!</code></span></a></li><li><a class="tocitem" href="#plot_solution_comparison"><span><code>plot_solution_comparison</code></span></a></li><li><a class="tocitem" href="#prettymemory"><span><code>prettymemory</code></span></a></li><li><a class="tocitem" href="#prettytime"><span><code>prettytime</code></span></a></li><li><a class="tocitem" href="#print_benchmark_line"><span><code>print_benchmark_line</code></span></a></li><li><a class="tocitem" href="#register!"><span><code>register!</code></span></a></li><li><a class="tocitem" href="#save_json"><span><code>save_json</code></span></a></li><li><a class="tocitem" href="#set_print_level"><span><code>set_print_level</code></span></a></li><li><a class="tocitem" href="#solve_and_extract_data"><span><code>solve_and_extract_data</code></span></a></li><li><a class="tocitem" href="#strip_benchmark_value"><span><code>strip_benchmark_value</code></span></a></li></ul></li></ul></li><li><span class="tocitem">Developers Guidelines</span><ul><li><a class="tocitem" href="../add_benchmark.html">Add a New Benchmark</a></li><li><a class="tocitem" href="../documentation_process.html">Documentation Process</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href="private.html">Private</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="private.html">Private</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/control-toolbox/CTBenchmarks.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Private-API"><a class="docs-heading-anchor" href="#Private-API">Private API</a><a id="Private-API-1"></a><a class="docs-heading-anchor-permalink" href="#Private-API" title="Permalink"></a></h1><p>This page lists the <strong>non-exported</strong> (internal) symbols of <code>CTBenchmarks</code>.</p><p>Access these symbols with:</p><pre><code class="language-julia hljs">import CTBenchmarks
CTBenchmarks.&lt;NAME&gt;</code></pre><h2 id="ComboPerformance"><a class="docs-heading-anchor" href="#ComboPerformance"><code>ComboPerformance</code></a><a id="ComboPerformance-1"></a><a class="docs-heading-anchor-permalink" href="#ComboPerformance" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.ComboPerformance"><a class="docstring-binding" href="#CTBenchmarks.ComboPerformance"><code>CTBenchmarks.ComboPerformance</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ComboPerformance</code></pre><p>Performance metrics for a single solver combination.</p><p><strong>Fields</strong></p><ul><li><code>combo::String</code>: Solver combination label (e.g., &quot;(exa, ipopt)&quot;)</li><li><code>robustness::Float64</code>: Percentage of instances solved (0-100)</li><li><code>efficiency::Float64</code>: Percentage of instances where this combo was fastest (0-100)</li></ul></div></section></details></article><h2 id="ITERATION"><a class="docs-heading-anchor" href="#ITERATION"><code>ITERATION</code></a><a id="ITERATION-1"></a><a class="docs-heading-anchor-permalink" href="#ITERATION" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.ITERATION"><a class="docstring-binding" href="#CTBenchmarks.ITERATION"><code>CTBenchmarks.ITERATION</code></a> — <span class="docstring-category">Constant</span></summary><section><div><pre><code class="language-julia hljs">ITERATION::Base.RefValue{Int}</code></pre><p>Internal counter used to track how many times the JuMP solve loop has been executed, in order to adjust the solver print level after the first iteration.</p></div></section></details></article><h2 id="PerformanceProfile"><a class="docs-heading-anchor" href="#PerformanceProfile"><code>PerformanceProfile</code></a><a id="PerformanceProfile-1"></a><a class="docs-heading-anchor-permalink" href="#PerformanceProfile" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.PerformanceProfile"><a class="docstring-binding" href="#CTBenchmarks.PerformanceProfile"><code>CTBenchmarks.PerformanceProfile</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PerformanceProfile{M}</code></pre><p>Immutable structure containing all data needed to plot and analyze a performance profile, together with the configuration that was used to build it.</p><p><strong>Type parameter</strong></p><ul><li><code>M</code>: Metric type used in the underlying profile (e.g., <code>Float64</code> for CPU time).</li></ul><p><strong>Fields</strong></p><ul><li><code>bench_id::String</code>: Benchmark identifier</li><li><code>df_instances::DataFrame</code>: All (problem, grid_size) instances attempted</li><li><code>df_successful::DataFrame</code>: Successful runs with aggregated metric and ratios</li><li><code>combos::Vector{String}</code>: List of solver labels (typically &quot;(model, solver)&quot;)</li><li><code>total_problems::Int</code>: Total number of instances (N in Dolan–Moré)</li><li><code>min_ratio::Float64</code>: Minimum performance ratio across all combos</li><li><code>max_ratio::Float64</code>: Maximum performance ratio across all combos</li><li><code>config::PerformanceProfileConfig{M}</code>: Configuration used to construct this profile</li></ul></div></section></details></article><h2 id="PerformanceProfileConfig"><a class="docs-heading-anchor" href="#PerformanceProfileConfig"><code>PerformanceProfileConfig</code></a><a id="PerformanceProfileConfig-1"></a><a class="docs-heading-anchor-permalink" href="#PerformanceProfileConfig" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.PerformanceProfileConfig"><a class="docstring-binding" href="#CTBenchmarks.PerformanceProfileConfig"><code>CTBenchmarks.PerformanceProfileConfig</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PerformanceProfileConfig{M}</code></pre><p>Configuration describing how to build a performance profile from a benchmark results table.</p><p><strong>Fields</strong></p><ul><li><code>instance_cols::Vector{Symbol}</code>: Columns defining an instance (e.g., <code>[:problem, :grid_size]</code>).</li><li><code>solver_cols::Vector{Symbol}</code>: Columns defining a solver/model (e.g., <code>[:model, :solver]</code>).</li><li><code>criterion::ProfileCriterion{M}</code>: Metric extraction and comparison rule.</li><li><code>is_success::Function</code>: <code>row::DataFrameRow -&gt; Bool</code>, selects successful runs.</li><li><code>row_filter::Function</code>: <code>row::DataFrameRow -&gt; Bool</code>, additional filtering.</li><li><code>aggregate::Function</code>: Aggregation <code>xs::AbstractVector{M} -&gt; M</code> when multiple runs exist for the same instance/solver.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">config = PerformanceProfileConfig{Float64}(
    [:problem, :grid_size],
    [:model, :solver],
    cpu_criterion,
    row -&gt; row.success == true &amp;&amp; row.benchmark !== nothing,
    row -&gt; true,
    xs -&gt; mean(skipmissing(xs))
)</code></pre></div></section></details></article><h2 id="PerformanceProfilePlotConfig"><a class="docs-heading-anchor" href="#PerformanceProfilePlotConfig"><code>PerformanceProfilePlotConfig</code></a><a id="PerformanceProfilePlotConfig-1"></a><a class="docs-heading-anchor-permalink" href="#PerformanceProfilePlotConfig" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.PerformanceProfilePlotConfig"><a class="docstring-binding" href="#CTBenchmarks.PerformanceProfilePlotConfig"><code>CTBenchmarks.PerformanceProfilePlotConfig</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PerformanceProfilePlotConfig</code></pre><p>Configuration for performance profile plot styling.</p><p><strong>Fields</strong></p><ul><li><code>size::Tuple{Int,Int}</code>: Plot size (width, height)</li><li><code>xlabel::String</code>: X-axis label</li><li><code>ylabel::String</code>: Y-axis label</li><li><code>title_font::Plots.Font</code>: Font settings for the title</li><li><code>label_font::Plots.Font</code>: Font settings for labels</li><li><code>linewidth::Float64</code>: Width of the profile lines</li><li><code>markersize::Int</code>: Size of the markers</li><li><code>framestyle::Symbol</code>: Plot frame style</li><li><code>legend_position::Symbol</code>: Legend position</li></ul></div></section></details></article><h2 id="PerformanceProfileRegistry"><a class="docs-heading-anchor" href="#PerformanceProfileRegistry"><code>PerformanceProfileRegistry</code></a><a id="PerformanceProfileRegistry-1"></a><a class="docs-heading-anchor-permalink" href="#PerformanceProfileRegistry" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.PerformanceProfileRegistry"><a class="docstring-binding" href="#CTBenchmarks.PerformanceProfileRegistry"><code>CTBenchmarks.PerformanceProfileRegistry</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PerformanceProfileRegistry</code></pre><p>A container for named performance profile configurations.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">registry = PerformanceProfileRegistry()
register!(registry, &quot;default_cpu&quot;, cpu_config)
config = get_config(registry, &quot;default_cpu&quot;)</code></pre></div></section></details></article><h2 id="ProfileAnalysis"><a class="docs-heading-anchor" href="#ProfileAnalysis"><code>ProfileAnalysis</code></a><a id="ProfileAnalysis-1"></a><a class="docs-heading-anchor-permalink" href="#ProfileAnalysis" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.ProfileAnalysis"><a class="docstring-binding" href="#CTBenchmarks.ProfileAnalysis"><code>CTBenchmarks.ProfileAnalysis</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ProfileAnalysis</code></pre><p>Complete analysis results for a performance profile.</p><p><strong>Fields</strong></p><ul><li><code>bench_id::String</code>: Benchmark identifier</li><li><code>stats::ProfileStats</code>: Statistical summary</li><li><code>performances::Vector{ComboPerformance}</code>: Performance metrics for each combo</li><li><code>most_robust::Vector{String}</code>: Combo(s) with highest robustness</li><li><code>most_efficient::Vector{String}</code>: Combo(s) with highest efficiency</li></ul></div></section></details></article><h2 id="ProfileCriterion"><a class="docs-heading-anchor" href="#ProfileCriterion"><code>ProfileCriterion</code></a><a id="ProfileCriterion-1"></a><a class="docs-heading-anchor-permalink" href="#ProfileCriterion" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.ProfileCriterion"><a class="docstring-binding" href="#CTBenchmarks.ProfileCriterion"><code>CTBenchmarks.ProfileCriterion</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ProfileCriterion{M}</code></pre><p>Criterion used to extract and compare a scalar metric from benchmark runs.</p><p><strong>Fields</strong></p><ul><li><code>name::String</code>: Human-readable name of the criterion (e.g., &quot;CPU time (s)&quot;).</li><li><code>value::Function</code>: Function <code>row::DataFrameRow -&gt; M</code> extracting the metric.</li><li><code>better::Function</code>: Function <code>(a::M, b::M) -&gt; Bool</code> returning <code>true</code> if <code>a</code> is strictly better than <code>b</code> according to the criterion.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">cpu_criterion = ProfileCriterion{Float64}(
    &quot;CPU time (s)&quot;,
    row -&gt; get(row.benchmark, &quot;time&quot;, NaN),
    (a, b) -&gt; a &lt;= b
)</code></pre></div></section></details></article><h2 id="ProfileStats"><a class="docs-heading-anchor" href="#ProfileStats"><code>ProfileStats</code></a><a id="ProfileStats-1"></a><a class="docs-heading-anchor-permalink" href="#ProfileStats" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.ProfileStats"><a class="docstring-binding" href="#CTBenchmarks.ProfileStats"><code>CTBenchmarks.ProfileStats</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ProfileStats</code></pre><p>Statistical summary of a performance profile dataset.</p><p><strong>Fields</strong></p><ul><li><code>n_problems::Int</code>: Number of unique problems</li><li><code>n_instances::Int</code>: Total number of instances (problem × grid_size combinations)</li><li><code>n_combos::Int</code>: Number of solver combinations</li><li><code>n_successful_runs::Int</code>: Number of successful runs across all combos</li><li><code>n_successful_instances::Int</code>: Number of instances with at least one successful run</li><li><code>unsuccessful_instances::Vector{Tuple}</code>: List of instances that failed for all combos</li><li><code>instance_cols::Vector{Symbol}</code>: Instance column names</li><li><code>solver_cols::Vector{Symbol}</code>: Solver column names</li><li><code>criterion_name::String</code>: Name of the performance criterion</li></ul></div></section></details></article><h2 id="_add_combo_series!"><a class="docs-heading-anchor" href="#_add_combo_series!"><code>_add_combo_series!</code></a><a id="_add_combo_series!-1"></a><a class="docs-heading-anchor-permalink" href="#_add_combo_series!" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._add_combo_series!"><a class="docstring-binding" href="#CTBenchmarks._add_combo_series!"><code>CTBenchmarks._add_combo_series!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_add_combo_series!(plt, x, y, label, color, marker, cfg)</code></pre><p>Add a single solver combination series (line + markers) to the plot.</p></div></section></details></article><h2 id="_add_reference_lines!"><a class="docs-heading-anchor" href="#_add_reference_lines!"><code>_add_reference_lines!</code></a><a id="_add_reference_lines!-1"></a><a class="docs-heading-anchor-permalink" href="#_add_reference_lines!" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._add_reference_lines!"><a class="docstring-binding" href="#CTBenchmarks._add_reference_lines!"><code>CTBenchmarks._add_reference_lines!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_add_reference_lines!(plt)</code></pre><p>Add reference lines at y=0, y=1 and x=1.</p></div></section></details></article><h2 id="_aggregate_metrics"><a class="docs-heading-anchor" href="#_aggregate_metrics"><code>_aggregate_metrics</code></a><a id="_aggregate_metrics-1"></a><a class="docs-heading-anchor-permalink" href="#_aggregate_metrics" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._aggregate_metrics"><a class="docstring-binding" href="#CTBenchmarks._aggregate_metrics"><code>CTBenchmarks._aggregate_metrics</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_aggregate_metrics(df, cfg) -&gt; DataFrame</code></pre><p>Aggregate metrics when multiple runs exist for the same instance/solver combination.</p></div></section></details></article><h2 id="_compute_curve_points"><a class="docs-heading-anchor" href="#_compute_curve_points"><code>_compute_curve_points</code></a><a id="_compute_curve_points-1"></a><a class="docs-heading-anchor-permalink" href="#_compute_curve_points" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._compute_curve_points"><a class="docstring-binding" href="#CTBenchmarks._compute_curve_points"><code>CTBenchmarks._compute_curve_points</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_compute_curve_points(ratios, total_problems) -&gt; (Vector{Float64}, Vector{Float64})</code></pre><p>Compute the step function (x, y) points for the performance profile.</p></div></section></details></article><h2 id="_compute_dolan_more_ratios"><a class="docs-heading-anchor" href="#_compute_dolan_more_ratios"><code>_compute_dolan_more_ratios</code></a><a id="_compute_dolan_more_ratios-1"></a><a class="docs-heading-anchor-permalink" href="#_compute_dolan_more_ratios" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._compute_dolan_more_ratios"><a class="docstring-binding" href="#CTBenchmarks._compute_dolan_more_ratios"><code>CTBenchmarks._compute_dolan_more_ratios</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_compute_dolan_more_ratios(df, cfg) -&gt; DataFrame</code></pre><p>Compute Dolan-Moré performance ratios (metric / best_metric).</p></div></section></details></article><h2 id="_compute_profile_metadata"><a class="docs-heading-anchor" href="#_compute_profile_metadata"><code>_compute_profile_metadata</code></a><a id="_compute_profile_metadata-1"></a><a class="docs-heading-anchor-permalink" href="#_compute_profile_metadata" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._compute_profile_metadata"><a class="docstring-binding" href="#CTBenchmarks._compute_profile_metadata"><code>CTBenchmarks._compute_profile_metadata</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_compute_profile_metadata(df, cfg) -&gt; (Vector{String}, Float64, Float64)</code></pre><p>Generate solver combination labels and compute min/max ratio bounds.</p></div></section></details></article><h2 id="_extract_benchmark_metrics"><a class="docs-heading-anchor" href="#_extract_benchmark_metrics"><code>_extract_benchmark_metrics</code></a><a id="_extract_benchmark_metrics-1"></a><a class="docs-heading-anchor-permalink" href="#_extract_benchmark_metrics" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._extract_benchmark_metrics"><a class="docstring-binding" href="#CTBenchmarks._extract_benchmark_metrics"><code>CTBenchmarks._extract_benchmark_metrics</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_extract_benchmark_metrics(df, cfg) -&gt; DataFrame</code></pre><p>Extract the performance metric from each row using the criterion function.</p></div></section></details></article><h2 id="_filter_benchmark_data"><a class="docs-heading-anchor" href="#_filter_benchmark_data"><code>_filter_benchmark_data</code></a><a id="_filter_benchmark_data-1"></a><a class="docs-heading-anchor-permalink" href="#_filter_benchmark_data" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._filter_benchmark_data"><a class="docstring-binding" href="#CTBenchmarks._filter_benchmark_data"><code>CTBenchmarks._filter_benchmark_data</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_filter_benchmark_data(df, cfg, allowed_combos) -&gt; DataFrame</code></pre><p>Filter benchmark rows based on configuration criteria and allowed combinations.</p></div></section></details></article><h2 id="_format_analysis_markdown"><a class="docs-heading-anchor" href="#_format_analysis_markdown"><code>_format_analysis_markdown</code></a><a id="_format_analysis_markdown-1"></a><a class="docs-heading-anchor-permalink" href="#_format_analysis_markdown" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._format_analysis_markdown"><a class="docstring-binding" href="#CTBenchmarks._format_analysis_markdown"><code>CTBenchmarks._format_analysis_markdown</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_format_analysis_markdown(analysis::ProfileAnalysis) -&gt; String</code></pre><p>Format a ProfileAnalysis as a Markdown string. (Internal helper)</p><p><strong>Arguments</strong></p><ul><li><code>analysis::ProfileAnalysis</code>: Structured analysis results</li></ul><p><strong>Returns</strong></p><ul><li><code>String</code>: Markdown-formatted analysis report</li></ul></div></section></details></article><h2 id="_init_profile_plot"><a class="docs-heading-anchor" href="#_init_profile_plot"><code>_init_profile_plot</code></a><a id="_init_profile_plot-1"></a><a class="docs-heading-anchor-permalink" href="#_init_profile_plot" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._init_profile_plot"><a class="docstring-binding" href="#CTBenchmarks._init_profile_plot"><code>CTBenchmarks._init_profile_plot</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_init_profile_plot(pp, cfg) -&gt; Plots.Plot</code></pre><p>Initialize the plot canvas with axes configuration.</p></div></section></details></article><h2 id="_marker_indices_for_curve"><a class="docs-heading-anchor" href="#_marker_indices_for_curve"><code>_marker_indices_for_curve</code></a><a id="_marker_indices_for_curve-1"></a><a class="docs-heading-anchor-permalink" href="#_marker_indices_for_curve" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._marker_indices_for_curve"><a class="docstring-binding" href="#CTBenchmarks._marker_indices_for_curve"><code>CTBenchmarks._marker_indices_for_curve</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_marker_indices_for_curve(ratios; M = 6)</code></pre><p>Compute marker positions for a performance profile curve.</p><p>Places M markers uniformly in log2 space between the first and last ratio, then snaps to the nearest available grid points.</p></div></section></details></article><h2 id="_nearest_index"><a class="docs-heading-anchor" href="#_nearest_index"><code>_nearest_index</code></a><a id="_nearest_index-1"></a><a class="docs-heading-anchor-permalink" href="#_nearest_index" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._nearest_index"><a class="docstring-binding" href="#CTBenchmarks._nearest_index"><code>CTBenchmarks._nearest_index</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_nearest_index(xs, x)</code></pre><p>Find the index of the element in <code>xs</code> closest to <code>x</code>.</p></div></section></details></article><h2 id="_plot_font_settings"><a class="docs-heading-anchor" href="#_plot_font_settings"><code>_plot_font_settings</code></a><a id="_plot_font_settings-1"></a><a class="docs-heading-anchor-permalink" href="#_plot_font_settings" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._plot_font_settings"><a class="docstring-binding" href="#CTBenchmarks._plot_font_settings"><code>CTBenchmarks._plot_font_settings</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_plot_font_settings()</code></pre><p>Return font settings for plot titles and axis labels.</p><p><strong>Returns</strong></p><ul><li><code>Tuple{Plots.Font, Plots.Font}</code>: tuple <code>(title_font, label_font)</code>.</li></ul></div></section></details></article><h2 id="_validate_benchmark_df"><a class="docs-heading-anchor" href="#_validate_benchmark_df"><code>_validate_benchmark_df</code></a><a id="_validate_benchmark_df-1"></a><a class="docs-heading-anchor-permalink" href="#_validate_benchmark_df" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks._validate_benchmark_df"><a class="docstring-binding" href="#CTBenchmarks._validate_benchmark_df"><code>CTBenchmarks._validate_benchmark_df</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">_validate_benchmark_df(df::DataFrame, cfg::PerformanceProfileConfig)</code></pre><p>Check that the benchmark DataFrame contains all required columns. (Internal helper)</p></div></section></details></article><h2 id="benchmark_data"><a class="docs-heading-anchor" href="#benchmark_data"><code>benchmark_data</code></a><a id="benchmark_data-1"></a><a class="docs-heading-anchor-permalink" href="#benchmark_data" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.benchmark_data"><a class="docstring-binding" href="#CTBenchmarks.benchmark_data"><code>CTBenchmarks.benchmark_data</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">benchmark_data(
;
    problems,
    solver_models,
    grid_sizes,
    disc_methods,
    tol,
    ipopt_mu_strategy,
    print_trace,
    max_iter,
    max_wall_time
)
</code></pre><p>Run benchmarks on optimal control problems and return results as a DataFrame.</p><p>For each combination of problem, solver, model, and grid size, this function:</p><ol><li>Sets up and solves the optimization problem</li><li>Captures timing and memory statistics using <code>@btimed</code> or <code>CUDA.@timed</code></li><li>Extracts solver statistics (objective value, iterations)</li><li>Stores all data in a DataFrame row</li></ol><p><strong>Arguments</strong></p><ul><li><code>problems</code>: Vector of problem names (Symbols)</li><li><code>solver_models</code>: Vector of Pairs mapping solver =&gt; models (e.g., [:ipopt =&gt; [:jump, :adnlp], :madnlp =&gt; [:exa, :exa_gpu]])</li><li><code>grid_sizes</code>: Vector of grid sizes (Int)</li><li><code>disc_methods</code>: Vector of discretization methods (Symbols)</li><li><code>tol</code>: Solver tolerance (Float64)</li><li><code>ipopt_mu_strategy</code>: Mu strategy for Ipopt (String)</li><li><code>print_trace</code>: Boolean - whether to print solver output (for debugging)</li><li><code>max_iter</code>: Maximum number of iterations (Int)</li><li><code>max_wall_time</code>: Maximum wall time in seconds (Float64)</li></ul><p><strong>Returns</strong></p><p>A DataFrame with columns:</p><ul><li><code>problem</code>: Symbol - problem name</li><li><code>solver</code>: Symbol - solver used (:ipopt or :madnlp)</li><li><code>model</code>: Symbol - model type (:jump, :adnlp, :exa, or :exa_gpu)</li><li><code>disc_method</code>: Symbol - discretization method</li><li><code>grid_size</code>: Int - number of grid points</li><li><code>tol</code>: Float64 - solver tolerance</li><li><code>mu_strategy</code>: Union{String, Missing} - mu strategy for Ipopt (missing for MadNLP)</li><li><code>max_iter</code>: Int - maximum number of iterations</li><li><code>max_wall_time</code>: Float64 - maximum wall time in seconds</li><li><code>benchmark</code>: NamedTuple - full benchmark object from @btimed or CUDA.@timed</li><li><code>objective</code>: Union{Float64, Missing} - objective function value (missing if failed)</li><li><code>iterations</code>: Union{Int, Missing} - number of solver iterations (missing if failed)</li><li><code>status</code>: Any - termination status (type depends on solver/model)</li><li><code>success</code>: Bool - whether the solve succeeded</li><li><code>criterion</code>: Union{String, Missing} - optimization sense (&quot;min&quot; or &quot;max&quot;, missing if failed)</li><li><code>solution</code>: Any - underlying solution object (JuMP model or OptimalControl solution)</li></ul></div></section></details></article><h2 id="build_payload"><a class="docs-heading-anchor" href="#build_payload"><code>build_payload</code></a><a id="build_payload-1"></a><a class="docs-heading-anchor-permalink" href="#build_payload" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.build_payload"><a class="docstring-binding" href="#CTBenchmarks.build_payload"><code>CTBenchmarks.build_payload</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">build_payload(
    results::DataFrames.DataFrame,
    meta::Dict,
    config::Dict
) -&gt; Dict
</code></pre><p>Combine benchmark results, metadata, and configuration into a JSON-friendly payload.</p><p>The results <code>DataFrame</code> is converted to a vector of dictionaries (one per row) for easy JSON serialisation and reconstruction. Solutions are extracted and kept in memory (not serialised to JSON) for later plot generation.</p><p><strong>Arguments</strong></p><ul><li><code>results::DataFrame</code>: Benchmark results table produced by <code>benchmark_data</code></li><li><code>meta::Dict</code>: Environment metadata produced by <code>generate_metadata</code></li><li><code>config::Dict</code>: Configuration describing the benchmark run (problems, solvers, grids, etc.)</li></ul><p><strong>Returns</strong></p><ul><li><code>Dict</code>: Payload with three keys:<ul><li><code>&quot;metadata&quot;</code> – merged metadata and configuration</li><li><code>&quot;results&quot;</code> – vector of row dictionaries obtained from <code>results</code></li><li><code>&quot;solutions&quot;</code> – vector of solution objects (kept in memory only)</li></ul></li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; payload = CTBenchmarks.build_payload(results, meta, config)
Dict{String, Any} with 3 entries:
  &quot;metadata&quot;  =&gt; Dict{String, Any}(...)
  &quot;results&quot;   =&gt; Vector{Dict}(...)
  &quot;solutions&quot; =&gt; Any[...]</code></pre></div></section></details></article><h2 id="compute_profile_stats"><a class="docs-heading-anchor" href="#compute_profile_stats"><code>compute_profile_stats</code></a><a id="compute_profile_stats-1"></a><a class="docs-heading-anchor-permalink" href="#compute_profile_stats" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.compute_profile_stats"><a class="docstring-binding" href="#CTBenchmarks.compute_profile_stats"><code>CTBenchmarks.compute_profile_stats</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">compute_profile_stats(pp::PerformanceProfile) -&gt; ProfileAnalysis</code></pre><p>Compute statistical analysis of a performance profile.</p><p>This function extracts and calculates all performance metrics without any formatting. It returns structured data that can be used for different presentation formats (Markdown, JSON, etc.).</p><p><strong>Arguments</strong></p><ul><li><code>pp::PerformanceProfile</code>: Pre-computed performance profile data</li></ul><p><strong>Returns</strong></p><ul><li><code>ProfileAnalysis</code>: Structured analysis results</li></ul></div></section></details></article><h2 id="costate_multiplier"><a class="docs-heading-anchor" href="#costate_multiplier"><code>costate_multiplier</code></a><a id="costate_multiplier-1"></a><a class="docs-heading-anchor-permalink" href="#costate_multiplier" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.costate_multiplier"><a class="docstring-binding" href="#CTBenchmarks.costate_multiplier"><code>CTBenchmarks.costate_multiplier</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">costate_multiplier(criterion) -&gt; Int64
</code></pre><p>Determine the sign used to plot costates based on the optimization criterion.</p><p>For maximisation problems, costates are plotted with a positive sign. For minimisation problems (the default), costates are plotted with a negative sign so that their visual behaviour matches the usual optimal control conventions.</p><p><strong>Arguments</strong></p><ul><li><code>criterion</code>: Optimization criterion (<code>:min</code>, <code>:max</code>, or <code>missing</code>).</li></ul><p><strong>Returns</strong></p><ul><li><code>Int</code>: <code>+1</code> if the problem is a maximisation, <code>-1</code> otherwise.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.costate_multiplier(:min)
-1

julia&gt; CTBenchmarks.costate_multiplier(:max)
1</code></pre></div></section></details></article><h2 id="create_jump_layout"><a class="docs-heading-anchor" href="#create_jump_layout"><code>create_jump_layout</code></a><a id="create_jump_layout-1"></a><a class="docs-heading-anchor-permalink" href="#create_jump_layout" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.create_jump_layout"><a class="docstring-binding" href="#CTBenchmarks.create_jump_layout"><code>CTBenchmarks.create_jump_layout</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">create_jump_layout(
    n::Int64,
    m::Int64,
    problem::Symbol,
    grid_size::Int64,
    state_labels::Vector{&lt;:AbstractString},
    control_labels::Vector{&lt;:AbstractString}
) -&gt; Any
</code></pre><p>Create a nested plot layout for JuMP solutions.</p><p>Generates a multi-panel layout with states and costates in two columns, and controls spanning the full width below. This layout facilitates easy visual comparison of multiple solutions overlaid on the same plots.</p><p><strong>Arguments</strong></p><ul><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>problem::Symbol</code>: Problem name (for plot styling)</li><li><code>grid_size::Int</code>: Grid size (used for sizing calculations)</li><li><code>state_labels::Vector{&lt;:AbstractString}</code>: Labels for state components</li><li><code>control_labels::Vector{&lt;:AbstractString}</code>: Labels for control components</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Plot</code>: Nested plot layout with (n + n + m) accessible subplots</li></ul><p><strong>Layout Structure</strong></p><ul><li><strong>Left column</strong>: State trajectories (n subplots)</li><li><strong>Right column</strong>: Costate trajectories (n subplots)</li><li><strong>Bottom</strong>: Control trajectories (m subplots, full width)</li></ul><p><strong>Details</strong></p><p>Subplots are accessed linearly:</p><ul><li><code>plt[1:n]</code> = states</li><li><code>plt[n+1:2n]</code> = costates</li><li><code>plt[2n+1:2n+m]</code> = controls</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; state_labels = [&quot;x₁&quot;, &quot;x₂&quot;, &quot;x₃&quot;]
julia&gt; control_labels = [&quot;u₁&quot;, &quot;u₂&quot;]
julia&gt; plt = CTBenchmarks.create_jump_layout(3, 2, :beam, 100, state_labels, control_labels)</code></pre></div></section></details></article><h2 id="default_plot_config"><a class="docs-heading-anchor" href="#default_plot_config"><code>default_plot_config</code></a><a id="default_plot_config-1"></a><a class="docs-heading-anchor-permalink" href="#default_plot_config" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.default_plot_config"><a class="docstring-binding" href="#CTBenchmarks.default_plot_config"><code>CTBenchmarks.default_plot_config</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">default_plot_config() -&gt; PerformanceProfilePlotConfig</code></pre><p>Create a default configuration for performance profile plots.</p></div></section></details></article><h2 id="filter_models_for_backend"><a class="docs-heading-anchor" href="#filter_models_for_backend"><code>filter_models_for_backend</code></a><a id="filter_models_for_backend-1"></a><a class="docs-heading-anchor-permalink" href="#filter_models_for_backend" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.filter_models_for_backend"><a class="docstring-binding" href="#CTBenchmarks.filter_models_for_backend"><code>CTBenchmarks.filter_models_for_backend</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">filter_models_for_backend(
    models::Vector{Symbol},
    disc_method::Symbol
) -&gt; Vector{Symbol}
</code></pre><p>Filter solver models depending on backend availability and discretization support.</p><ul><li>GPU models (ending with <code>_gpu</code>) are kept only if CUDA is available.</li><li>JuMP models are kept only when <code>disc_method == :trapeze</code>.</li></ul><p><strong>Arguments</strong></p><ul><li><code>models::Vector{Symbol}</code>: Candidate model types (e.g. <code>[:jump, :adnlp, :exa, :exa_gpu]</code>)</li><li><code>disc_method::Symbol</code>: Discretization method (<code>:trapeze</code> or <code>:midpoint</code>)</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Symbol}</code>: Filtered list of models that are compatible with the current backend configuration.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.filter_models_for_backend([:jump, :exa, :exa_gpu], :trapeze)
3-element Vector{Symbol}:
 :jump
 :exa
 :exa_gpu</code></pre></div></section></details></article><h2 id="format_solution_label"><a class="docs-heading-anchor" href="#format_solution_label"><code>format_solution_label</code></a><a id="format_solution_label-1"></a><a class="docs-heading-anchor-permalink" href="#format_solution_label" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.format_solution_label"><a class="docstring-binding" href="#CTBenchmarks.format_solution_label"><code>CTBenchmarks.format_solution_label</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">format_solution_label(
    model::Symbol,
    solver::Symbol,
    success::Bool
) -&gt; String
</code></pre><p>Format a short label for use in plot legends, combining success status with the model and solver names.</p><p>The label starts with a tick or cross depending on whether the solution was successful, followed by <code>model-solver</code>.</p><p><strong>Arguments</strong></p><ul><li><code>model::Symbol</code>: Model name (e.g. <code>:jump</code>, <code>:adnlp</code>, <code>:exa</code>)</li><li><code>solver::Symbol</code>: Solver name (e.g. <code>:ipopt</code>, <code>:madnlp</code>)</li><li><code>success::Bool</code>: Whether the solve succeeded (<code>true</code>) or failed (<code>false</code>)</li></ul><p><strong>Returns</strong></p><ul><li><code>String</code>: A label such as <code>&quot;✓ jump-ipopt&quot;</code> or <code>&quot;✗ exa-madnlp&quot;</code></li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.format_solution_label(:jump, :ipopt, true)
&quot;✓ jump-ipopt&quot;

julia&gt; CTBenchmarks.format_solution_label(:exa, :madnlp, false)
&quot;✗ exa-madnlp&quot;</code></pre></div></section></details></article><h2 id="generate_metadata"><a class="docs-heading-anchor" href="#generate_metadata"><code>generate_metadata</code></a><a id="generate_metadata-1"></a><a class="docs-heading-anchor-permalink" href="#generate_metadata" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.generate_metadata"><a class="docstring-binding" href="#CTBenchmarks.generate_metadata"><code>CTBenchmarks.generate_metadata</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">generate_metadata() -&gt; Dict{String, String}
</code></pre><p>Collect metadata about the current Julia environment for benchmark reproducibility.</p><p>The returned dictionary includes a timestamp, Julia version, OS and machine information, as well as textual snapshots of the package environment.</p><p><strong>Returns</strong></p><ul><li><code>Dict{String,String}</code>: Dictionary with keys<ul><li><code>&quot;timestamp&quot;</code>: Current time in UTC (ISO8601-like formatting)</li><li><code>&quot;julia_version&quot;</code>: Julia version string</li><li><code>&quot;os&quot;</code>: Kernel/OS identifier</li><li><code>&quot;machine&quot;</code>: Hostname of the current machine</li><li><code>&quot;pkg_status&quot;</code>: Output of <code>Pkg.status()</code> with ANSI colours</li><li><code>&quot;versioninfo&quot;</code>: Output of <code>versioninfo()</code> with ANSI colours</li><li><code>&quot;pkg_manifest&quot;</code>: Output of <code>Pkg.status(mode=PKGMODE_MANIFEST)</code> with ANSI colours</li></ul></li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; meta = CTBenchmarks.generate_metadata()
Dict{String, String} with 7 entries:
  &quot;timestamp&quot;     =&gt; &quot;2025-11-15 18:30:00 UTC&quot;
  &quot;julia_version&quot; =&gt; &quot;1.10.0&quot;
  &quot;os&quot;            =&gt; &quot;Linux&quot;
  ⋮</code></pre></div></section></details></article><h2 id="get_color"><a class="docs-heading-anchor" href="#get_color"><code>get_color</code></a><a id="get_color-1"></a><a class="docs-heading-anchor-permalink" href="#get_color" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_color"><a class="docstring-binding" href="#CTBenchmarks.get_color"><code>CTBenchmarks.get_color</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_color(
    model::Union{String, Symbol},
    solver::Union{String, Symbol},
    idx::Int64
) -&gt; Symbol
</code></pre><p>Return a consistent color for a given (model, solver) pair.</p><p>This function ensures visual consistency across plots by assigning fixed colors to known (model, solver) combinations. For unknown combinations, it cycles through a default palette based on the provided index.</p><p><strong>Fixed Mappings</strong></p><ul><li><code>(adnlp, ipopt)</code> → <code>:blue</code></li><li><code>(exa, ipopt)</code> → <code>:red</code></li><li><code>(adnlp, madnlp)</code> → <code>:green</code></li><li><code>(exa, madnlp)</code> → <code>:orange</code></li><li><code>(jump, ipopt)</code> → <code>:purple</code></li><li><code>(jump, madnlp)</code> → <code>:brown</code></li><li><code>(exa_gpu, madnlp)</code> → <code>:cyan</code></li></ul><p><strong>Arguments</strong></p><ul><li><code>model::Union{Symbol,String}</code>: Model name (case-insensitive)</li><li><code>solver::Union{Symbol,String}</code>: Solver name (case-insensitive)</li><li><code>idx::Int</code>: Index for palette fallback (used if pair not in fixed mappings)</li></ul><p><strong>Returns</strong></p><ul><li><code>Symbol</code>: Color symbol suitable for Plots.jl (e.g., <code>:blue</code>, <code>:red</code>)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.get_color(:adnlp, :ipopt, 1)
:blue

julia&gt; CTBenchmarks.get_color(:unknown, :solver, 2)
:red</code></pre></div></section></details></article><h2 id="get_config"><a class="docs-heading-anchor" href="#get_config"><code>get_config</code></a><a id="get_config-1"></a><a class="docs-heading-anchor-permalink" href="#get_config" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_config"><a class="docstring-binding" href="#CTBenchmarks.get_config"><code>CTBenchmarks.get_config</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_config(registry::PerformanceProfileRegistry, name::AbstractString) -&gt; PerformanceProfileConfig</code></pre><p>Retrieve a registered performance profile configuration by name.</p><p><strong>Arguments</strong></p><ul><li><code>registry</code>: The registry to search.</li><li><code>name</code>: Name of the configuration.</li></ul><p><strong>Throws</strong></p><ul><li><code>KeyError</code> if the name is not found in the registry.</li></ul></div></section></details></article><h2 id="get_dimensions"><a class="docs-heading-anchor" href="#get_dimensions"><code>get_dimensions</code></a><a id="get_dimensions-1"></a><a class="docs-heading-anchor-permalink" href="#get_dimensions" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_dimensions"><a class="docstring-binding" href="#CTBenchmarks.get_dimensions"><code>CTBenchmarks.get_dimensions</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_dimensions(
    group::DataFrames.SubDataFrame
) -&gt; Tuple{Any, Any}
</code></pre><p>Get state and control dimensions from the first available solution in a group.</p><p>Extracts the problem dimensions (number of states and controls) by examining the first solution in the group. Works with both OptimalControl.Solution and JuMP.Model objects.</p><p><strong>Arguments</strong></p><ul><li><code>group::SubDataFrame</code>: DataFrame subset with solution rows</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Int, Int}</code>: <code>(n, m)</code> where n = number of states, m = number of controls</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; n, m = CTBenchmarks.get_dimensions(group)
(3, 2)</code></pre></div></section></details></article><h2 id="get_left_margin"><a class="docs-heading-anchor" href="#get_left_margin"><code>get_left_margin</code></a><a id="get_left_margin-1"></a><a class="docs-heading-anchor-permalink" href="#get_left_margin" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_left_margin"><a class="docstring-binding" href="#CTBenchmarks.get_left_margin"><code>CTBenchmarks.get_left_margin</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_left_margin(problem::Symbol) -&gt; Measures.AbsoluteLength
</code></pre><p>Get the left margin for plots based on the problem.</p><p>Different problems may require different margins to accommodate axis labels and titles. The beam problem uses a smaller margin (5mm) while other problems use 20mm.</p><p><strong>Arguments</strong></p><ul><li><code>problem::Symbol</code>: Problem name (e.g., <code>:beam</code>, <code>:shuttle</code>)</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Measure</code>: Left margin in millimeters (5mm or 20mm)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.get_left_margin(:beam)
5 mm

julia&gt; CTBenchmarks.get_left_margin(:shuttle)
20 mm</code></pre></div></section></details></article><h2 id="get_marker_indices"><a class="docs-heading-anchor" href="#get_marker_indices"><code>get_marker_indices</code></a><a id="get_marker_indices-1"></a><a class="docs-heading-anchor-permalink" href="#get_marker_indices" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_marker_indices"><a class="docstring-binding" href="#CTBenchmarks.get_marker_indices"><code>CTBenchmarks.get_marker_indices</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_marker_indices(
    idx::Int64,
    card_g::Int64,
    grid_size::Int64,
    marker_interval::Int64
) -&gt; StepRange{Int64, Int64}
</code></pre><p>Calculate marker indices with offset to avoid superposition between curves.</p><p>When multiple curves are overlaid on the same plot, markers can overlap and obscure the visualization. This function staggers the marker positions across curves by applying an offset based on the curve index.</p><p><strong>Arguments</strong></p><ul><li><code>idx::Int</code>: Curve index (1-based)</li><li><code>card_g::Int</code>: Total number of curves</li><li><code>grid_size::Int</code>: Number of grid points on the curve</li><li><code>marker_interval::Int</code>: Base spacing between markers</li></ul><p><strong>Returns</strong></p><ul><li><code>UnitRange{Int}</code>: Range of indices for marker placement</li></ul><p><strong>Details</strong></p><p>For curve <code>idx</code> out of <code>card_g</code> curves, the first marker is offset by:</p><pre><code class="language-julia hljs">offset = (idx - 1) * marker_interval / card_g</code></pre><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.get_marker_indices(1, 3, 100, 20)
1:20:101

julia&gt; CTBenchmarks.get_marker_indices(2, 3, 100, 20)
8:20:101</code></pre></div></section></details></article><h2 id="get_marker_style"><a class="docs-heading-anchor" href="#get_marker_style"><code>get_marker_style</code></a><a id="get_marker_style-1"></a><a class="docs-heading-anchor-permalink" href="#get_marker_style" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_marker_style"><a class="docstring-binding" href="#CTBenchmarks.get_marker_style"><code>CTBenchmarks.get_marker_style</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_marker_style(
    model::Union{String, Symbol},
    solver::Union{String, Symbol},
    idx::Int64
) -&gt; Symbol
</code></pre><p>Get marker shape and spacing for a given (model, solver) pair.</p><p>This function provides consistent marker styles for known (model, solver) combinations and automatically calculates appropriate marker spacing based on grid size to avoid visual clutter while maintaining visibility.</p><p><strong>Fixed Mappings</strong></p><ul><li><code>(adnlp, ipopt)</code> → <code>:circle</code></li><li><code>(exa, ipopt)</code> → <code>:square</code></li><li><code>(adnlp, madnlp)</code> → <code>:diamond</code></li><li><code>(exa, madnlp)</code> → <code>:utriangle</code></li><li><code>(jump, ipopt)</code> → <code>:dtriangle</code></li><li><code>(jump, madnlp)</code> → <code>:star5</code></li><li><code>(exa_gpu, madnlp)</code> → <code>:hexagon</code></li></ul><p><strong>Arguments</strong></p><ul><li><code>model::Union{Symbol,String}</code>: Model name (case-insensitive)</li><li><code>solver::Union{Symbol,String}</code>: Solver name (case-insensitive)</li><li><code>idx::Int</code>: Index for marker fallback (used if pair not in fixed mappings)</li><li><code>grid_size::Int</code>: Number of grid points on the curve</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Symbol, Int}</code>: <code>(marker_shape, marker_interval)</code> where:<ul><li><code>marker_shape</code>: Symbol for marker type (e.g., <code>:circle</code>, <code>:square</code>)</li><li><code>marker_interval</code>: Spacing between markers (calculated as <code>max(1, grid_size ÷ 6)</code>)</li></ul></li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.get_marker_style(:adnlp, :ipopt, 1, 200)
(:circle, 33)

julia&gt; CTBenchmarks.get_marker_style(:unknown, :solver, 2, 100)
(:square, 16)</code></pre></div></section></details></article><h2 id="get_solution_dimensions"><a class="docs-heading-anchor" href="#get_solution_dimensions"><code>get_solution_dimensions</code></a><a id="get_solution_dimensions-1"></a><a class="docs-heading-anchor-permalink" href="#get_solution_dimensions" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.get_solution_dimensions"><a class="docstring-binding" href="#CTBenchmarks.get_solution_dimensions"><code>CTBenchmarks.get_solution_dimensions</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">get_solution_dimensions(
    solution::CTModels.Solution
) -&gt; Tuple{Int64, Int64}
</code></pre><p>Extract state and control dimensions from an OptimalControl solution.</p><p><strong>Arguments</strong></p><ul><li><code>solution::OptimalControl.Solution</code>: OptimalControl solution object</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Int, Int}</code>: <code>(n, m)</code> where n = number of states, m = number of controls</li></ul></div></section><section><div><pre><code class="language-julia hljs">get_solution_dimensions(
    solution::JuMP.Model
) -&gt; Tuple{Any, Any}
</code></pre><p>Extract state and control dimensions from a JuMP model solution.</p><p><strong>Arguments</strong></p><ul><li><code>solution::JuMP.Model</code>: JuMP model solution object</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Int, Int}</code>: <code>(n, m)</code> where n = number of states, m = number of controls</li></ul></div></section></details></article><h2 id="is_cuda_on"><a class="docs-heading-anchor" href="#is_cuda_on"><code>is_cuda_on</code></a><a id="is_cuda_on-1"></a><a class="docs-heading-anchor-permalink" href="#is_cuda_on" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.is_cuda_on"><a class="docstring-binding" href="#CTBenchmarks.is_cuda_on"><code>CTBenchmarks.is_cuda_on</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">is_cuda_on() -&gt; Bool
</code></pre><p>Check whether CUDA is available and functional on this machine.</p><p>This function is used to decide whether GPU-based models (those whose name ends with <code>_gpu</code>) can be run in the benchmark suite.</p><p><strong>Returns</strong></p><ul><li><code>Bool</code>: <code>true</code> if CUDA is functional, <code>false</code> otherwise.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.is_cuda_on()
false</code></pre></div></section></details></article><h2 id="list_profiles"><a class="docs-heading-anchor" href="#list_profiles"><code>list_profiles</code></a><a id="list_profiles-1"></a><a class="docs-heading-anchor-permalink" href="#list_profiles" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.list_profiles"><a class="docstring-binding" href="#CTBenchmarks.list_profiles"><code>CTBenchmarks.list_profiles</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">list_profiles(registry::PerformanceProfileRegistry) -&gt; Vector{String}</code></pre><p>Return a list of all registered profile names.</p></div></section></details></article><h2 id="plot_jump_group"><a class="docs-heading-anchor" href="#plot_jump_group"><code>plot_jump_group</code></a><a id="plot_jump_group-1"></a><a class="docs-heading-anchor-permalink" href="#plot_jump_group" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_jump_group"><a class="docstring-binding" href="#CTBenchmarks.plot_jump_group"><code>CTBenchmarks.plot_jump_group</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_jump_group(
    jump_rows::DataFrames.SubDataFrame,
    plt,
    color_idx::Int64,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64
) -&gt; Tuple{Any, Int64}
plot_jump_group(
    jump_rows::DataFrames.SubDataFrame,
    plt,
    color_idx::Int64,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    card_g_override::Union{Nothing, Int64}
) -&gt; Tuple{Any, Int64}
</code></pre><p>Plot all JuMP solutions in a group with consistent styling.</p><p>This function creates the plot layout if <code>plt</code> is nothing, then adds all JuMP solutions from the group. JuMP solutions require special layout handling compared to OptimalControl solutions.</p><p><strong>Arguments</strong></p><ul><li><code>jump_rows::SubDataFrame</code>: Rows containing JuMP solutions</li><li><code>plt</code>: Existing plot (or <code>nothing</code> to create new)</li><li><code>color_idx::Int</code>: Current color index for consistent styling</li><li><code>problem::Symbol</code>: Problem name</li><li><code>grid_size::Int</code>: Grid size</li><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>card_g_override::Union{Int,Nothing}</code>: Override for total number of curves (for marker offset)</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Plots.Plot, Int}</code>: Updated plot and next color index</li></ul></div></section></details></article><h2 id="plot_jump_solution"><a class="docs-heading-anchor" href="#plot_jump_solution"><code>plot_jump_solution</code></a><a id="plot_jump_solution-1"></a><a class="docs-heading-anchor-permalink" href="#plot_jump_solution" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_jump_solution"><a class="docstring-binding" href="#CTBenchmarks.plot_jump_solution"><code>CTBenchmarks.plot_jump_solution</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_jump_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    criterion
) -&gt; Any
plot_jump_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    criterion,
    marker
) -&gt; Any
plot_jump_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    criterion,
    marker,
    marker_interval
) -&gt; Any
plot_jump_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    criterion,
    marker,
    marker_interval,
    idx::Int64
) -&gt; Any
plot_jump_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    criterion,
    marker,
    marker_interval,
    idx::Int64,
    card_g::Int64
) -&gt; Any
</code></pre><p>Create a new multi-panel plot for a single JuMP solution.</p><p>Generates a comprehensive visualization with state, costate, and control trajectories from a JuMP model, with spaced markers and legend entry indicating success status.</p><p><strong>Arguments</strong></p><ul><li><code>solution</code>: JuMP.Model object</li><li><code>model::Symbol</code>: Model name (for legend)</li><li><code>solver::Symbol</code>: Solver name (for legend)</li><li><code>success::Bool</code>: Whether the solution converged successfully</li><li><code>color</code>: Color symbol (from <code>get_color</code>)</li><li><code>problem::Symbol</code>: Problem name (for plot styling)</li><li><code>grid_size::Int</code>: Grid size</li><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>criterion</code>: Optimization criterion (<code>:min</code> or <code>:max</code>, affects costate sign)</li><li><code>marker</code>: Marker shape symbol (default: <code>:circle</code>)</li><li><code>marker_interval::Int</code>: Spacing between markers (default: 10)</li><li><code>idx::Int</code>: Curve index for marker offset (default: 1)</li><li><code>card_g::Int</code>: Total number of curves for marker offset (default: 1)</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Plot</code>: Multi-panel plot with (n + n + m) subplots</li></ul></div></section></details></article><h2 id="plot_jump_solution!"><a class="docs-heading-anchor" href="#plot_jump_solution!"><code>plot_jump_solution!</code></a><a id="plot_jump_solution!-1"></a><a class="docs-heading-anchor-permalink" href="#plot_jump_solution!" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_jump_solution!"><a class="docstring-binding" href="#CTBenchmarks.plot_jump_solution!"><code>CTBenchmarks.plot_jump_solution!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_jump_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    criterion
) -&gt; Any
plot_jump_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    criterion,
    marker
) -&gt; Any
plot_jump_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    criterion,
    marker,
    marker_interval
) -&gt; Any
plot_jump_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    criterion,
    marker,
    marker_interval,
    idx::Int64
) -&gt; Any
plot_jump_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    criterion,
    marker,
    marker_interval,
    idx::Int64,
    card_g::Int64
) -&gt; Any
</code></pre><p>Add a JuMP solution to an existing multi-panel plot.</p><p>Appends state, costate, and control trajectories from a JuMP model to existing subplots with spaced markers and consistent styling. Updates the legend with success status.</p><p><strong>Arguments</strong></p><ul><li><code>plt</code>: Existing Plots.Plot to modify</li><li><code>solution</code>: JuMP.Model object</li><li><code>model::Symbol</code>: Model name (for legend)</li><li><code>solver::Symbol</code>: Solver name (for legend)</li><li><code>success::Bool</code>: Whether the solution converged successfully</li><li><code>color</code>: Color symbol (from <code>get_color</code>)</li><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>criterion</code>: Optimization criterion (<code>:min</code> or <code>:max</code>, affects costate sign)</li><li><code>marker</code>: Marker shape symbol (default: <code>:none</code>)</li><li><code>marker_interval::Int</code>: Spacing between markers (default: 10)</li><li><code>idx::Int</code>: Curve index for marker offset (default: 1)</li><li><code>card_g::Int</code>: Total number of curves for marker offset (default: 1)</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Plot</code>: Modified plot with new solution added</li></ul><p><strong>Note</strong></p><p>Even with nested layout, subplots are accessed linearly:</p><ul><li><code>plt[1:n]</code> = states</li><li><code>plt[n+1:2n]</code> = costates</li><li><code>plt[2n+1:2n+m]</code> = controls</li></ul></div></section></details></article><h2 id="plot_ocp_group"><a class="docs-heading-anchor" href="#plot_ocp_group"><code>plot_ocp_group</code></a><a id="plot_ocp_group-1"></a><a class="docs-heading-anchor-permalink" href="#plot_ocp_group" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_ocp_group"><a class="docstring-binding" href="#CTBenchmarks.plot_ocp_group"><code>CTBenchmarks.plot_ocp_group</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_ocp_group(
    ocp_rows::DataFrames.SubDataFrame,
    plt,
    color_idx::Int64,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64
) -&gt; Tuple{Any, Int64}
plot_ocp_group(
    ocp_rows::DataFrames.SubDataFrame,
    plt,
    color_idx::Int64,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    card_g_override::Union{Nothing, Int64}
) -&gt; Tuple{Any, Int64}
</code></pre><p>Plot all OptimalControl solutions in a group with consistent styling.</p><p>This function creates the base plot if <code>plt</code> is nothing, then adds all OptimalControl solutions from the group with consistent colors and markers. It manages color indexing across multiple groups to ensure visual consistency.</p><p><strong>Arguments</strong></p><ul><li><code>ocp_rows::SubDataFrame</code>: Rows containing OptimalControl solutions</li><li><code>plt</code>: Existing plot (or <code>nothing</code> to create new)</li><li><code>color_idx::Int</code>: Current color index for consistent styling</li><li><code>problem::Symbol</code>: Problem name</li><li><code>grid_size::Int</code>: Grid size</li><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>card_g_override::Union{Int,Nothing}</code>: Override for total number of curves (for marker offset)</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Plots.Plot, Int}</code>: Updated plot and next color index</li></ul></div></section></details></article><h2 id="plot_ocp_solution"><a class="docs-heading-anchor" href="#plot_ocp_solution"><code>plot_ocp_solution</code></a><a id="plot_ocp_solution-1"></a><a class="docs-heading-anchor-permalink" href="#plot_ocp_solution" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_ocp_solution"><a class="docstring-binding" href="#CTBenchmarks.plot_ocp_solution"><code>CTBenchmarks.plot_ocp_solution</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_ocp_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    marker,
    marker_interval
) -&gt; Any
plot_ocp_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    marker,
    marker_interval,
    idx::Int64
) -&gt; Any
plot_ocp_solution(
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    problem::Symbol,
    grid_size::Int64,
    n::Int64,
    m::Int64,
    marker,
    marker_interval,
    idx::Int64,
    card_g::Int64
) -&gt; Any
</code></pre><p>Create a new multi-panel plot for a single OptimalControl solution.</p><p>Generates a comprehensive visualization with state, costate, and control trajectories, with spaced markers for improved visibility and a legend entry indicating success status.</p><p><strong>Arguments</strong></p><ul><li><code>solution</code>: OptimalControl.Solution object</li><li><code>model::Symbol</code>: Model name (for legend)</li><li><code>solver::Symbol</code>: Solver name (for legend)</li><li><code>success::Bool</code>: Whether the solution converged successfully</li><li><code>color</code>: Color symbol (from <code>get_color</code>)</li><li><code>problem::Symbol</code>: Problem name (for plot styling)</li><li><code>grid_size::Int</code>: Grid size</li><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>marker</code>: Marker shape symbol (from <code>get_marker_style</code>)</li><li><code>marker_interval::Int</code>: Spacing between markers</li><li><code>idx::Int</code>: Curve index for marker offset (default: 1)</li><li><code>card_g::Int</code>: Total number of curves for marker offset (default: 1)</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Plot</code>: Multi-panel plot with (n + n + m) subplots</li></ul></div></section></details></article><h2 id="plot_ocp_solution!"><a class="docs-heading-anchor" href="#plot_ocp_solution!"><code>plot_ocp_solution!</code></a><a id="plot_ocp_solution!-1"></a><a class="docs-heading-anchor-permalink" href="#plot_ocp_solution!" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_ocp_solution!"><a class="docstring-binding" href="#CTBenchmarks.plot_ocp_solution!"><code>CTBenchmarks.plot_ocp_solution!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_ocp_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    marker,
    marker_interval
) -&gt; Any
plot_ocp_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    marker,
    marker_interval,
    idx::Int64
) -&gt; Any
plot_ocp_solution!(
    plt,
    solution,
    model::Symbol,
    solver::Symbol,
    success::Bool,
    color,
    n::Int64,
    m::Int64,
    marker,
    marker_interval,
    idx::Int64,
    card_g::Int64
) -&gt; Any
</code></pre><p>Add an OptimalControl solution to an existing multi-panel plot.</p><p>Appends state, costate, and control trajectories to existing subplots with spaced markers and consistent styling. Updates the legend with success status.</p><p><strong>Arguments</strong></p><ul><li><code>plt</code>: Existing Plots.Plot to modify</li><li><code>solution</code>: OptimalControl.Solution object</li><li><code>model::Symbol</code>: Model name (for legend)</li><li><code>solver::Symbol</code>: Solver name (for legend)</li><li><code>success::Bool</code>: Whether the solution converged successfully</li><li><code>color</code>: Color symbol (from <code>get_color</code>)</li><li><code>n::Int</code>: Number of states</li><li><code>m::Int</code>: Number of controls</li><li><code>marker</code>: Marker shape symbol (from <code>get_marker_style</code>)</li><li><code>marker_interval::Int</code>: Spacing between markers</li><li><code>idx::Int</code>: Curve index for marker offset (default: 1)</li><li><code>card_g::Int</code>: Total number of curves for marker offset (default: 1)</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Plot</code>: Modified plot with new solution added</li></ul></div></section></details></article><h2 id="plot_solution_comparison"><a class="docs-heading-anchor" href="#plot_solution_comparison"><code>plot_solution_comparison</code></a><a id="plot_solution_comparison-1"></a><a class="docs-heading-anchor-permalink" href="#plot_solution_comparison" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_solution_comparison"><a class="docstring-binding" href="#CTBenchmarks.plot_solution_comparison"><code>CTBenchmarks.plot_solution_comparison</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">plot_solution_comparison(
    group::DataFrames.SubDataFrame,
    problem::Symbol,
    grid_size::Int64
) -&gt; Any
</code></pre><p>Create a comprehensive comparison plot for all solutions in a group.</p><p>This function orchestrates the plotting of all OptimalControl and JuMP solutions for a given problem and grid size, arranging them in a multi-panel layout with consistent styling.</p><p><strong>Arguments</strong></p><ul><li><code>group::SubDataFrame</code>: DataFrame subset with rows for the same (problem, grid_size)</li><li><code>problem::Symbol</code>: Problem name (used for plot styling, e.g., left margin)</li><li><code>grid_size::Int</code>: Grid size (used for marker spacing calculations)</li></ul><p><strong>Returns</strong></p><ul><li><code>Plots.Plot</code>: Multi-panel plot with states, costates, and controls</li></ul><p><strong>Layout</strong></p><ul><li><strong>Top panels</strong>: State trajectories (n columns)</li><li><strong>Middle panels</strong>: Costate trajectories (n columns)</li><li><strong>Bottom panels</strong>: Control trajectories (m columns, full width)</li></ul><p><strong>Strategy</strong></p><ol><li>OptimalControl solutions plotted first (simple overlay with <code>plot!</code>)</li><li>JuMP solutions plotted last (for proper subplot layout)</li><li>All solutions use consistent colors and markers via <code>get_color</code> and <code>get_marker_style</code></li><li>Success/failure indicators (✓/✗) shown in legend</li></ol></div></section></details></article><h2 id="prettymemory"><a class="docs-heading-anchor" href="#prettymemory"><code>prettymemory</code></a><a id="prettymemory-1"></a><a class="docs-heading-anchor-permalink" href="#prettymemory" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.prettymemory"><a class="docstring-binding" href="#CTBenchmarks.prettymemory"><code>CTBenchmarks.prettymemory</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">prettymemory(b) -&gt; String
</code></pre><p>Format a memory footprint <code>bytes</code> into a human-readable string using binary prefixes (bytes, KiB, MiB, GiB) with two decimal places.</p><p>The function uses standard binary units (1024 bytes = 1 KiB) and automatically selects the most appropriate unit based on the magnitude of the input value.</p><p><strong>Arguments</strong></p><ul><li><code>bytes::Integer</code>: Memory size in bytes (must be non-negative)</li></ul><p><strong>Returns</strong></p><ul><li><code>String</code>: Formatted memory string with two decimal places and unit suffix</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.prettymemory(512)
&quot;512 bytes&quot;

julia&gt; CTBenchmarks.prettymemory(1048576)
&quot;1.00 MiB&quot;

julia&gt; CTBenchmarks.prettymemory(2147483648)
&quot;2.00 GiB&quot;</code></pre></div></section></details></article><h2 id="prettytime"><a class="docs-heading-anchor" href="#prettytime"><code>prettytime</code></a><a id="prettytime-1"></a><a class="docs-heading-anchor-permalink" href="#prettytime" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.prettytime"><a class="docstring-binding" href="#CTBenchmarks.prettytime"><code>CTBenchmarks.prettytime</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">prettytime(t) -&gt; String
</code></pre><p>Format a duration <code>t</code> expressed in <strong>seconds</strong> into a human-readable string with three decimal places and adaptive units (ns, μs, ms, s).</p><p>The function automatically selects the most appropriate unit based on the magnitude of the input value, ensuring readable output across a wide range of timescales.</p><p><strong>Arguments</strong></p><ul><li><code>t::Real</code>: Duration in seconds (can be positive or negative)</li></ul><p><strong>Returns</strong></p><ul><li><code>String</code>: Formatted time string with three decimal places and unit suffix</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.prettytime(0.001234)
&quot;1.234 ms&quot;

julia&gt; CTBenchmarks.prettytime(1.5)
&quot;1.500 s &quot;

julia&gt; CTBenchmarks.prettytime(5.6e-7)
&quot;560.000 ns&quot;</code></pre></div></section></details></article><h2 id="print_benchmark_line"><a class="docs-heading-anchor" href="#print_benchmark_line"><code>print_benchmark_line</code></a><a id="print_benchmark_line-1"></a><a class="docs-heading-anchor-permalink" href="#print_benchmark_line" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.print_benchmark_line"><a class="docstring-binding" href="#CTBenchmarks.print_benchmark_line"><code>CTBenchmarks.print_benchmark_line</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">print_benchmark_line(model::Symbol, stats::NamedTuple)
</code></pre><p>Print a formatted line summarizing benchmark statistics for <code>model</code> with colors.</p><p>This function formats and displays benchmark results in a human-readable table row, including execution time, memory usage, solver objective value, iteration count, and success status. It automatically detects and handles both CPU benchmarks (from <code>@btimed</code>) and GPU benchmarks (from <code>CUDA.@timed</code>).</p><p><strong>Arguments</strong></p><ul><li><code>model::Symbol</code>: Name of the model being benchmarked (e.g., <code>:jump</code>, <code>:adnlp</code>)</li><li><code>stats::NamedTuple</code>: Statistics dictionary containing:<ul><li><code>benchmark</code>: Timing and memory data (Dict or NamedTuple) with fields:<ul><li><code>:time</code>: Execution time in seconds</li><li><code>:bytes</code> or <code>:cpu_bytes</code>, <code>:gpu_bytes</code>: Memory allocation</li></ul></li><li><code>objective</code>: Solver objective value (or <code>missing</code>)</li><li><code>iterations</code>: Number of solver iterations (or <code>missing</code>)</li><li><code>success</code>: Boolean indicating successful completion</li><li><code>criterion</code>: Optimization criterion (e.g., <code>:min</code>, <code>:max</code>) or <code>missing</code></li><li><code>status</code>: Error message (used when benchmark is missing)</li></ul></li></ul><p><strong>Output</strong></p><p>Prints a colored, formatted line to stdout with:</p><ul><li>Success indicator (✓ in green or ✗ in red)</li><li>Model name in magenta</li><li>Formatted execution time</li><li>Iteration count</li><li>Objective value in scientific notation</li><li>Criterion type</li><li>Memory usage (CPU and/or GPU)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; stats = (
           benchmark = (time = 0.123, bytes = 1048576),
           objective = 42.5,
           iterations = 100,
           success = true,
           criterion = :min
       )

julia&gt; CTBenchmarks.print_benchmark_line(:jump, stats)
  ✓ | jump     | time:      0.123 s  | iters:   100 | obj: 4.250000e+01 (min) | CPU:       1.00 MiB</code></pre></div></section></details></article><h2 id="register!"><a class="docs-heading-anchor" href="#register!"><code>register!</code></a><a id="register!-1"></a><a class="docs-heading-anchor-permalink" href="#register!" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.register!"><a class="docstring-binding" href="#CTBenchmarks.register!"><code>CTBenchmarks.register!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">register!(registry::PerformanceProfileRegistry, name::AbstractString, config::PerformanceProfileConfig)</code></pre><p>Register a performance profile configuration under a given name.</p><p><strong>Arguments</strong></p><ul><li><code>registry</code>: The registry to add the configuration to.</li><li><code>name</code>: Name to associate with the configuration.</li><li><code>config</code>: The performance profile configuration.</li></ul></div></section></details></article><h2 id="save_json"><a class="docs-heading-anchor" href="#save_json"><code>save_json</code></a><a id="save_json-1"></a><a class="docs-heading-anchor-permalink" href="#save_json" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.save_json"><a class="docstring-binding" href="#CTBenchmarks.save_json"><code>CTBenchmarks.save_json</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">save_json(payload::Dict, filepath::AbstractString) -&gt; Int64
</code></pre><p>Save a JSON payload to a file. Creates the parent directory if needed and uses pretty printing for readability.</p><p>The <code>payload</code> is typically produced by <code>build_payload</code>. The <code>&quot;solutions&quot;</code> entry is excluded from serialisation so that the JSON contains only metadata and results.</p><p><strong>Arguments</strong></p><ul><li><code>payload::Dict</code>: Benchmark results with metadata</li><li><code>filepath::AbstractString</code>: Full path to the output JSON file (including filename)</li></ul><p><strong>Returns</strong></p><ul><li><code>Nothing</code>: Writes the JSON file as a side effect.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; payload = CTBenchmarks.build_payload(results, meta, config)

julia&gt; CTBenchmarks.save_json(payload, &quot;benchmarks.json&quot;)</code></pre></div></section></details></article><h2 id="set_print_level"><a class="docs-heading-anchor" href="#set_print_level"><code>set_print_level</code></a><a id="set_print_level-1"></a><a class="docs-heading-anchor-permalink" href="#set_print_level" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.set_print_level"><a class="docstring-binding" href="#CTBenchmarks.set_print_level"><code>CTBenchmarks.set_print_level</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">set_print_level(
    solver::Symbol,
    print_trace::Bool
) -&gt; Union{Int64, MadNLP.LogLevels}
</code></pre><p>Set print level based on solver and <code>print_trace</code> flag.</p><p>For Ipopt, this returns an integer verbosity level. For MadNLP, it returns a <code>MadNLP.LogLevels</code> value. The flag <code>print_trace</code> is typically propagated from high-level benchmarking options.</p><p><strong>Arguments</strong></p><ul><li><code>solver::Symbol</code>: Solver name (<code>:ipopt</code> or <code>:madnlp</code>)</li><li><code>print_trace::Bool</code>: Whether detailed solver output should be printed</li></ul><p><strong>Returns</strong></p><ul><li><code>Int</code> or <code>MadNLP.LogLevels</code>: Print level appropriate for the chosen solver</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; CTBenchmarks.set_print_level(:ipopt, true)
5

julia&gt; CTBenchmarks.set_print_level(:madnlp, false)
MadNLP.ERROR</code></pre></div></section></details></article><h2 id="solve_and_extract_data"><a class="docs-heading-anchor" href="#solve_and_extract_data"><code>solve_and_extract_data</code></a><a id="solve_and_extract_data-1"></a><a class="docs-heading-anchor-permalink" href="#solve_and_extract_data" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.solve_and_extract_data"><a class="docstring-binding" href="#CTBenchmarks.solve_and_extract_data"><code>CTBenchmarks.solve_and_extract_data</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">solve_and_extract_data(
    problem::Symbol,
    solver::Symbol,
    model::Symbol,
    grid_size::Int64,
    disc_method::Symbol,
    tol::Float64,
    mu_strategy::Union{Missing, String},
    print_trace::Bool,
    max_iter::Int64,
    max_wall_time::Float64
) -&gt; NamedTuple{(:benchmark, :objective, :iterations, :status, :success, :criterion, :solution)}
</code></pre><p>Solve an optimal control problem and extract performance and solver statistics.</p><p>This internal helper function orchestrates the solve process for different model types (JuMP, adnlp, exa, exa_gpu) and captures timing, memory, and solver statistics. It handles error cases gracefully by returning missing values instead of propagating exceptions.</p><p><strong>Arguments</strong></p><ul><li><code>problem::Symbol</code>: problem name (e.g., <code>:beam</code>, <code>:chain</code>)</li><li><code>solver::Symbol</code>: solver to use (<code>:ipopt</code> or <code>:madnlp</code>)</li><li><code>model::Symbol</code>: model type (<code>:jump</code>, <code>:adnlp</code>, <code>:exa</code>, or <code>:exa_gpu</code>)</li><li><code>grid_size::Int</code>: number of grid points</li><li><code>disc_method::Symbol</code>: discretization method (<code>:trapeze</code> or <code>:midpoint</code>)</li><li><code>tol::Float64</code>: solver tolerance</li><li><code>mu_strategy::Union{String, Missing}</code>: mu strategy for Ipopt (missing for MadNLP)</li><li><code>print_trace::Bool</code>: whether to emit detailed solver output</li><li><code>max_iter::Int</code>: maximum number of iterations</li><li><code>max_wall_time::Float64</code>: maximum wall time in seconds</li></ul><p><strong>Returns</strong></p><p>A NamedTuple with fields:</p><ul><li><code>benchmark</code>: full benchmark object from <code>@btimed</code> (CPU) or <code>CUDA.@timed</code> (GPU)</li><li><code>objective::Union{Float64, Missing}</code>: objective function value (missing if failed)</li><li><code>iterations::Union{Int, Missing}</code>: number of solver iterations (missing if failed)</li><li><code>status::Any</code>: termination status (type depends on solver/model)</li><li><code>success::Bool</code>: whether the solve succeeded</li><li><code>criterion::Union{String, Missing}</code>: optimization sense (<code>&quot;min&quot;</code> or <code>&quot;max&quot;</code>, missing if failed)</li><li><code>solution::Union{Any, Missing}</code>: the solution object (JuMP model or OCP solution, missing if failed)</li></ul><p><strong>Details</strong></p><p><strong>Model-specific logic</strong>:</p><ul><li><strong>JuMP</strong> (<code>:jump</code>): Uses <code>@btimed</code> for CPU benchmarking, requires <code>:trapeze</code> discretization</li><li><strong>GPU</strong> (<code>:exa_gpu</code>): Uses <code>CUDA.@timed</code> for GPU benchmarking, requires MadNLP solver and functional CUDA</li><li><strong>OptimalControl</strong> (<code>:adnlp</code>, <code>:exa</code>): Uses <code>@btimed</code> for CPU benchmarking with OptimalControl backend</li></ul><p><strong>Solver configuration</strong>:</p><ul><li><strong>Ipopt</strong>: Configured with MUMPS linear solver, mu strategy, and second-order barrier</li><li><strong>MadNLP</strong>: Configured with MUMPS linear solver</li></ul><p><strong>Print level adjustment</strong>: The solver print level is reduced after the first iteration to avoid excessive output during benchmarking (controlled by the <code>ITERATION</code> counter).</p><p><strong>Error handling</strong>: If any solve fails, returns a NamedTuple with <code>success=false</code> and missing values for objective, iterations, and solution, allowing batch processing to continue.</p><p><strong>Throws</strong></p><ul><li><code>AssertionError</code>: If GPU model is used without MadNLP, without functional CUDA, if JuMP model uses non-trapeze discretization, or if Ipopt is used without mu_strategy.</li></ul></div></section></details></article><h2 id="strip_benchmark_value"><a class="docs-heading-anchor" href="#strip_benchmark_value"><code>strip_benchmark_value</code></a><a id="strip_benchmark_value-1"></a><a class="docs-heading-anchor-permalink" href="#strip_benchmark_value" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.strip_benchmark_value"><a class="docstring-binding" href="#CTBenchmarks.strip_benchmark_value"><code>CTBenchmarks.strip_benchmark_value</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">strip_benchmark_value(bench) -&gt; NamedTuple
</code></pre><p>Remove the <code>value</code> field from benchmark outputs (NamedTuple or Dict) to ensure JSON-serializable data while preserving all other statistics.</p><p>The <code>value</code> field typically contains the actual return value from the benchmarked code, which may not be JSON-serializable. This function strips it out while keeping timing, memory allocation, and other benchmark statistics intact.</p><p><strong>Arguments</strong></p><ul><li><code>bench</code>: Benchmark output (NamedTuple, Dict, or other type)</li></ul><p><strong>Returns</strong></p><ul><li>Same type as input, with <code>value</code> field removed (if present)</li></ul><p><strong>Details</strong></p><p>Three methods are provided:</p><ul><li><strong>Default</strong>: Returns input unchanged (for types without a <code>value</code> field)</li><li><strong>NamedTuple</strong>: Reconstructs NamedTuple without the <code>:value</code> key</li><li><strong>Dict</strong>: Creates new Dict excluding both <code>:value</code> and <code>&quot;value&quot;</code> keys</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; bench_nt = (time=0.001, alloc=1024, value=42)
(time = 0.001, alloc = 1024, value = 42)

julia&gt; CTBenchmarks.strip_benchmark_value(bench_nt)
(time = 0.001, alloc = 1024)

julia&gt; bench_dict = Dict(&quot;time&quot; =&gt; 0.001, &quot;value&quot; =&gt; 42)
Dict{String, Float64} with 2 entries:
  &quot;time&quot;  =&gt; 0.001
  &quot;value&quot; =&gt; 42

julia&gt; CTBenchmarks.strip_benchmark_value(bench_dict)
Dict{String, Float64} with 1 entry:
  &quot;time&quot; =&gt; 0.001</code></pre></div></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="public.html">« Public</a><a class="docs-footer-nextpage" href="../add_benchmark.html">Add a New Benchmark »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 8 January 2026 16:12">Thursday 8 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
