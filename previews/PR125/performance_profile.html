<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Profile · CTBenchmarks</title><meta name="title" content="Performance Profile · CTBenchmarks"/><meta property="og:title" content="Performance Profile · CTBenchmarks"/><meta property="twitter:title" content="Performance Profile · CTBenchmarks"/><meta name="description" content="Documentation for CTBenchmarks."/><meta property="og:description" content="Documentation for CTBenchmarks."/><meta property="twitter:description" content="Documentation for CTBenchmarks."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script><link href="https://control-toolbox.org/assets/css/documentation.css" rel="stylesheet" type="text/css"/><script src="https://control-toolbox.org/assets/js/documentation.js"></script><script src="assets/js/ctbenchmarks-details.js"></script><link href="assets/css/ctbenchmarks-details.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">CTBenchmarks</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Introduction</a></li><li class="is-active"><a class="tocitem" href="performance_profile.html">Performance Profile</a><ul class="internal"><li><a class="tocitem" href="#The-General-Concept"><span>The General Concept</span></a></li><li><a class="tocitem" href="#Performance-Profiles-in-CTBenchmarks.jl"><span>Performance Profiles in CTBenchmarks.jl</span></a></li><li><a class="tocitem" href="#Optimal-Control-and-Discretization"><span>Optimal Control and Discretization</span></a></li><li><a class="tocitem" href="#Example:-Performance-Profile-Plot"><span>Example: Performance Profile Plot</span></a></li><li><a class="tocitem" href="#Interpreting-Performance-Profiles"><span>Interpreting Performance Profiles</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><span class="tocitem">Core benchmarks</span><ul><li><a class="tocitem" href="core/cpu.html">CPU</a></li><li><a class="tocitem" href="core/gpu.html">GPU</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Problems</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="core/problems/beam.html">beam</a></li><li><a class="tocitem" href="core/problems/chain.html">chain</a></li><li><a class="tocitem" href="core/problems/double_oscillator.html">double_oscillator</a></li><li><a class="tocitem" href="core/problems/electric_vehicle.html">electric_vehicle</a></li><li><a class="tocitem" href="core/problems/glider.html">glider</a></li><li><a class="tocitem" href="core/problems/insurance.html">insurance</a></li><li><a class="tocitem" href="core/problems/jackson.html">jackson</a></li><li><a class="tocitem" href="core/problems/robbins.html">robbins</a></li><li><a class="tocitem" href="core/problems/robot.html">robot</a></li><li><a class="tocitem" href="core/problems/rocket.html">rocket</a></li><li><a class="tocitem" href="core/problems/space_shuttle.html">space_shuttle</a></li><li><a class="tocitem" href="core/problems/steering.html">steering</a></li><li><a class="tocitem" href="core/problems/vanderpol.html">vanderpol</a></li></ul></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="api/public.html">Public</a></li><li><a class="tocitem" href="api/private.html">Private</a></li></ul></li><li><span class="tocitem">Developers Guidelines</span><ul><li><a class="tocitem" href="add_benchmark.html">Add a New Benchmark</a></li><li><a class="tocitem" href="documentation_process.html">Documentation Process</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="performance_profile.html">Performance Profile</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="performance_profile.html">Performance Profile</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/control-toolbox/CTBenchmarks.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="performance-profiles"><a class="docs-heading-anchor" href="#performance-profiles">Performance Profiles</a><a id="performance-profiles-1"></a><a class="docs-heading-anchor-permalink" href="#performance-profiles" title="Permalink"></a></h1><p>Performance profiles are a powerful visualization tool for comparing the performance of multiple algorithms (or solver-model combinations) across a set of test problems. They were introduced by Dolan and Moré in 2002<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1" class="footnote-ref">[1]</a><span class="footnote-preview" id="fn-1"></span></sup> and have become a standard method for benchmarking optimization software.</p><p>This page explains:</p><ul><li>The general concept of performance profiles</li><li>How they are adapted in CTBenchmarks.jl</li><li>How to interpret the resulting plots</li></ul><hr/><h2 id="The-General-Concept"><a class="docs-heading-anchor" href="#The-General-Concept">The General Concept</a><a id="The-General-Concept-1"></a><a class="docs-heading-anchor-permalink" href="#The-General-Concept" title="Permalink"></a></h2><h3 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h3><p>Traditional benchmarking efforts often involve extensive tables displaying solver performance on various metrics. However, these tables face inherent challenges:</p><ul><li>The sheer volume of data becomes overwhelming, especially for large test sets</li><li>Interpretation of results frequently leads to disagreements</li><li>A small subset of problems can dominate the conclusions</li></ul><p>Performance profiles address these issues by using <strong>performance ratios</strong> rather than raw metrics, offering insights into the percent improvement of a solver&#39;s metric compared to the best solver.</p><h3 id="Mathematical-Definition"><a class="docs-heading-anchor" href="#Mathematical-Definition">Mathematical Definition</a><a id="Mathematical-Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Definition" title="Permalink"></a></h3><p>Consider:</p><ul><li>A set of <strong>solvers</strong> <span>$S$</span> (or solver-model combinations)</li><li>A set of <strong>problems</strong> <span>$P$</span></li><li>A <strong>performance metric</strong> <span>$t_{p,s}$</span> for each solver <span>$s \in S$</span> on problem <span>$p \in P$</span></li></ul><p>The metric must be a positive value where <strong>smaller is better</strong> (e.g., CPU time, number of iterations).</p><h4 id="Performance-Ratio"><a class="docs-heading-anchor" href="#Performance-Ratio">Performance Ratio</a><a id="Performance-Ratio-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Ratio" title="Permalink"></a></h4><p>The <strong>performance ratio</strong> <span>$r_{p,s}$</span> of solver <span>$s$</span> on problem <span>$p$</span> is defined as:</p><p class="math-container">\[r_{p,s} := \frac{t_{p,s}}{\min_{s&#39; \in S} t_{p,s&#39;}}\]</p><p>where <span>$t_{p,s}$</span> is the value of the chosen metric for solver <span>$s$</span> on problem <span>$p$</span>.</p><p>Key properties:</p><ul><li>We have <span>$r_{p,s} \geq 1$</span> by definition</li><li>Having <span>$r_{p,s} = 1$</span> means that solver <span>$s$</span> achieved the best performance on problem <span>$p$</span></li><li>When a solver <strong>fails</strong> to solve a problem (e.g., reaches maximum time or iteration limit), we assign <span>$r_{p,s} = +\infty$</span></li></ul><h4 id="Performance-Profile-Function"><a class="docs-heading-anchor" href="#Performance-Profile-Function">Performance Profile Function</a><a id="Performance-Profile-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Profile-Function" title="Permalink"></a></h4><p>The <strong>performance profile</strong> is the cumulative distribution function for the performance ratio:</p><p class="math-container">\[\rho_s(\tau) := \frac{1}{n_p} \sum_{p \in P} \mathbb{1}_{r_{p,s} \leq \tau}\]</p><p>where:</p><ul><li>the parameter <span>$n_p$</span> is the total number of problems</li><li>the indicator function <span>$\mathbb{1}_X$</span> is defined as <span>$\mathbb{1}_X = 1$</span> if condition <span>$X$</span> is true, and <span>$\mathbb{1}_X = 0$</span> otherwise</li></ul><p>In words, <span>$\rho_s(\tau)$</span> represents <strong>the proportion of problems for which solver <span>$s$</span> has a performance ratio within a factor <span>$\tau$</span> of the best solver</strong>.</p><h3 id="Key-Properties"><a class="docs-heading-anchor" href="#Key-Properties">Key Properties</a><a id="Key-Properties-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Properties" title="Permalink"></a></h3><p>By definition, <span>$\rho_s(\tau)$</span> has several important properties:</p><ol><li><strong>Range</strong>: <span>$0 \leq \rho_s(\tau) \leq 1$</span> for all <span>$\tau$</span></li><li><strong>At <span>$\tau = 1$</span></strong>: The value <span>$\rho_s(1)$</span> gives the <strong>percentage of problems where solver <span>$s$</span> achieved the best performance</strong>. The sum across all solvers may exceed 100% in case of ties.</li><li><strong>Monotonicity</strong>: <span>$\tau \mapsto \rho_s(\tau)$</span> is a <strong>non-decreasing function</strong></li><li><strong>Plateau</strong>: For <span>$\tau$</span> sufficiently large, all solvers should reach a plateau representing <strong>the percentage of problems solved</strong>. If <span>$\rho_s(\tau) &lt; 1$</span> for all <span>$\tau$</span>, solver <span>$s$</span> failed on some problems.</li></ol><hr/><h2 id="Performance-Profiles-in-CTBenchmarks.jl"><a class="docs-heading-anchor" href="#Performance-Profiles-in-CTBenchmarks.jl">Performance Profiles in CTBenchmarks.jl</a><a id="Performance-Profiles-in-CTBenchmarks.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Profiles-in-CTBenchmarks.jl" title="Permalink"></a></h2><h3 id="Adaptation-to-Our-Context"><a class="docs-heading-anchor" href="#Adaptation-to-Our-Context">Adaptation to Our Context</a><a id="Adaptation-to-Our-Context-1"></a><a class="docs-heading-anchor-permalink" href="#Adaptation-to-Our-Context" title="Permalink"></a></h3><p>In CTBenchmarks.jl, we adapt the classical Dolan–Moré definition to our specific benchmark structure:</p><h4 id="Instances"><a class="docs-heading-anchor" href="#Instances">Instances</a><a id="Instances-1"></a><a class="docs-heading-anchor-permalink" href="#Instances" title="Permalink"></a></h4><p>An <strong>instance</strong> is a pair <span>$(\mathrm{problem}, \mathrm{grid\_size})$</span> appearing in the benchmark results, regardless of whether it was successfully solved by any solver.</p><p>For example:</p><ul><li><code>(beam, 100)</code></li><li><code>(beam, 500)</code></li><li><code>(crane, 200)</code></li></ul><p>are three distinct instances.</p><h4 id="Solver-Model-Combinations"><a class="docs-heading-anchor" href="#Solver-Model-Combinations">Solver-Model Combinations</a><a id="Solver-Model-Combinations-1"></a><a class="docs-heading-anchor-permalink" href="#Solver-Model-Combinations" title="Permalink"></a></h4><p>A <strong>solver-model combination</strong> <span>$s$</span> is identified by the pair <code>(model, solver)</code>.</p><p>For example:</p><ul><li><code>(JuMP, Ipopt)</code></li><li><code>(ADNLPModels, Ipopt)</code></li><li><code>(ExaModels, MadNLP)</code></li></ul><p>are three distinct solver-model combinations.</p><h3 id="Performance-Metric"><a class="docs-heading-anchor" href="#Performance-Metric">Performance Metric</a><a id="Performance-Metric-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Metric" title="Permalink"></a></h3><p>For each instance <span>$p = (\mathrm{problem}, \mathrm{grid\_size})$</span> and solver-model <span>$s$</span>:</p><ol><li><p>If the run <span>$(p, s)$</span> has <code>success == true</code> and a valid benchmark object, we extract the <strong>CPU wall time</strong>:</p><p class="math-container">\[t_{p,s} = \text{benchmark[&quot;time&quot;]}\]</p></li><li><p>Among all solver-models that succeeded on instance <span>$p$</span>, we compute the <strong>best (minimal) time</strong>:</p><p class="math-container">\[t_p^* = \min_{s&#39; \in S} t_{p,s&#39;}\]</p></li><li><p>For every successful run <span>$(p, s)$</span>, we define the <strong>performance ratio</strong>:</p><p class="math-container">\[r_{p,s} = \frac{t_{p,s}}{t_p^*} \geq 1\]</p></li><li><p>Instances where solver-model <span>$s$</span> <strong>failed</strong> (or has no valid timing) are treated as having <span>$r_{p,s} = +\infty$</span></p></li></ol><h3 id="Performance-Profile-Definition"><a class="docs-heading-anchor" href="#Performance-Profile-Definition">Performance Profile Definition</a><a id="Performance-Profile-Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Profile-Definition" title="Permalink"></a></h3><p>The performance profile of each solver-model combination <span>$s$</span> is:</p><p class="math-container">\[\rho_s(\tau) = \frac{1}{N} \cdot \#\{ \text{instances } p : r_{p,s} \leq \tau \}\]</p><p>where <span>$N$</span> is the <strong>total number of distinct <span>$(\mathrm{problem}, \mathrm{grid\_size})$</span> instances</strong> present in the JSON file, <strong>including those where all solvers failed</strong>.</p><h3 id="Treatment-of-Failures"><a class="docs-heading-anchor" href="#Treatment-of-Failures">Treatment of Failures</a><a id="Treatment-of-Failures-1"></a><a class="docs-heading-anchor-permalink" href="#Treatment-of-Failures" title="Permalink"></a></h3><p>This definition has important consequences:</p><ul><li><p>Only instances with <code>success == true</code> and valid timing contribute ratios <span>$r_{p,s}$</span> and can increase <span>$\rho_s(\tau)$</span></p></li><li><p>Instances where a given solver-model <strong>fails</strong> are counted in <span>$N$</span> but never in the numerator for that solver-model</p></li><li><p>Instances where <strong>all</strong> solver-models fail are still included in <span>$N$</span> but do not contribute any <span>$r_{p,s}$</span> for any solver-model</p></li></ul><p><strong>Consequence</strong>: If there exist problem-grid instances that are not solved by a given solver-model combination, its curve <span>$\rho_s(\tau)$</span> will <strong>plateau strictly below 1</strong> (100%). If some instances are unsolved by <em>all</em> solver-models, then <strong>no curve can reach 1</strong>, clearly indicating that there are problems for which none of the tested approaches succeeded.</p><hr/><h3 id="Implementation-overview"><a class="docs-heading-anchor" href="#Implementation-overview">Implementation overview</a><a id="Implementation-overview-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-overview" title="Permalink"></a></h3><p>In the implementation, CTBenchmarks.jl separates the <em>definition</em> of a performance profile from its <em>computation</em> and <em>visualization</em>.</p><ul><li><code>ProfileCriterion{M}</code> describes the metric:<ul><li>a human-readable <code>name</code>,</li><li>a function <code>row::DataFrameRow -&gt; M</code> extracting the metric value from each benchmark row,</li><li>a comparison <code>better(a::M, b::M)</code> indicating when <code>a</code> is strictly better than <code>b</code> (e.g., <code>a &lt;= b</code> for a time or iteration count).</li></ul></li><li><code>PerformanceProfileConfig{M}</code> describes how to build a profile from a table of benchmark results:<ul><li><code>instance_cols</code>: columns that define an <strong>instance</strong> (in this documentation: <code>[:problem, :grid_size]</code>),</li><li><code>solver_cols</code>: columns that define a <strong>solver combination</strong> (here: <code>[:model, :solver]</code>),</li><li><code>criterion</code>: the <code>ProfileCriterion{M}</code> to use,</li><li><code>is_success</code>: predicate selecting <strong>successful runs</strong>,</li><li><code>row_filter</code>: additional filtering (e.g., by hardware or scenario),</li><li><code>aggregate</code>: how to aggregate multiple runs of the same (instance, solver combination) into a single metric value.</li></ul></li><li><code>PerformanceProfile{M}</code> is an immutable structure that stores:<ul><li>the benchmark identifier,</li><li>all instances and successful runs with their performance ratios,</li><li>the list of solver combinations and the Dolan–Moré ratio bounds,</li><li>the <code>PerformanceProfileConfig{M}</code> that was used to construct it.</li></ul></li></ul><p>The main profiles used in this documentation are defined by two configurations:</p><ul><li><p><strong>CPU-time profile</strong> (default time-based profile)</p><ul><li>instances: <code>(problem, grid_size)</code>,</li><li>solver combinations: <code>(model, solver)</code>,</li><li>criterion: <em>CPU time</em>, using the <code>benchmark[&quot;time&quot;]</code> field,</li><li>successful runs: those with <code>success == true</code> and a valid benchmark object,</li><li>aggregation: mean CPU time over repeated runs of the same (instance, solver combination).</li></ul></li><li><p><strong>Iterations profile</strong> (iteration-based profile)</p><ul><li>instances: <code>(problem, grid_size)</code>,</li><li>solver combinations: <code>(model, solver)</code>,</li><li>criterion: <em>Iterations</em>, using the <code>iterations</code> field recorded in benchmark results,</li><li>successful runs: those with <code>success == true</code> and a valid, non-missing <code>iterations</code> count,</li><li>aggregation: mean number of iterations over repeated runs of the same (instance, solver combination).</li></ul></li></ul><p>The corresponding Julia functions are:</p><ul><li><code>compute_profile_default_cpu(bench_id, src_dir)</code> and <code>compute_profile_default_iter(bench_id, src_dir)</code>, which build <code>PerformanceProfile{Float64}</code> objects using the respective configurations,</li><li><code>_plot_profile_default_cpu(bench_id, src_dir)</code> and <code>_plot_profile_default_iter(bench_id, src_dir)</code>, which call <code>plot_performance_profile</code> to generate the figures,</li><li><code>_analyze_profile_default_cpu(bench_id, src_dir)</code> and <code>_analyze_profile_default_iter(bench_id, src_dir)</code>, which call <code>analyze_performance_profile</code> to produce the textual summaries.</li></ul><p>In addition to the plot, CTBenchmarks.jl provides an automatic textual analysis generated by <code>_analyze_profile_default_cpu(bench_id)</code> (used via <code>INCLUDE_TEXT</code> blocks in the documentation). This analysis is computed from the performance profile data.</p><hr/><h2 id="Optimal-Control-and-Discretization"><a class="docs-heading-anchor" href="#Optimal-Control-and-Discretization">Optimal Control and Discretization</a><a id="Optimal-Control-and-Discretization-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-Control-and-Discretization" title="Permalink"></a></h2><h3 id="What-are-Optimal-Control-Problems?"><a class="docs-heading-anchor" href="#What-are-Optimal-Control-Problems?">What are Optimal Control Problems?</a><a id="What-are-Optimal-Control-Problems?-1"></a><a class="docs-heading-anchor-permalink" href="#What-are-Optimal-Control-Problems?" title="Permalink"></a></h3><p>The benchmarks in CTBenchmarks.jl are based on <strong>optimal control problems (OCPs)</strong> from the <a href="https://control-toolbox.org/OptimalControlProblems.jl/stable/">OptimalControlProblems.jl</a> package. An optimal control problem with fixed initial and final times consists of minimizing a cost functional (in Bolza form):</p><p class="math-container">\[J(x, u) = g(x(t_0), x(t_f)) + \int_{t_0}^{t_f} f^{0}(t, x(t), u(t))~\mathrm{d}t\]</p><p>where:</p><ul><li>the variable <span>$x(t)$</span> is the <strong>state</strong> trajectory (e.g., position, velocity)</li><li>the variable <span>$u(t)$</span> is the <strong>control</strong> input (e.g., force, torque)</li><li>the function <span>$g$</span> is the <strong>Mayer cost</strong> (terminal cost)</li><li>the function <span>$f^0$</span> is the <strong>Lagrange cost</strong> (running cost)</li><li>the variable <span>$t \in [t_0, t_f]$</span> is the time interval</li></ul><p>The state and control must satisfy the <strong>dynamics constraint</strong>:</p><p class="math-container">\[\dot{x}(t) = f(t, x(t), u(t))\]</p><p>and possibly other constraints:</p><p class="math-container">\[\begin{array}{llcll}
x_{\mathrm{lower}} &amp; \le &amp; x(t) &amp; \le &amp; x_{\mathrm{upper}}, &amp; \text{(state box constraints)} \\
u_{\mathrm{lower}} &amp; \le &amp; u(t) &amp; \le &amp; u_{\mathrm{upper}}, &amp; \text{(control box constraints)} \\
c_{\mathrm{lower}} &amp; \le &amp; c(t, x(t), u(t)) &amp; \le &amp; c_{\mathrm{upper}}, &amp; \text{(path constraints)} \\
b_{\mathrm{lower}} &amp; \le &amp; b(x(t_0), x(t_f)) &amp; \le &amp; b_{\mathrm{upper}}. &amp; \text{(boundary constraints)}
\end{array}\]</p><p><strong>Cost types</strong>:</p><ul><li><strong>Mayer</strong>: Only terminal cost (<span>$f^0 = 0$</span>)</li><li><strong>Lagrange</strong>: Only integral cost (<span>$g = 0$</span>)</li><li><strong>Bolza</strong>: Both terminal and integral costs</li></ul><h3 id="The-Direct-Method:-From-OCP-to-NLP"><a class="docs-heading-anchor" href="#The-Direct-Method:-From-OCP-to-NLP">The Direct Method: From OCP to NLP</a><a id="The-Direct-Method:-From-OCP-to-NLP-1"></a><a class="docs-heading-anchor-permalink" href="#The-Direct-Method:-From-OCP-to-NLP" title="Permalink"></a></h3><p>The <strong>direct method</strong> transforms the infinite-dimensional optimal control problem into a finite-dimensional <strong>nonlinear programming problem (NLP)</strong> by discretizing time. This approach is:</p><ul><li><strong>More robust</strong> with respect to initialization than indirect methods (Pontryagin&#39;s Maximum Principle)</li><li><strong>Easier to apply</strong>, which explains its widespread use in industrial applications</li><li><strong>Less precise</strong> than indirect methods, but sufficient for many practical purposes</li></ul><h4 id="Discretization-Scheme"><a class="docs-heading-anchor" href="#Discretization-Scheme">Discretization Scheme</a><a id="Discretization-Scheme-1"></a><a class="docs-heading-anchor-permalink" href="#Discretization-Scheme" title="Permalink"></a></h4><p>In OptimalControlProblems.jl, every OCP is discretized using the <strong>trapezoidal rule</strong> on a uniform grid with <span>$N$</span> steps:</p><p class="math-container">\[\begin{array}{lclr}
t \in [t_0,t_f] &amp; \to &amp; t_0 &lt; t_1 &lt; \dots &lt; t_N=t_f, \text{ with } t_{i}-t_{i-1} = \frac{t_f-t_0}{N}, &amp; i = 1:N \\[0.5em]
x(\cdot),\, u(\cdot) &amp; \to &amp; X=\{x_0, \ldots, x_N, u_0, \ldots, u_N\} &amp; \\[1em]
\hline \\
\text{step} &amp; \to &amp; \displaystyle h = \frac{t_f-t_0}{N} &amp; \\[0.5em]
\text{criterion} &amp; \to &amp; \displaystyle g(x_0, x_N) + \frac{h}{2} \sum_{i=1}^{N} \left( f^0(t_i, x_i, u_i) + f^0(t_{i-1}, x_{i-1}, u_{i-1}) \right) &amp; \\[1em]
\text{dynamics} &amp; \to &amp; \displaystyle x_{i} = x_{i-1} + \frac{h}{2} \left( f(t_i, x_i, u_i) + f(t_{i-1}, x_{i-1}, u_{i-1}) \right), &amp; i = 1:N \\[1em]
\text{state constraints} &amp; \to &amp; x_{\mathrm{lower}} \le x_i \le x_{\mathrm{upper}}, &amp; i = 0:N \\[1em]
\text{control constraints} &amp; \to &amp; u_{\mathrm{lower}} \le u_i \le u_{\mathrm{upper}}, &amp; i = 0:N \\[1em]
\text{path constraints} &amp; \to &amp; c_{\mathrm{lower}} \le c(t_i, x_i, u_i) \le c_{\mathrm{upper}}, &amp; i = 0:N \\[1em]
\text{boundary constraints} &amp; \to &amp; b_{\mathrm{lower}} \le b(x_0, x_N) \le b_{\mathrm{upper}} &amp;
\end{array}\]</p><p>This yields a standard NLP of the form:</p><p class="math-container">\[\text{(NLP)} \quad \left\{ \begin{array}{lr}
\min \  F(X) \\[1em]
X_{\mathrm{lower}} \le X \le X_{\mathrm{upper}}\\[0.5em]
C_{\mathrm{lower}} \le C(X) \le C_{\mathrm{upper}}
\end{array} \right.\]</p><p>where <span>$X$</span> contains all discretized state and control variables, and <span>$C(X)$</span> represents the discretized dynamics and constraints.</p><h3 id="Grid-Size-and-Problem-Instances"><a class="docs-heading-anchor" href="#Grid-Size-and-Problem-Instances">Grid Size and Problem Instances</a><a id="Grid-Size-and-Problem-Instances-1"></a><a class="docs-heading-anchor-permalink" href="#Grid-Size-and-Problem-Instances" title="Permalink"></a></h3><p>The <strong>grid size</strong> <span>$N$</span> (number of discretization steps) is a crucial parameter:</p><ul><li><strong>Smaller <span>$N$</span></strong>: Faster to solve, but less accurate approximation of the continuous problem</li><li><strong>Larger <span>$N$</span></strong>: More accurate, but computationally more expensive</li></ul><p>In CTBenchmarks.jl, we benchmark each optimal control problem at <strong>multiple grid sizes</strong> to assess:</p><ul><li><strong>Scalability</strong>: How does solver performance degrade as <span>$N$</span> increases?</li><li><strong>Accuracy vs. speed trade-offs</strong>: Which solver-model combinations are efficient for coarse/fine grids?</li></ul><p>This is why an <strong>instance</strong> is defined as a pair <span>$(\mathrm{problem}, \mathrm{grid\_size})$</span>: the same optimal control problem discretized with different <span>$N$</span> values represents different computational challenges.</p><h3 id="Available-Optimal-Control-Problems"><a class="docs-heading-anchor" href="#Available-Optimal-Control-Problems">Available Optimal Control Problems</a><a id="Available-Optimal-Control-Problems-1"></a><a class="docs-heading-anchor-permalink" href="#Available-Optimal-Control-Problems" title="Permalink"></a></h3><p>The <a href="https://control-toolbox.org/OptimalControlProblems.jl/stable/">OptimalControlProblems.jl</a> package provides a curated collection of optimal control problems from the literature. Each problem is modeled in two ways:</p><ol><li><strong>JuMP models</strong>: Direct NLP formulation using <a href="https://jump.dev/">JuMP.jl</a></li><li><strong>OptimalControl models</strong>: High-level OCP description using <a href="https://control-toolbox.org/OptimalControl.jl/stable/">OptimalControl.jl</a>, with automatic discretization via <a href="https://control-toolbox.org/CTDirect.jl/stable/">CTDirect.jl</a></li></ol><p><strong>Examples of problems</strong> (see the <a href="https://control-toolbox.org/OptimalControlProblems.jl/stable/problems_browser.html">problems browser</a> for the complete list):</p><ul><li><strong>Beam</strong>: Minimize vibrations in a flexible beam</li><li><strong>Chain</strong>: Hanging chain with control forces</li><li><strong>Double oscillator</strong>: Coupled oscillators with control</li><li><strong>Goddard</strong>: Rocket ascent problem (maximize altitude)</li><li><strong>Robot</strong>: Robot arm trajectory optimization</li><li><strong>Steering</strong>: Vehicle steering with obstacle avoidance</li><li><strong>Vanderpol</strong>: Van der Pol oscillator control</li></ul><p>Each problem has specific characteristics:</p><ul><li><strong>State dimension</strong>: Number of state variables (e.g., position, velocity)</li><li><strong>Control dimension</strong>: Number of control inputs</li><li><strong>Cost type</strong>: Mayer, Lagrange, or Bolza</li><li><strong>Constraints</strong>: Which types of constraints are present (state, control, path, boundary)</li></ul><p>You can explore all problems interactively in the <a href="https://control-toolbox.org/OptimalControlProblems.jl/stable/problems_browser.html">problems browser</a>, which allows filtering by:</p><ul><li>Number of state/control variables</li><li>Cost type (Mayer, Lagrange, Bolza)</li><li>Constraint types (state, control, path, boundary)</li><li>Final time (fixed or free)</li></ul><h3 id="Models-and-Solvers"><a class="docs-heading-anchor" href="#Models-and-Solvers">Models and Solvers</a><a id="Models-and-Solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Models-and-Solvers" title="Permalink"></a></h3><p>In CTBenchmarks.jl, a <strong>model</strong> refers to the Julia package used to formulate the NLP:</p><ul><li><strong>JuMP</strong>: <a href="https://jump.dev/">JuMP.jl</a> with automatic differentiation</li><li><strong>ADNLPModels</strong>: <a href="https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl">ADNLPModels.jl</a> with automatic differentiation</li><li><strong>ExaModels</strong>: <a href="https://github.com/exanauts/ExaModels.jl">ExaModels.jl</a> for GPU-accelerated modeling</li><li><strong>OptimalControl</strong>: <a href="https://control-toolbox.org/OptimalControl.jl/stable/">OptimalControl.jl</a> with <a href="https://control-toolbox.org/CTDirect.jl/stable/">CTDirect.jl</a> for direct transcription</li></ul><p>A <strong>solver</strong> is the optimization algorithm used to solve the NLP:</p><ul><li><strong>Ipopt</strong>: <a href="https://github.com/jump-dev/Ipopt.jl">Ipopt.jl</a> (interior-point method)</li><li><strong>MadNLP</strong>: <a href="https://github.com/MadNLP/MadNLP.jl">MadNLP.jl</a> (interior-point method, GPU-capable)</li></ul><p>Different <strong>model-solver combinations</strong> can have vastly different performance characteristics:</p><ul><li><strong>Modeling overhead</strong>: Time to build the NLP (automatic differentiation, sparsity detection)</li><li><strong>Solver efficiency</strong>: Time to solve the NLP (linear algebra, convergence rate)</li><li><strong>Memory usage</strong>: RAM and GPU memory requirements</li><li><strong>Scalability</strong>: Performance on large-scale problems (large <span>$N$</span>)</li></ul><hr/><h2 id="Example:-Performance-Profile-Plot"><a class="docs-heading-anchor" href="#Example:-Performance-Profile-Plot">Example: Performance Profile Plot</a><a id="Example:-Performance-Profile-Plot-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Performance-Profile-Plot" title="Permalink"></a></h2><p>The following figure shows a typical performance profile from CTBenchmarks.jl, comparing 6 solver-model combinations on a set of optimal control problems with varying grid sizes.</p><p><img src="assets/figs/performance_profile_example.svg" alt="Performance Profile Example"/></p><h3 id="Reading-This-Example"><a class="docs-heading-anchor" href="#Reading-This-Example">Reading This Example</a><a id="Reading-This-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Reading-This-Example" title="Permalink"></a></h3><p>In this plot:</p><ul><li><p><strong>6 solver-model combinations</strong> are compared:</p><ul><li><code>(ADNLPModels, Ipopt)</code> (blue circles)</li><li><code>(ADNLPModels, MadNLP)</code> (green diamonds)</li><li><code>(ExaModels, Ipopt)</code> (red squares)</li><li><code>(ExaModels, MadNLP)</code> (orange triangles)</li><li><code>(JuMP, Ipopt)</code> (purple inverted triangles)</li><li><code>(JuMP, MadNLP)</code> (brown stars)</li></ul></li><li><p><strong>Multiple problem instances</strong>: Each curve represents performance across all <span>$(\mathrm{problem}, \mathrm{grid\_size})$</span> pairs tested</p></li></ul><p><strong>Key observations</strong>:</p><ol><li><p><strong>At <span>$\tau = 1$</span></strong> (leftmost):</p><ul><li><code>(ExaModels, Ipopt)</code> (red) is the fastest on ~25% of instances</li><li><code>(ExaModels, MadNLP)</code> (orange) is the fastest on ~20% of instances</li><li>No single combination dominates all instances</li></ul></li><li><p><strong>At <span>$\tau = 2$</span></strong>:</p><ul><li><code>(ExaModels, Ipopt)</code> (red) solves ~60% of instances within 2× the best time</li><li><code>(ExaModels, MadNLP)</code> (orange) solves ~70% of instances within 2× the best time</li></ul></li><li><p><strong>Plateaus</strong> (rightmost):</p><ul><li><code>(ExaModels, MadNLP)</code> (orange) reaches ~75%, indicating it solved 75% of all instances</li><li><code>(ADNLPModels, Ipopt)</code> (blue) reaches ~80%</li><li><code>(ADNLPModels, MadNLP)</code> (green) reaches ~75%</li><li><code>(JuMP, Ipopt)</code> (purple) reaches ~70%</li><li>Some combinations fail on 20-30% of instances</li></ul></li><li><p><strong>Trade-offs</strong>:</p><ul><li><strong>ExaModels combinations</strong> are often fastest when they succeed, but have lower robustness</li><li><strong>ADNLPModels + Ipopt</strong> is more robust (80% success) but rarely the fastest</li><li><strong>JuMP combinations</strong> show intermediate performance</li></ul></li></ol><p><strong>Interpretation</strong>: There is no clear winner. The choice of solver-model combination depends on your priorities:</p><ul><li>For <strong>maximum robustness</strong>: Choose <code>(ADNLPModels, Ipopt)</code></li><li>For <strong>speed on easy problems</strong>: Choose <code>(ExaModels, Ipopt)</code> or <code>(ExaModels, MadNLP)</code></li><li>For <strong>balanced performance</strong>: Consider <code>(ADNLPModels, MadNLP)</code> or <code>(JuMP, Ipopt)</code></li></ul><p>This example illustrates why performance profiles are valuable: they reveal the <strong>full spectrum of performance</strong> (efficiency, robustness, scalability) in a single plot, enabling informed decisions based on your specific requirements.</p><hr/><h2 id="Interpreting-Performance-Profiles"><a class="docs-heading-anchor" href="#Interpreting-Performance-Profiles">Interpreting Performance Profiles</a><a id="Interpreting-Performance-Profiles-1"></a><a class="docs-heading-anchor-permalink" href="#Interpreting-Performance-Profiles" title="Permalink"></a></h2><h3 id="Visual-Elements"><a class="docs-heading-anchor" href="#Visual-Elements">Visual Elements</a><a id="Visual-Elements-1"></a><a class="docs-heading-anchor-permalink" href="#Visual-Elements" title="Permalink"></a></h3><p>A typical performance profile plot shows:</p><ul><li><p><strong>X-axis</strong>: Performance ratio <span>$\tau$</span> (log scale, base 2)</p><ul><li>Values like 1, 2, 4, 10, 50, 100</li><li>Factor by which a solver is slower than the best</li></ul></li><li><p><strong>Y-axis</strong>: Proportion of solved instances <span>$\rho_s(\tau)$</span> (linear scale, 0 to 1)</p><ul><li>Displayed as percentages: 0%, 10%, ..., 100%</li></ul></li><li><p><strong>Curves</strong>: One curve per solver-model combination</p><ul><li>Each curve is piecewise constant and non-decreasing</li><li>Markers help distinguish curves</li></ul></li></ul><h3 id="Reading-the-Plot"><a class="docs-heading-anchor" href="#Reading-the-Plot">Reading the Plot</a><a id="Reading-the-Plot-1"></a><a class="docs-heading-anchor-permalink" href="#Reading-the-Plot" title="Permalink"></a></h3><h4 id="At-\\tau-1-(leftmost-point)"><a class="docs-heading-anchor" href="#At-\\tau-1-(leftmost-point)">At <span>$\tau = 1$</span> (leftmost point)</a><a id="At-\\tau-1-(leftmost-point)-1"></a><a class="docs-heading-anchor-permalink" href="#At-\\tau-1-(leftmost-point)" title="Permalink"></a></h4><p>The height of a curve at <span>$\tau = 1$</span> indicates <strong>the proportion of instances where that solver-model was the fastest</strong>.</p><p>Example:</p><ul><li>If <code>(JuMP, Ipopt)</code> has <span>$\rho(\tau=1) = 0.6$</span>, it means JuMP+Ipopt was the fastest on 60% of instances</li></ul><h4 id="At-intermediate-\\tau"><a class="docs-heading-anchor" href="#At-intermediate-\\tau">At intermediate <span>$\tau$</span></a><a id="At-intermediate-\\tau-1"></a><a class="docs-heading-anchor-permalink" href="#At-intermediate-\\tau" title="Permalink"></a></h4><p>The height at <span>$\tau = 2$</span> indicates <strong>the proportion of instances where that solver-model was within a factor 2 of the best</strong>.</p><p>Example:</p><ul><li>If <code>(ADNLPModels, Ipopt)</code> has <span>$\rho(\tau=2) = 0.8$</span>, it means ADNLPModels+Ipopt solved 80% of instances within twice the time of the best solver</li></ul><h4 id="Plateau-(rightmost-part)"><a class="docs-heading-anchor" href="#Plateau-(rightmost-part)">Plateau (rightmost part)</a><a id="Plateau-(rightmost-part)-1"></a><a class="docs-heading-anchor-permalink" href="#Plateau-(rightmost-part)" title="Permalink"></a></h4><p>The plateau represents <strong>the proportion of instances successfully solved</strong> by that solver-model, regardless of performance.</p><p>Example:</p><ul><li>If <code>(ExaModels, MadNLP)</code> plateaus at 0.95, it means ExaModels+MadNLP solved 95% of all instances (but failed on 5%)</li></ul><h3 id="Common-Patterns"><a class="docs-heading-anchor" href="#Common-Patterns">Common Patterns</a><a id="Common-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#Common-Patterns" title="Permalink"></a></h3><h4 id="Pattern-1:-Clear-Winner"><a class="docs-heading-anchor" href="#Pattern-1:-Clear-Winner">Pattern 1: Clear Winner</a><a id="Pattern-1:-Clear-Winner-1"></a><a class="docs-heading-anchor-permalink" href="#Pattern-1:-Clear-Winner" title="Permalink"></a></h4><pre><code class="language-text hljs">Solver A: ρ(1) = 1.0, plateau at 1.0
Solver B: ρ(1) = 0.0, plateau at 1.0</code></pre><p>Solver A was faster on all problems, and both solved all problems. <strong>Solver A is clearly preferable.</strong></p><h4 id="Pattern-2:-Fast-but-Not-Robust"><a class="docs-heading-anchor" href="#Pattern-2:-Fast-but-Not-Robust">Pattern 2: Fast but Not Robust</a><a id="Pattern-2:-Fast-but-Not-Robust-1"></a><a class="docs-heading-anchor-permalink" href="#Pattern-2:-Fast-but-Not-Robust" title="Permalink"></a></h4><pre><code class="language-text hljs">Solver A: ρ(1) = 0.7, plateau at 0.75
Solver B: ρ(1) = 0.3, plateau at 1.0</code></pre><p>Solver A is faster on most problems but fails on 25% of them. Solver B is slower but solves everything. <strong>Trade-off between speed and robustness.</strong></p><h4 id="Pattern-3:-Very-Small-Factors"><a class="docs-heading-anchor" href="#Pattern-3:-Very-Small-Factors">Pattern 3: Very Small Factors</a><a id="Pattern-3:-Very-Small-Factors-1"></a><a class="docs-heading-anchor-permalink" href="#Pattern-3:-Very-Small-Factors" title="Permalink"></a></h4><p>If all curves are very close and differences occur only at <span>$\tau \approx 1.0001$</span>, the solvers are essentially equivalent for practical purposes.</p><h4 id="Pattern-4:-Multiple-Solvers-(2)"><a class="docs-heading-anchor" href="#Pattern-4:-Multiple-Solvers-(2)">Pattern 4: Multiple Solvers (&gt;2)</a><a id="Pattern-4:-Multiple-Solvers-(2)-1"></a><a class="docs-heading-anchor-permalink" href="#Pattern-4:-Multiple-Solvers-(2)" title="Permalink"></a></h4><p>With more than two solvers, performance profiles do not directly establish a complete ranking. A solver may dominate when compared to the full set but not when compared pairwise to another solver<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2" class="footnote-ref">[2]</a><span class="footnote-preview" id="fn-2"></span></sup>.</p><h3 id="What-to-Look-For"><a class="docs-heading-anchor" href="#What-to-Look-For">What to Look For</a><a id="What-to-Look-For-1"></a><a class="docs-heading-anchor-permalink" href="#What-to-Look-For" title="Permalink"></a></h3><p>When analyzing performance profiles in CTBenchmarks.jl:</p><ol><li><strong>Robustness</strong>: Does the curve reach 100%? If not, which problems failed?</li></ol><ul><li><p><strong>Dataset overview</strong></p><ul><li><em>Problems</em>: number of distinct optimal control problems.</li><li><em>Instances</em>: <span>$N = \#\{(\mathrm{problem}, \mathrm{grid\_size})\}$</span>.</li><li><em>Solver combos</em>: <span>$S = \#\{(\mathrm{model}, \mathrm{solver})\}$</span>.</li></ul></li><li><p><strong>Profile configuration</strong></p><ul><li>Printed directly from the stored <code>PerformanceProfileConfig{M}</code>:<ul><li>instance definition (columns used to define an instance),</li><li>solver-combo definition (columns used to define a solver combination),</li><li>name of the criterion (here: CPU time in seconds).</li></ul></li></ul></li><li><p><strong>Successful runs</strong></p><ul><li>A <strong>run</strong> is a pair (instance, solver combination).</li><li><code>Successful runs</code> reports <span>$\#\{(p,s) : \text{run } (p,s) \text{ succeeded}\} / (N \times S)$</span>.</li><li>This is the fraction of the full instance–solver grid for which we have a successful metric value.</li></ul></li><li><p><strong>Successful / unsuccessful instances</strong></p><ul><li>An <strong>instance</strong> is called <em>successful</em> if at least one solver combination succeeded on it.</li><li><code>Successful instances</code> reports <span>$\#\{p : \exists s, \text{run } (p,s) \text{ succeeded}\} / N$</span>.</li><li><code>Unsuccessful instances</code> are those for which <strong>no</strong> solver combination succeeded; they are listed explicitly.</li></ul></li><li><p><strong>Robustness (per solver combination)</strong></p><ul><li>For each solver combination <span>$s$</span>, robustness is <span>$\#\{p : \text{run } (p,s) \text{ succeeded}\} / N$</span>.</li><li>This is the percentage of instances that each solver combination manages to solve at least once.</li></ul></li><li><p><strong>Efficiency (per solver combination)</strong></p><ul><li>For each solver combination <span>$s$</span>, efficiency is <span>$\#\{p : r_{p,s} = 1\} / N$</span>, i.e., the proportion of instances where this solver combination achieves the <strong>best metric</strong> (ratio <span>$r_{p,s} = 1$</span>).</li><li>This corresponds to the height of its performance-profile curve at <span>$\tau = 1$</span>.</li></ul></li><li><p><strong>Most robust / most efficient</strong></p><ul><li>The analysis identifies the solver combination(s) with the highest robustness and the highest efficiency and reports ties explicitly.</li></ul></li></ul><p>Together with the performance-profile plot, this textual analysis helps to separate clearly:</p><ul><li>how often each solver combination <strong>succeeds</strong> (robustness),</li><li>how often it is <strong>best</strong> (efficiency),</li><li>and how many instances are intrinsically difficult (unsuccessful for all combinations).</li></ul><hr/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>See also:</p><ul><li><a href="https://tmigot.github.io/posts/2024/06/teaching">Performance Profile Benchmarking Tool</a> by Tangi Migot</li><li>Moré, J. J., &amp; Wild, S. M. (2009). Benchmarking derivative-free optimization algorithms. <em>SIAM Journal on Optimization</em>, 20(1), 172-191. <a href="https://epubs.siam.org/doi/abs/10.1137/080724083">DOI: 10.1137/080724083</a></li></ul><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Dolan, E. D., &amp; Moré, J. J. (2002). Benchmarking optimization software with performance profiles. <em>Mathematical Programming</em>, 91, 201-213. <a href="https://link.springer.com/article/10.1007/s101070100263">DOI: 10.1007/s101070100263</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Gould, N., &amp; Scott, J. (2016). A note on performance profiles for benchmarking software. <em>ACM Transactions on Mathematical Software (TOMS)</em>, 43(2), 1-5. <a href="https://dl.acm.org/doi/abs/10.1145/2950048">DOI: 10.1145/2950048</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="index.html">« Introduction</a><a class="docs-footer-nextpage" href="core/cpu.html">CPU »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 8 January 2026 16:22">Thursday 8 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
