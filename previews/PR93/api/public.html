<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public · CTBenchmarks</title><meta name="title" content="Public · CTBenchmarks"/><meta property="og:title" content="Public · CTBenchmarks"/><meta property="twitter:title" content="Public · CTBenchmarks"/><meta name="description" content="Documentation for CTBenchmarks."/><meta property="og:description" content="Documentation for CTBenchmarks."/><meta property="twitter:description" content="Documentation for CTBenchmarks."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://control-toolbox.org/assets/css/documentation.css" rel="stylesheet" type="text/css"/><script src="https://control-toolbox.org/assets/js/documentation.js"></script><script src="../assets/js/ctbenchmarks-details.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">CTBenchmarks</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Introduction</a></li><li><span class="tocitem">Core benchmarks</span><ul><li><a class="tocitem" href="../benchmark-core-cpu.html">CPU</a></li><li><a class="tocitem" href="../benchmark-core-gpu.html">GPU</a></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">By Problems</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../benchmark-core-beam.html">Beam</a></li></ul></li></ul></li><li><span class="tocitem">API Reference</span><ul><li class="is-active"><a class="tocitem" href="public.html">Public</a><ul class="internal"><li><a class="tocitem" href="#benchmark"><span><code>benchmark</code></span></a></li><li><a class="tocitem" href="#plot_solutions"><span><code>plot_solutions</code></span></a></li><li><a class="tocitem" href="#run"><span><code>run</code></span></a></li></ul></li><li><a class="tocitem" href="private.html">Private</a></li></ul></li><li><a class="tocitem" href="../dev.html">Development Guidelines</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href="public.html">Public</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="public.html">Public</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/control-toolbox/CTBenchmarks.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Public-API"><a class="docs-heading-anchor" href="#Public-API">Public API</a><a id="Public-API-1"></a><a class="docs-heading-anchor-permalink" href="#Public-API" title="Permalink"></a></h1><p>This page lists the <strong>exported</strong> symbols of <code>CTBenchmarks</code>.</p><p>Load all public symbols into the current scope with:</p><pre><code class="language-julia hljs">using CTBenchmarks</code></pre><p>Alternatively, load only the module with:</p><pre><code class="language-julia hljs">import CTBenchmarks</code></pre><p>and then prefix all calls with <code>CTBenchmarks.</code> to create <code>CTBenchmarks.&lt;NAME&gt;</code>.</p><h2 id="benchmark"><a class="docs-heading-anchor" href="#benchmark"><code>benchmark</code></a><a id="benchmark-1"></a><a class="docs-heading-anchor-permalink" href="#benchmark" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.benchmark"><a class="docstring-binding" href="#CTBenchmarks.benchmark"><code>CTBenchmarks.benchmark</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">benchmark(;
    problems,
    solver_models,
    grid_sizes,
    disc_methods,
    tol,
    ipopt_mu_strategy,
    print_trace,
    max_iter,
    max_wall_time,
    grid_size_max_cpu
) -&gt; Nothing</code></pre><p>Run benchmarks on optimal control problems and save results to a JSON file.</p><p>This function performs the following steps:</p><ol><li>Detects CUDA availability and filters out :exa_gpu if CUDA is not functional</li><li>Runs benchmarks using <code>benchmark_data()</code> to generate a DataFrame of results</li><li>Collects environment metadata (Julia version, OS, machine, timestamp)</li><li>Builds a JSON-friendly payload combining results and metadata</li><li>Returns the payload as a Dict</li></ol><p>The JSON file can be easily loaded and converted back to a DataFrame using:</p><pre><code class="language-julia hljs">using JSON, DataFrames
data = JSON.parsefile(&quot;path/to/data.json&quot;)
df = DataFrame(data[&quot;results&quot;])</code></pre><div class="admonition is-info" id="File-Management-in-CI-dd970eabc9dfa99f"><header class="admonition-header">File Management in CI<a class="admonition-anchor" href="#File-Management-in-CI-dd970eabc9dfa99f" title="Permalink"></a></header><div class="admonition-body"><p>When run in the GitHub Actions workflow, <code>Project.toml</code> and <code>Manifest.toml</code> are  automatically copied to the output directory by the workflow itself. This ensures  reproducibility of benchmark results.</p></div></div><div class="admonition is-info" id="Return-Value-767dc651e3ca4db8"><header class="admonition-header">Return Value<a class="admonition-anchor" href="#Return-Value-767dc651e3ca4db8" title="Permalink"></a></header><div class="admonition-body"><p>This function returns <code>Dict</code>.</p></div></div><p><strong>Arguments</strong></p><ul><li><code>problems</code>: Vector of problem names (Symbols)</li><li><code>solver_models</code>: Vector of Pairs mapping solver =&gt; models (e.g., [:ipopt =&gt; [:jump, :adnlp], :madnlp =&gt; [:exa, :exa_gpu]])</li><li><code>grid_sizes</code>: Vector of grid sizes (Int)</li><li><code>disc_methods</code>: Vector of discretization methods (Symbols)</li><li><code>tol</code>: Solver tolerance (Float64)</li><li><code>ipopt_mu_strategy</code>: Mu strategy for Ipopt (String)</li><li><code>print_trace</code>: Boolean - whether to print solver output (for debugging)</li><li><code>max_iter</code>: Maximum number of iterations (Int)</li><li><code>max_wall_time</code>: Maximum wall time in seconds (Float64)</li><li><code>grid_size_max_cpu</code>: Maximum grid size for CPU models (Int)</li></ul><p><strong>Returns</strong></p><ul><li><code>Dict</code></li></ul></div></details></article><h2 id="plot_solutions"><a class="docs-heading-anchor" href="#plot_solutions"><code>plot_solutions</code></a><a id="plot_solutions-1"></a><a class="docs-heading-anchor-permalink" href="#plot_solutions" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.plot_solutions"><a class="docstring-binding" href="#CTBenchmarks.plot_solutions"><code>CTBenchmarks.plot_solutions</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">plot_solutions(payload::Dict, output_dir::AbstractString)</code></pre><p>Generate PDF plots comparing solutions for each (problem, grid_size) pair.</p><p><strong>Arguments</strong></p><ul><li><code>payload::Dict</code>: Benchmark results with solutions</li><li><code>output_dir::AbstractString</code>: Directory where to save PDF files</li></ul><p><strong>Details</strong></p><p>Creates one PDF per (problem, grid<em>size) combination directly inside `output</em>dir<code>. Each plot overlays all solver-model combinations for comparison. Filename format:</code>&lt;problem&gt;<em>N&lt;grid</em>size&gt;.pdf`</p><p>Solutions are plotted in order: OptimalControl solutions first (easy overlay), then JuMP solutions last (for proper layout).</p></div></details></article><h2 id="run"><a class="docs-heading-anchor" href="#run"><code>run</code></a><a id="run-1"></a><a class="docs-heading-anchor-permalink" href="#run" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="CTBenchmarks.run"><a class="docstring-binding" href="#CTBenchmarks.run"><code>CTBenchmarks.run</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">run(version::Symbol=:complete; filepath=nothing, print_trace=false)</code></pre><p>Run comprehensive benchmarks on optimal control problems with various solvers and discretization methods.</p><p>This function executes a predefined benchmark suite that evaluates the performance of different  optimal control solvers (Ipopt, MadNLP) across multiple models (JuMP, ADNLP, Exa, Exa-GPU) and  problems. Results are collected in a structured dictionary and optionally saved to JSON.</p><p><strong>Arguments</strong></p><ul><li><code>version::Symbol</code>: Benchmark suite version to run (default: <code>:complete</code>)<ul><li><code>:complete</code>: Full suite with 14 problems, multiple grid sizes (100, 200, 500), and two discretization methods</li><li><code>:minimal</code>: Quick suite with only the beam problem and grid size 100 (useful for testing)</li></ul></li><li><code>filepath::Union{AbstractString, Nothing}</code>: Optional path to save results as JSON file (must end with <code>.json</code>).  If <code>nothing</code>, results are only returned in memory.</li><li><code>print_trace::Bool</code>: Whether to print solver trace information during execution (default: <code>false</code>)</li></ul><p><strong>Returns</strong></p><ul><li><code>Dict</code>: Benchmark results containing timing data, solver statistics, and metadata for each problem-solver-model combination</li></ul><p><strong>Throws</strong></p><ul><li><code>CTBase.IncorrectArgument</code>: If <code>filepath</code> is provided but does not end with <code>.json</code></li><li><code>ErrorException</code>: If <code>version</code> is neither <code>:complete</code> nor <code>:minimal</code></li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using CTBenchmarks

julia&gt; # Run minimal benchmark and save results
julia&gt; results = run(:minimal; filepath=&quot;results.json&quot;)

julia&gt; # Run complete benchmark without saving
julia&gt; results = run(:complete)

julia&gt; # Run with solver trace output
julia&gt; results = run(:minimal; print_trace=true)</code></pre><p><strong>See Also</strong></p><ul><li><a href="public.html#benchmark"><code>benchmark</code></a>: Core benchmarking function with full customization</li></ul></div></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../benchmark-core-beam.html">« Beam</a><a class="docs-footer-nextpage" href="private.html">Private »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.0 on <span class="colophon-date" title="Saturday 15 November 2025 18:16">Saturday 15 November 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
