var documenterSearchIndex = {"docs":
[{"location":"benchmark-core-cpu.html#Core-CPU-Benchmarks","page":"CPU","title":"Core CPU Benchmarks","text":"","category":"section"},{"location":"benchmark-core-cpu.html#Ubuntu-Latest","page":"CPU","title":"Ubuntu Latest","text":"","category":"section"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"This benchmark suite evaluates optimal control problems on a standard CPU platform using GitHub Actions runners.","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"Benchmark Configuration:","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_print_config(BENCH_CORE_UBUNTU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"This configuration focuses on CPU-based solvers and provides a comprehensive comparison across different modelling frameworks.","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"note: Note\nThe linear solver is MUMPS for all experiments.","category":"page"},{"location":"benchmark-core-cpu.html#Environment","page":"CPU","title":"üñ•Ô∏è Environment","text":"","category":"section"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_basic_metadata(BENCH_CORE_UBUNTU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_downloads_toml(BENCH_CORE_UBUNTU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"<details style=\"margin-bottom: 0.5em; margin-top: 0.5em;\"><summary>‚ÑπÔ∏è Version info</summary>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_bench_data(BENCH_CORE_UBUNTU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"</details>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üì¶ Package status</summary>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_package_status(BENCH_CORE_UBUNTU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"</details>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üìö Complete manifest</summary>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_complete_manifest(BENCH_CORE_UBUNTU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"</details>","category":"page"},{"location":"benchmark-core-cpu.html#Results","page":"CPU","title":"üìä Results","text":"","category":"section"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_plot_performance_profiles(BENCH_CORE_UBUNTU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_print_benchmark_log(BENCH_CORE_UBUNTU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-cpu.html#Moonshot-CPU","page":"CPU","title":"Moonshot CPU","text":"","category":"section"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"This benchmark suite evaluates optimal control problems on self-hosted CPU hardware.","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"Benchmark Configuration:","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_print_config(BENCH_CORE_MOONSHOT_CPU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"This configuration tests larger grid sizes on dedicated hardware, comparing performance with the GitHub Actions runner.","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"note: Note\nThe linear solver is MUMPS for all experiments.","category":"page"},{"location":"benchmark-core-cpu.html#Environment-2","page":"CPU","title":"üöÄ Environment","text":"","category":"section"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_basic_metadata(BENCH_CORE_MOONSHOT_CPU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_downloads_toml(BENCH_CORE_MOONSHOT_CPU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"<details style=\"margin-bottom: 0.5em; margin-top: 0.5em;\"><summary>‚ÑπÔ∏è Version info</summary>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_bench_data(BENCH_CORE_MOONSHOT_CPU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"</details>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üì¶ Package status</summary>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_package_status(BENCH_CORE_MOONSHOT_CPU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"</details>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üìö Complete manifest</summary>","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_complete_manifest(BENCH_CORE_MOONSHOT_CPU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"</details>","category":"page"},{"location":"benchmark-core-cpu.html#Results-2","page":"CPU","title":"‚ö° Results","text":"","category":"section"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_plot_performance_profiles(BENCH_CORE_MOONSHOT_CPU) # hide","category":"page"},{"location":"benchmark-core-cpu.html","page":"CPU","title":"CPU","text":"_print_benchmark_log(BENCH_CORE_MOONSHOT_CPU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-gpu.html#Core-GPU-Benchmark","page":"GPU","title":"Core GPU Benchmark","text":"","category":"section"},{"location":"benchmark-core-gpu.html#Moonshot-GPU","page":"GPU","title":"Moonshot GPU","text":"","category":"section"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"This benchmark suite evaluates optimal control problems on GPU-accelerated hardware, focusing on large-scale problems.","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"Benchmark Configuration:","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_print_config(BENCH_CORE_MOONSHOT_GPU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"This configuration demonstrates GPU acceleration capabilities with ExaModels on large-scale problems, comparing CPU vs GPU performance for the same modelling framework.","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"note: Note\nThe linear solver is MUMPS for all experiments.","category":"page"},{"location":"benchmark-core-gpu.html#Environment","page":"GPU","title":"üöÄ Environment","text":"","category":"section"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_basic_metadata(BENCH_CORE_MOONSHOT_GPU) # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_downloads_toml(BENCH_CORE_MOONSHOT_GPU) # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"<details style=\"margin-bottom: 0.5em; margin-top: 0.5em;\"><summary>‚ÑπÔ∏è Version info</summary>","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_bench_data(BENCH_CORE_MOONSHOT_GPU) # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"</details>","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üì¶ Package status</summary>","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_package_status(BENCH_CORE_MOONSHOT_GPU) # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"</details>","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üìö Complete manifest</summary>","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_complete_manifest(BENCH_CORE_MOONSHOT_GPU) # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"</details>","category":"page"},{"location":"benchmark-core-gpu.html#Results","page":"GPU","title":"‚ö° Results","text":"","category":"section"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_plot_performance_profiles(BENCH_CORE_MOONSHOT_GPU) # hide","category":"page"},{"location":"benchmark-core-gpu.html","page":"GPU","title":"GPU","text":"_print_benchmark_log(BENCH_CORE_MOONSHOT_GPU) # hide\nnothing # hide","category":"page"},{"location":"api.html#API","page":"API","title":"API","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Pages   = [\"api.md\"]\nModules = [CTBenchmarks]\nOrder = [:module, :constant, :type, :function, :macro]","category":"page"},{"location":"api.html#CTBenchmarks.benchmark-Tuple{}","page":"API","title":"CTBenchmarks.benchmark","text":"benchmark(;\n    problems,\n    solver_models,\n    grid_sizes,\n    disc_methods,\n    tol,\n    ipopt_mu_strategy,\n    print_trace,\n    max_iter,\n    max_wall_time,\n    grid_size_max_cpu\n) -> Nothing\n\nRun benchmarks on optimal control problems and save results to a JSON file.\n\nThis function performs the following steps:\n\nDetects CUDA availability and filters out :exa_gpu if CUDA is not functional\nRuns benchmarks using benchmark_data() to generate a DataFrame of results\nCollects environment metadata (Julia version, OS, machine, timestamp)\nBuilds a JSON-friendly payload combining results and metadata\nReturns the payload as a Dict\n\nThe JSON file can be easily loaded and converted back to a DataFrame using:\n\nusing JSON, DataFrames\ndata = JSON.parsefile(\"path/to/data.json\")\ndf = DataFrame(data[\"results\"])\n\nnote: File Management in CI\nWhen run in the GitHub Actions workflow, Project.toml and Manifest.toml are  automatically copied to the output directory by the workflow itself. This ensures  reproducibility of benchmark results.\n\nnote: Return Value\nThis function returns Dict.\n\nArguments\n\nproblems: Vector of problem names (Symbols)\nsolver_models: Vector of Pairs mapping solver => models (e.g., [:ipopt => [:jump, :adnlp], :madnlp => [:exa, :exa_gpu]])\ngrid_sizes: Vector of grid sizes (Int)\ndisc_methods: Vector of discretization methods (Symbols)\ntol: Solver tolerance (Float64)\nipopt_mu_strategy: Mu strategy for Ipopt (String)\nprint_trace: Boolean - whether to print solver output (for debugging)\nmax_iter: Maximum number of iterations (Int)\nmax_wall_time: Maximum wall time in seconds (Float64)\ngrid_size_max_cpu: Maximum grid size for CPU models (Int)\n\nReturns\n\nDict\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.benchmark_data-Tuple{}","page":"API","title":"CTBenchmarks.benchmark_data","text":"benchmark_data(;\n    problems,\n    solver_models,\n    grid_sizes,\n    disc_methods,\n    tol,\n    ipopt_mu_strategy,\n    print_trace\n    max_iter,\n    max_wall_time,\n    grid_size_max_cpu\n) -> DataFrame\n\nRun benchmarks on optimal control problems and return results as a DataFrame.\n\nFor each combination of problem, solver, model, and grid size, this function:\n\nSets up and solves the optimization problem\nCaptures timing and memory statistics using @btimed or CUDA.@timed\nExtracts solver statistics (objective value, iterations)\nStores all data in a DataFrame row\n\nArguments\n\nproblems: Vector of problem names (Symbols)\nsolver_models: Vector of Pairs mapping solver => models (e.g., [:ipopt => [:jump, :adnlp], :madnlp => [:exa, :exa_gpu]])\ngrid_sizes: Vector of grid sizes (Int)\ndisc_methods: Vector of discretization methods (Symbols)\ntol: Solver tolerance (Float64)\nipopt_mu_strategy: Mu strategy for Ipopt (String)\nprint_trace: Boolean - whether to print solver output (for debugging)\nmax_iter: Maximum number of iterations (Int)\nmax_wall_time: Maximum wall time in seconds (Float64)\n\nReturns\n\nA DataFrame with columns:\n\nproblem: Symbol - problem name\nsolver: Symbol - solver used (:ipopt or :madnlp)\nmodel: Symbol - model type (:jump, :adnlp, :exa, or :exa_gpu)\ndisc_method: Symbol - discretization method\ngrid_size: Int - number of grid points\ntol: Float64 - solver tolerance\nmu_strategy: Union{String, Missing} - mu strategy for Ipopt (missing for MadNLP)\nprint_level: Any - print level for solver (Int for Ipopt, MadNLP.LogLevels for MadNLP)\nmax_iter: Int - maximum number of iterations\nmax_wall_time: Float64 - maximum wall time in seconds\nbenchmark: NamedTuple - full benchmark object from @btimed or CUDA.@timed\nobjective: Union{Float64, Missing} - objective function value (missing if failed)\niterations: Union{Int, Missing} - number of solver iterations (missing if failed)\nstatus: Any - termination status (type depends on solver/model)\nsuccess: Bool - whether the solve succeeded\ncriterion: Union{String, Missing} - optimization sense (\"min\" or \"max\", missing if failed)\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.build_payload-Tuple{DataFrames.DataFrame, Dict, Dict}","page":"API","title":"CTBenchmarks.build_payload","text":"build_payload(results::DataFrame, meta::Dict, config::Dict) -> Dict\n\nCombine benchmark results DataFrame, metadata, and configuration into a JSON-friendly dictionary. The DataFrame is converted to a vector of dictionaries (one per row) for easy JSON serialization and reconstruction.\n\nSolutions are extracted and kept in memory (not serialized to JSON) for later plot generation.\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.create_jump_layout-Tuple{Int64, Int64, Symbol, Int64}","page":"API","title":"CTBenchmarks.create_jump_layout","text":"create_jump_layout(n::Int, m::Int, problem::Symbol, grid_size::Int)\n\nCreate a plot layout for JuMP solutions with 2 columns (state/costate) and controls below.\n\nLayout structure:\n\nTop: n rows √ó 2 columns (states left, costates right)\nBottom: m rows √ó 2 columns (controls spanning full width)\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.filter_models_for_backend-Tuple{Vector{Symbol}, Symbol}","page":"API","title":"CTBenchmarks.filter_models_for_backend","text":"filter_models_for_backend(models::Vector{Symbol}, disc_method::Symbol) -> Vector{Symbol}\n\nFilter solver models depending on backend availability and discretization support.\n\nGPU models (ending with _gpu) are kept only if CUDA is available.\nJuMP models are kept only when disc_method == :trapeze.\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.generate_metadata-Tuple{}","page":"API","title":"CTBenchmarks.generate_metadata","text":"generate_metadata() -> Dict{String, String}\n\nReturn metadata about the current environment:\n\ntimestamp (UTC, ISO8601)\njulia_version\nos\nmachine hostname\npkg_status - output of Pkg.status() with ANSI colors\nversioninfo - output of versioninfo() with ANSI colors\npkg_manifest - output of Pkg.status(mode=PKGMODE_MANIFEST) with ANSI colors\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.get_dimensions-Tuple{DataFrames.SubDataFrame}","page":"API","title":"CTBenchmarks.get_dimensions","text":"get_dimensions(group::SubDataFrame) -> (Int, Int)\n\nGet state and control dimensions from the first successful solution in group.\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.is_cuda_on-Tuple{}","page":"API","title":"CTBenchmarks.is_cuda_on","text":"is_cuda_on() -> Bool\n\nReturn true if CUDA is functional on this machine.\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.plot_solution_comparison-Tuple{DataFrames.SubDataFrame, Symbol, Int64}","page":"API","title":"CTBenchmarks.plot_solution_comparison","text":"plot_solution_comparison(group::SubDataFrame, problem::Symbol, grid_size::Int)\n\nCreate a comparison plot for all solutions in a group (same problem, same grid_size).\n\nStrategy:\n\nPlot OptimalControl solutions first (easy with plot!)\nPlot JuMP solutions last (to get proper layout)\n\nLayout: 2 columns for states/costates, then controls below in full width\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.plot_solutions-Tuple{Dict, AbstractString}","page":"API","title":"CTBenchmarks.plot_solutions","text":"plot_solutions(payload::Dict, output_dir::AbstractString)\n\nGenerate PDF plots comparing solutions for each (problem, grid_size) pair.\n\nArguments\n\npayload::Dict: Benchmark results with solutions\noutput_dir::AbstractString: Directory where to save PDF files\n\nDetails\n\nCreates one PDF per (problem, gridsize) combination in `outputdir/figures/. Each plot overlays all solver-model combinations for comparison. Filename format:<problem>N<gridsize>.pdf`\n\nSolutions are plotted in order: OptimalControl solutions first (easy overlay), then JuMP solutions last (for proper layout).\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.prettymemory-Tuple{Any}","page":"API","title":"CTBenchmarks.prettymemory","text":"prettymemory(bytes::Integer) -> String\n\nFormat a memory footprint bytes into a human-readable string using binary prefixes (bytes, KiB, MiB, GiB) with two decimal places.\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.prettytime-Tuple{Any}","page":"API","title":"CTBenchmarks.prettytime","text":"prettytime(t::Real) -> String\n\nFormat a duration t expressed in seconds into a human-readable string with three decimal places and adaptive units (ns, Œºs, ms, s).\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.print_benchmark_line-Tuple{Symbol, NamedTuple}","page":"API","title":"CTBenchmarks.print_benchmark_line","text":"print_benchmark_line(model::Symbol, stats::NamedTuple)\n\nPrint a formatted line summarizing benchmark statistics for model with colors. Handles both CPU benchmarks (from @btimed) and GPU benchmarks (from CUDA.@timed).\n\nDisplays: time, allocations/memory, objective, iterations, and success status\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.run","page":"API","title":"CTBenchmarks.run","text":"Run the benchmarks for a specific version.\n\nArguments\n\nversion::Symbol: version to run (:complete or :minimal)\nfilepath::Union{AbstractString, Nothing}: optional path to the JSON file where results should be saved. When provided, it must end with .json.\nprint_trace::Bool: whether to print the trace of the solver\n\nReturns\n\nDict containing benchmark results and metadata\n\n\n\n\n\n","category":"function"},{"location":"api.html#CTBenchmarks.save_json-Tuple{Dict, AbstractString}","page":"API","title":"CTBenchmarks.save_json","text":"save_json(payload::Dict, outpath::AbstractString)\n\nSave a JSON payload to a file. Creates the parent directory if needed. Uses pretty printing for readability. Sanitizes NaN and Inf values to null for JSON compatibility.\n\nSolutions and solution_types are excluded from JSON serialization (kept only in memory).\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.set_print_level-Tuple{Symbol, Bool}","page":"API","title":"CTBenchmarks.set_print_level","text":"set_print_level(solver::Symbol, print_trace::Bool) -> Int\n\nSet print level based on solver and print_trace flag.\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.solve_and_extract_data-Tuple{Symbol, Symbol, Symbol, Int64, Symbol, Float64, Union{Missing, String}, Bool, Int64, Float64}","page":"API","title":"CTBenchmarks.solve_and_extract_data","text":"solve_and_extract_data(problem, solver, model, grid_size, disc_method, \n                      tol, mu_strategy, print_level, max_iter, max_wall_time) -> NamedTuple\n\nSolve an optimal control problem and extract performance and solver statistics.\n\nThis internal helper function handles the solve process and data extraction for different model types (JuMP, adnlp, exa, exa_gpu).\n\nArguments\n\nproblem::Symbol: problem name (e.g., :beam, :chain)\nsolver::Symbol: solver to use (:ipopt or :madnlp)\nmodel::Symbol: model type (:jump, :adnlp, :exa, or :exa_gpu)\ngrid_size::Int: number of grid points\ndisc_method::Symbol: discretization method\ntol::Float64: solver tolerance\nmu_strategy::Union{String, Missing}: mu strategy for Ipopt (missing for MadNLP)\nprint_level::Union{Int, MadNLP.LogLevels, Missing}: print level for solver (Int for Ipopt, MadNLP.LogLevels for MadNLP)\nmax_iter::Int: maximum number of iterations\nmax_wall_time::Float64: maximum wall time in seconds\n\nReturns\n\nA NamedTuple with fields:\n\nbenchmark: full benchmark object from @btimed (CPU) or CUDA.@timed (GPU)\nobjective::Union{Float64, Missing}: objective function value (missing if failed)\niterations::Union{Int, Missing}: number of solver iterations (missing if failed)\nstatus::Any: termination status (type depends on solver/model)\nsuccess::Bool: whether the solve succeeded\ncriterion::Union{String, Missing}: optimization sense (\"min\" or \"max\", missing if failed)\n\n\n\n\n\n","category":"method"},{"location":"api.html#CTBenchmarks.strip_benchmark_value-Tuple{Any}","page":"API","title":"CTBenchmarks.strip_benchmark_value","text":"strip_benchmark_value(bench)\n\nRemove the value field from benchmark outputs (NamedTuple or Dict) to ensure JSON-serializable data while preserving all other statistics.\n\n\n\n\n\n","category":"method"},{"location":"dev.html#Development-Guidelines","page":"Development Guidelines","title":"Development Guidelines","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"This guide explains how to add a new benchmark to the CTBenchmarks.jl pipeline.","category":"page"},{"location":"dev.html#Overview","page":"Development Guidelines","title":"Overview","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Adding a new benchmark involves creating several components:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Step Description Status\nBenchmark script Julia script that runs the benchmark Required\nJSON configuration Add benchmark config to JSON file Required\nGitHub label Label to trigger the benchmark on pull requests Required\nIndividual workflow Workflow for manual testing (reads from JSON) Optional\nDocumentation page Display benchmark results in the documentation Optional","category":"page"},{"location":"dev.html#Step-by-Step-Guide","page":"Development Guidelines","title":"Step-by-Step Guide","text":"","category":"section"},{"location":"dev.html#1.-Create-the-Benchmark-Script-{#benchmark-script}","page":"Development Guidelines","title":"1. Create the Benchmark Script {#benchmark-script}","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Create a new Julia script in the benchmarks/ directory. Choose a descriptive filename that will serve as your benchmark identifier.","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Naming convention: Use kebab-case (e.g., core-ubuntu-latest.jl, core-moonshot-gpu.jl)","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Example: benchmarks/core-ubuntu-latest.jl","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"# Benchmark script for <id>\n# Setup (Pkg.activate, instantiate, update, using CTBenchmarks) is handled by the workflow\n\nfunction run()\n    results = CTBenchmarks.benchmark(;\n        problems = [:problem1, :problem2, ...],\n        solver_models = [:solver => [:model1, :model2]],\n        grid_sizes = [100, 500, 1000],\n        disc_methods = [:trapeze],\n        tol = 1e-6,\n        ipopt_mu_strategy = \"adaptive\",\n        print_trace = false,\n        max_iter = 1000,\n        max_wall_time = 500.0\n    )\n    println(\"‚úÖ Benchmark completed successfully!\")\n    return results\nend","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Key points:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Setup code is handled by the workflow - No need to include using Pkg, Pkg.activate(), Pkg.instantiate(), Pkg.update(), or using CTBenchmarks in your script. The GitHub Actions workflow handles all environment setup automatically.\nAll parameters are required - the benchmark function has no optional arguments\nDefine a run() function - it must take no arguments, return the Dict payload from CTBenchmarks.benchmark, and should not perform any file I/O\nThe workflow calls run(), saves the returned payload as {id}.json, and stores it under docs/src/assets/benchmarks/{id}/\nTOML files are copied by the workflow - Project.toml and Manifest.toml are automatically copied to the output directory by the GitHub Actions workflow to ensure reproducibility\nAvailable problems: The list of problems you can choose is available in the OptimalControlProblems.jl documentation\nFor local testing: See benchmarks/local.jl for an example that includes the setup code needed to run benchmarks locally","category":"page"},{"location":"dev.html#2.-Add-Configuration-to-JSON-{#json-config}","page":"Development Guidelines","title":"2. Add Configuration to JSON {#json-config}","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Edit benchmarks/benchmarks-config.json and add your benchmark configuration:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"{\n  \"benchmarks\": [\n    {\n      \"id\": \"your-benchmark-id\",\n      \"julia_version\": \"1.11\",\n      \"julia_arch\": \"x64\",\n      \"runs_on\": \"ubuntu-latest\",\n      \"runner\": \"github\"\n    }\n  ]\n}","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Configuration fields:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"id (required): Unique identifier for the benchmark (kebab-case)\nMust exactly match your script filename (without the .jl extension)\nConvention: {family}-{runner} (e.g., core-ubuntu-latest, core-moonshot)\nExample: if your script is benchmarks/core-ubuntu-latest.jl, use \"id\": \"core-ubuntu-latest\"\nUsed in label: run bench {id}\njulia_version (required): Julia version to use (e.g., \"1.11\")\njulia_arch (required): Architecture (typically \"x64\")\nruns_on (required): GitHub runner specification\nFor standard runners: \"ubuntu-latest\"\nFor self-hosted runners with custom labels: \"[\\\"moonshot\\\"]\" or \"[\\\"mothra\\\"]\" (use the runner label configured in your self-hosted runner)`\nrunner (required): Runner type for caching strategy\n\"github\" for standard GitHub runners (uses julia-actions/cache)\n\"self-hosted\" for self-hosted runners (uses actions/cache for artifacts only)","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Examples:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"// Standard GitHub runner\n{\n  \"id\": \"core-ubuntu-latest\",\n  \"julia_version\": \"1.11\",\n  \"julia_arch\": \"x64\",\n  \"runs_on\": \"ubuntu-latest\",\n  \"runner\": \"github\"\n}\n\n// Self-hosted runner with custom label\n{\n  \"id\": \"core-moonshot\",\n  \"julia_version\": \"1.11\",\n  \"julia_arch\": \"x64\",\n  \"runs_on\": \"[\\\"moonshot\\\"]\",\n  \"runner\": \"self-hosted\"\n}","category":"page"},{"location":"dev.html#Automatic-Workflow-Execution","page":"Development Guidelines","title":"Automatic Workflow Execution","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Good news! You don't need to create a workflow file manually. The orchestrator automatically runs your benchmark based on the JSON configuration using a matrix strategy.","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"When you add a label to a PR (e.g., run bench your-benchmark-id), the orchestrator:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Reads benchmarks/benchmarks-config.json\nFinds your benchmark configuration by matching the label with the id field\nCalls the reusable workflow with the parameters from the JSON (Julia version, architecture, runner, etc.)\nThe reusable workflow loads and executes your script at benchmarks/{id}.jl\nResults are saved to docs/src/assets/benchmarks/{id}/{id}.json","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Everything is automatic! ‚ú®","category":"page"},{"location":"dev.html#3.-Create-the-GitHub-Label-{#github-label}","page":"Development Guidelines","title":"3. Create the GitHub Label {#github-label}","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"On GitHub, create a new label for your benchmark:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Go to your repository ‚Üí Issues ‚Üí Labels\nClick New label\nName: run bench {id} where {id} matches your JSON configuration\nExample: run bench core-ubuntu-latest\nExample: run bench core-moonshot-gpu\nImportant: Use the exact benchmark ID from JSON\nChoose a color and description\nClick Create label","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Label types:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Individual labels - Trigger a specific benchmark:\nFormat: run bench {id}\nExample: run bench core-moonshot-gpu\nExample: run bench minimal-ubuntu-latest\nGroup labels - Trigger all benchmarks with a common prefix:\nFormat: run bench {prefix}-all\nExample: run bench core-all ‚Üí runs all core-* benchmarks\nExample: run bench minimal-all ‚Üí runs all minimal-* benchmarks\nExample: run bench gpu-all ‚Üí runs all gpu-* benchmarks","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Naming convention for benchmark families:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"To use group labels effectively, follow this naming convention:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"{family}-{runner} format (e.g., core-ubuntu-latest, core-moonshot)\nAll benchmarks in the same family share the same prefix\nGroup label run bench {family}-all will run all benchmarks in that family","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Examples:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"core-ubuntu-latest, core-moonshot-gpu, core-mothra-gpu ‚Üí run bench core-all\nminimal-ubuntu-latest, minimal-moonshot-gpu, minimal-mothra-gpu ‚Üí run bench minimal-all\ngpu-cuda12, gpu-cuda13 ‚Üí run bench gpu-all","category":"page"},{"location":"dev.html#4.-(Optional)-Create-Individual-Workflow-{#individual-workflow}","page":"Development Guidelines","title":"4. (Optional) Create Individual Workflow {#individual-workflow}","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"info: Optional Step\nIndividual workflows are optional. The orchestrator will automatically run your benchmark based on the JSON configuration. Individual workflows are useful for:Manual testing via workflow_dispatch\nRunning a specific benchmark without the orchestrator\nDebugging","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Create .github/workflows/benchmark-{id}.yml:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"name: Benchmark {Name}\n\non:\n  workflow_call:\n  workflow_dispatch:\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  load-config:\n    runs-on: ubuntu-latest\n    outputs:\n      config: ${{ steps.get-config.outputs.config }}\n    steps:\n      - uses: actions/checkout@v5\n      - name: Get benchmark config\n        id: get-config\n        run: |\n          CONFIG=$(jq -c '.benchmarks[] | select(.id == \"{id}\")' benchmarks/benchmarks-config.json)\n          echo \"config=$CONFIG\" >> $GITHUB_OUTPUT\n  \n  bench:\n    needs: load-config\n    uses: ./.github/workflows/benchmark-reusable.yml\n    with:\n      script_path: benchmarks/${{ fromJSON(needs.load-config.outputs.config).id }}.jl\n      julia_version: ${{ fromJSON(needs.load-config.outputs.config).julia_version }}\n      julia_arch: ${{ fromJSON(needs.load-config.outputs.config).julia_arch }}\n      runs_on: ${{ fromJSON(needs.load-config.outputs.config).runs_on }}\n      runner: ${{ fromJSON(needs.load-config.outputs.config).runner }}","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Key features:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Reads configuration from JSON - Single source of truth\nUses ID to construct script path - benchmarks/${{ fromJSON(...).id }}.jl ensures consistency\nCan be triggered manually via workflow_dispatch for testing\nCan be called by orchestrator via workflow_call\nNo hardcoded values - Everything comes from JSON configuration","category":"page"},{"location":"dev.html#5.-(Optional)-Create-Documentation-Page-{#documentation-page}","page":"Development Guidelines","title":"5. (Optional) Create Documentation Page {#documentation-page}","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"If you want to display results in the documentation, create docs/src/benchmark-<name>.md.template:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"# <Name> Benchmark\n\n```@setup BENCH\ninclude(joinpath(@__DIR__, \"assets\", \"jl\", \"utils.jl\"))\n\n# Define benchmark ID\nconst BENCH_ID = \"<id>\"\n```\n\n## Description\n\nBrief description of your benchmark configuration.\n\n**Benchmark Configuration:**\n\n- **Solvers:** List of solvers (e.g., Ipopt, MadNLP)\n- **Models:** List of models (e.g., JuMP, ADNLPModels, ExaModels)\n- **Grid sizes:** Discretisation points (e.g., 200, 500, 1000)\n- **Discretisation:** Method used (e.g., Trapeze)\n- **Tolerance:** 1e-6\n- **Limits:** Max iterations and wall time\n\n!!! note\n    Add any relevant notes about the benchmark setup (e.g., linear solver used)\n\n### üñ•Ô∏è Environment\n\n<!-- INCLUDE_ENVIRONMENT:\nBENCH_ID = BENCH_ID\nENV_NAME = BENCH\n-->\n\n### üìä Results\n\n```@example BENCH\n_plot_performance_profiles(BENCH_ID) # hide\n```\n\n```@example BENCH\n_print_benchmark_log(BENCH_ID) # hide\nnothing # hide\n```","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Key points:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Use a single @setup BENCH block for all benchmarks in the same page\nDefine BENCH_ID as a constant with your benchmark identifier\nUse _plot_performance_profiles(BENCH_ID) to display performance plots (optional)\nUse _print_benchmark_log(BENCH_ID) to display detailed results table\nThe INCLUDE_ENVIRONMENT comment is processed by the documentation build system","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Then add it to docs/make.jl:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"pages = [\n    \"Introduction\" => \"index.md\",\n    \"Core benchmark\" => \"benchmark-core.md\",\n    \"<Name> Benchmark\" => \"benchmark-<name>.md\",\n    \"API\" => \"api.md\",\n    \"Development Guidelines\" => \"dev.md\",\n]","category":"page"},{"location":"dev.html#Testing-Your-Benchmark","page":"Development Guidelines","title":"Testing Your Benchmark","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Local testing: Run your script locally to verify it works\nPush changes: Commit and push all files\nCreate PR: Open a pull request\nAdd label: Add the run bench <name> label to trigger the workflow\nMonitor: Check the Actions tab to monitor execution","category":"page"},{"location":"dev.html#Troubleshooting","page":"Development Guidelines","title":"Troubleshooting","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Cache issues on self-hosted runners:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Ensure \"runner\": \"self-hosted\" is set in your JSON configuration\nThe reusable workflow uses actions/cache for artifacts only on self-hosted runners\nStandard GitHub runners should use \"runner\": \"github\" to enable full package caching","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Workflow not triggering:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Verify the label name matches exactly: run bench {id} where {id} is from your JSON\nCheck that your benchmark ID exists in benchmarks/benchmarks-config.json\nEnsure the benchmark script file exists at benchmarks/{id}.jl","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Benchmark script fails:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Check Julia version compatibility\nVerify all dependencies are available on the target runner\nReview the benchmark function parameters","category":"page"},{"location":"dev.html#Examples","page":"Development Guidelines","title":"Examples","text":"","category":"section"},{"location":"dev.html#Example-1:-Standard-GitHub-Runner","page":"Development Guidelines","title":"Example 1: Standard GitHub Runner","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"A CPU benchmark running on GitHub Actions:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"JSON configuration:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"{\n  \"id\": \"core-ubuntu-latest\",\n  \"julia_version\": \"1.11\",\n  \"julia_arch\": \"x64\",\n  \"runs_on\": \"\\\"ubuntu-latest\\\"\",\n  \"runner\": \"github\"\n}","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Files:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Script: benchmarks/core-ubuntu-latest.jl\nLabel: run bench core-ubuntu-latest\nDocumentation: docs/src/benchmark-core.md.template","category":"page"},{"location":"dev.html#Example-2:-Self-Hosted-Runner-(Moonshot)","page":"Development Guidelines","title":"Example 2: Self-Hosted Runner (Moonshot)","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"A GPU benchmark on a self-hosted runner with custom label:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"JSON configuration:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"{\n  \"id\": \"core-moonshot-gpu\",\n  \"julia_version\": \"1.11\",\n  \"julia_arch\": \"x64\",\n  \"runs_on\": \"[\\\"moonshot\\\"]\",\n  \"runner\": \"self-hosted\"\n}","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Files:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Script: benchmarks/core-moonshot-gpu.jl\nLabel: run bench core-moonshot-gpu","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Key points:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Uses simplified runner label [\"moonshot\"] instead of full system labels\nThe runner: \"self-hosted\" field tells the workflow to use artifact-only caching","category":"page"},{"location":"dev.html#Example-3:-Multiple-Runners,-Same-Hardware","page":"Development Guidelines","title":"Example 3: Multiple Runners, Same Hardware","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"You can create CPU and GPU variants for the same hardware:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"CPU variant:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"{\n  \"id\": \"core-moonshot-cpu\",\n  \"julia_version\": \"1.11\",\n  \"julia_arch\": \"x64\",\n  \"runs_on\": \"[\\\"moonshot\\\"]\",\n  \"runner\": \"self-hosted\"\n}","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"GPU variant:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"{\n  \"id\": \"core-moonshot-gpu\",\n  \"julia_version\": \"1.11\",\n  \"julia_arch\": \"x64\",\n  \"runs_on\": \"[\\\"moonshot\\\"]\",\n  \"runner\": \"self-hosted\"\n}","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Both use the same runner label but different benchmark scripts with different solver configurations.","category":"page"},{"location":"dev.html#How-the-Orchestrator-Works","page":"Development Guidelines","title":"How the Orchestrator Works","text":"","category":"section"},{"location":"dev.html#Matrix-Strategy","page":"Development Guidelines","title":"Matrix Strategy","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"The orchestrator uses a matrix strategy to dynamically call benchmarks:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Guard job reads benchmarks/benchmarks-config.json\nBased on PR labels, it builds a JSON array of selected benchmarks\nBenchmark job uses matrix to iterate over selected benchmarks\nEach matrix iteration calls benchmark-reusable.yml with the appropriate parameters","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Benefits:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"No need to declare individual jobs for each benchmark\nAdding a benchmark requires only JSON modification\nAll benchmarks run in parallel (matrix strategy)\nConsistent behavior across all benchmarks","category":"page"},{"location":"dev.html#Label-System","page":"Development Guidelines","title":"Label System","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"The orchestrator supports two types of labels with automatic prefix detection:","category":"page"},{"location":"dev.html#Individual-Labels","page":"Development Guidelines","title":"Individual Labels","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Format: run bench {id}\nBehavior: Runs the specific benchmark with that exact ID\nExamples:\nrun bench core-ubuntu-latest ‚Üí runs only core-ubuntu-latest\nrun bench minimal-macos ‚Üí runs only minimal-macos","category":"page"},{"location":"dev.html#Group-Labels-(Generic)","page":"Development Guidelines","title":"Group Labels (Generic)","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Format: run bench {prefix}-all\nBehavior: Automatically runs all benchmarks whose ID starts with {prefix}-\nHow it works:\nThe orchestrator extracts the prefix from the label (e.g., core from run bench core-all)\nIt scans all benchmark IDs in the JSON\nIt selects all benchmarks matching the pattern {prefix}-*\nExamples:\nrun bench core-all ‚Üí runs core-ubuntu-latest, core-moonshot-cpu, core-moonshot-gpu, core-mothra-gpu\nrun bench minimal-all ‚Üí runs all benchmarks starting with minimal-","category":"page"},{"location":"dev.html#Multiple-Labels","page":"Development Guidelines","title":"Multiple Labels","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"You can combine multiple labels on a PR:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"run bench core-all + run bench minimal-ubuntu-latest ‚Üí runs all core-* benchmarks + minimal-ubuntu-latest\nrun bench core-moonshot + run bench gpu-all ‚Üí runs core-moonshot + all gpu-* benchmarks","category":"page"},{"location":"dev.html#Automatic-Discovery","page":"Development Guidelines","title":"Automatic Discovery","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"The system is completely generic - no hardcoded family names:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Add benchmarks with any prefix (e.g., perf-*, stress-*, validation-*)\nCreate corresponding group labels (e.g., run bench perf-all)\nThe orchestrator automatically detects and processes them","category":"page"},{"location":"dev.html#Configuration-File","page":"Development Guidelines","title":"Configuration File","text":"","category":"section"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"The benchmarks/benchmarks-config.json file is the single source of truth:","category":"page"},{"location":"dev.html","page":"Development Guidelines","title":"Development Guidelines","text":"Orchestrator reads it to discover available benchmarks\nIndividual workflows read it to get their configuration\nEasy to maintain and validate\nCan be extended with additional metadata","category":"page"},{"location":"benchmark-core-beam.html#Core-Beam-Benchmark","page":"Beam","title":"Core Beam Benchmark","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"This page presents benchmark results for the beam problem across different platforms and configurations.","category":"page"},{"location":"benchmark-core-beam.html#Ubuntu-Latest-Beam-Problem","page":"Beam","title":"Ubuntu Latest - Beam Problem","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"Results for the beam problem on GitHub Actions runners (Ubuntu latest).","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"Benchmark Configuration:","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"_print_config(BENCH_CORE_UBUNTU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"This configuration focuses on CPU-based solvers and provides a comprehensive comparison across different modelling frameworks.","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"note: Note\nThe linear solver is MUMPS for all experiments.","category":"page"},{"location":"benchmark-core-beam.html#Ubuntu-Results","page":"Beam","title":"üìä Ubuntu Results","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"_print_benchmark_log(BENCH_CORE_UBUNTU; problems=[\"beam\"]) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-beam.html#Moonshot-CPU-Beam-Problem","page":"Beam","title":"Moonshot CPU - Beam Problem","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"Results for the beam problem on self-hosted CPU hardware.","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"Benchmark Configuration:","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"_print_config(BENCH_CORE_MOONSHOT_CPU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"This configuration tests larger grid sizes on dedicated hardware, comparing performance with the GitHub Actions runner.","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"note: Note\nThe linear solver is MUMPS for all experiments.","category":"page"},{"location":"benchmark-core-beam.html#Moonshot-CPU-Results","page":"Beam","title":"‚ö° Moonshot CPU Results","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"_print_benchmark_log(BENCH_CORE_MOONSHOT_CPU; problems=[\"beam\"]) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-beam.html#Moonshot-GPU-Beam-Problem","page":"Beam","title":"Moonshot GPU - Beam Problem","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"Results for the beam problem on GPU-accelerated hardware.","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"Benchmark Configuration:","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"_print_config(BENCH_CORE_MOONSHOT_GPU) # hide\nnothing # hide","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"This configuration demonstrates GPU acceleration capabilities with ExaModels on large-scale problems, comparing CPU vs GPU performance for the same modelling framework.","category":"page"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"note: Note\nThe linear solver is MUMPS for all experiments.","category":"page"},{"location":"benchmark-core-beam.html#Moonshot-GPU-Results","page":"Beam","title":"üöÄ Moonshot GPU Results","text":"","category":"section"},{"location":"benchmark-core-beam.html","page":"Beam","title":"Beam","text":"_print_benchmark_log(BENCH_CORE_MOONSHOT_GPU; problems=[\"beam\"]) # hide\nnothing # hide","category":"page"},{"location":"index.html#CTBenchmarks","page":"Introduction","title":"CTBenchmarks","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"CTBenchmarks.jl is a comprehensive benchmarking suite for optimal control problems, designed to evaluate and compare the performance of different solvers and modelling approaches within the control-toolbox ecosystem.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"This package provides:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"üöÄ Pre-configured benchmark suites for quick performance evaluation\nüìä Automated result collection and analysis\nüîß Flexible API for creating custom benchmarks\nüìà Detailed performance metrics including timing, memory usage, and solver statistics","category":"page"},{"location":"index.html#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"CTBenchmarks.jl is registered in the Julia General Registry. Install it using the package manager:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(\"CTBenchmarks\")","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Or in the Julia REPL package mode (press ]):","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"pkg> add CTBenchmarks","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Once installed, load the package:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"using CTBenchmarks","category":"page"},{"location":"index.html#Quick-Start","page":"Introduction","title":"Quick Start","text":"","category":"section"},{"location":"index.html#Running-Pre-configured-Benchmarks","page":"Introduction","title":"Running Pre-configured Benchmarks","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"CTBenchmarks provides two pre-configured benchmark suites:","category":"page"},{"location":"index.html#Minimal-Benchmark-(Fast)","page":"Introduction","title":"Minimal Benchmark (Fast)","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Run a quick benchmark on a single problem to test your setup:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"CTBenchmarks.run(:minimal)","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"This runs the :beam problem with:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Grid size: 100\nDiscretization: trapeze\nSolvers: Ipopt and MadNLP\nModels: JuMP, adnlp, exa, exa_gpu","category":"page"},{"location":"index.html#Complete-Benchmark-(Comprehensive)","page":"Introduction","title":"Complete Benchmark (Comprehensive)","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Run the full benchmark suite across all problems:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"CTBenchmarks.run(:complete)","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"This runs 14 optimal control problems with:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Grid sizes: 100, 200, 500\nDiscretizations: trapeze, midpoint\nSolvers: Ipopt and MadNLP\nModels: JuMP, adnlp, exa, exa_gpu","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"tip: Solver Output\nBy default, solver output is suppressed. To see detailed solver traces, use:CTBenchmarks.run(:minimal; print_trace=true)","category":"page"},{"location":"index.html#Saving-Results","page":"Introduction","title":"Saving Results","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"To save benchmark results to a directory:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"results = CTBenchmarks.run(:minimal; filepath=\"my_results/minimal.json\")","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"This returns the benchmark payload as a Dict and saves it to my_results/minimal.json (the directory is created automatically if needed). The filepath argument is optional but, when provided, it must end with .json.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"my_results/minimal.json ‚Äì Benchmark results in JSON format","category":"page"},{"location":"index.html#Creating-Custom-Benchmarks","page":"Introduction","title":"Creating Custom Benchmarks","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"For more control over your benchmarks, use the CTBenchmarks.benchmark function directly:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"results = CTBenchmarks.benchmark(;\n    problems = [:beam, :chain, :robot],\n    solver_models = [\n        :ipopt => [:jump, :adnlp, :exa],\n        :madnlp => [:exa, :exa_gpu]\n    ],\n    grid_sizes = [200, 500, 1000],\n    disc_methods = [:trapeze],\n    tol = 1e-6,\n    ipopt_mu_strategy = \"adaptive\",\n    print_trace = false,\n    max_iter = 1000,\n    max_wall_time = 500.0\n)\n\nCTBenchmarks.save_json(results, \"custom_benchmark.json\")","category":"page"},{"location":"index.html#Available-Problems","page":"Introduction","title":"Available Problems","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"CTBenchmarks includes 14 optimal control problems from OptimalControlProblems.jl:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":":beam - Beam control problem\n:chain - Chain of masses\n:double_oscillator - Double oscillator\n:ducted_fan - Ducted fan control\n:electric_vehicle - Electric vehicle optimization\n:glider - Glider trajectory\n:insurance - Insurance problem\n:jackson - Jackson problem\n:robbins - Robbins problem\n:robot - Robot arm control\n:rocket - Rocket trajectory\n:space_shuttle - Space shuttle re-entry\n:steering - Steering control\n:vanderpol - Van der Pol oscillator","category":"page"},{"location":"index.html#Solver-and-Model-Combinations","page":"Introduction","title":"Solver and Model Combinations","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Supported Solvers:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":":ipopt - Interior Point Optimizer\n:madnlp - Matrix-free Augmented Lagrangian NLP solver","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Supported Models:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":":jump - JuMP modelling framework\n:adnlp - Automatic differentiation NLP models\n:exa - ExaModels (CPU)\n:exa_gpu - ExaModels (GPU acceleration)","category":"page"},{"location":"index.html#Benchmark-Parameters","page":"Introduction","title":"Benchmark Parameters","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"grid_sizes: Number of discretization points (e.g., [100, 200, 500])\ndisc_methods: Discretization schemes (:trapeze, :midpoint)\ntol: Solver tolerance (e.g., 1e-6)\nmax_iter: Maximum solver iterations (e.g., 1000)\nmax_wall_time: Maximum wall time in seconds (e.g., 500.0)","category":"page"},{"location":"index.html#Benchmark-Results-in-This-Documentation","page":"Introduction","title":"Benchmark Results in This Documentation","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"This documentation includes pre-computed benchmark results from continuous integration runs on different platforms:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Ubuntu Latest - Standard CPU benchmarks on GitHub Actions runners\nMoonshot - GPU-accelerated benchmarks on dedicated hardware","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"These results provide reference performance data and demonstrate the capabilities of different solver and model combinations. You can explore them in the Core Benchmark section.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Each benchmark result page includes:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"üìä Performance metrics (time, memory, iterations)\nüñ•Ô∏è Environment information (Julia version, OS, hardware)\nüìú Reproducible benchmark scripts\nüì¶ Complete dependency information","category":"page"},{"location":"index.html#Understanding-Benchmark-Output","page":"Introduction","title":"Understanding Benchmark Output","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"When you run a benchmark, you'll see output similar to:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Benchmarks results:\n\n‚îå‚îÄ problem: beam\n‚îÇ\n‚îú‚îÄ‚îÄ‚î¨ solver: ipopt, disc_method: trapeze\n‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  N : 100\n‚îÇ  ‚îÇ  ‚úì | JuMP    | time:    1.234 s | iters: 42    | obj: 1.234567e+00 (min) | CPU:    2.5 MiB\n‚îÇ  ‚îÇ  ‚úì | adnlp   | time:    0.987 s | iters: 42    | obj: 1.234567e+00 (min) | CPU:    2.1 MiB\n‚îÇ  ‚îÇ  ‚úì | exa     | time:    0.765 s | iters: 42    | obj: 1.234567e+00 (min) | CPU:    1.8 MiB\n‚îÇ  ‚îî‚îÄ\n‚îî‚îÄ","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Legend:","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"‚úì / ‚úó - Success or failure indicator\nModel - Modelling framework (JuMP, ADNLPModels, ExaModels)\ntime - Total solve time\niters - Number of solver iterations\nobj - Objective function value and criterion (min or max problem)\nMemory - CPU memory usage (GPU memory shown separately for GPU models)","category":"page"},{"location":"index.html#Documentation-build-environment","page":"Introduction","title":"Documentation build environment","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"_downloads_toml() # hide","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"<details style=\"margin-bottom: 0.5em; margin-top: 1em;\"><summary>‚ÑπÔ∏è Version info</summary>","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"versioninfo() # hide","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"</details>","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üì¶ Package status</summary>","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Pkg.status() # hide","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"</details>","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"<details style=\"margin-bottom: 0.5em;\"><summary>üìö Complete manifest</summary>","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Pkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"</details>","category":"page"}]
}
