name: Orchestrate Core Benchmark and Docs

on:
  pull_request:
    types: [labeled, synchronize, opened, reopened]

permissions:
  actions: write
  contents: write
  pull-requests: write

jobs:
  guard:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      run_ubuntu: ${{ steps.check.outputs.run_ubuntu }}
      run_moonshot: ${{ steps.check.outputs.run_moonshot }}
      run_mothra: ${{ steps.check.outputs.run_mothra }}
      benchmarks_summary: ${{ steps.check.outputs.benchmarks_summary }}
    steps:
      - name: Check which benchmarks should run
        id: check
        run: |
          echo "ğŸ›¡ï¸  Guard job: Checking execution conditions..."
          
          EVENT_NAME="${{ github.event_name }}"
          echo "ğŸ“‹ Event type: $EVENT_NAME"
          
          # Initialize outputs
          RUN_UBUNTU="false"
          RUN_MOONSHOT="false"
          RUN_MOTHRA="false"
          BENCHMARKS_LIST=""
          
          if [[ "$EVENT_NAME" == "push" ]]; then
            # For push events to main, run no benchmarks
            echo "ğŸš€ Push event to main branch detected"
            echo "âœ… Running no benchmarks"
          elif [[ "$EVENT_NAME" == "pull_request" ]]; then
            # For PR events, check base branch and labels
            LABELS="${{ join(github.event.pull_request.labels.*.name, ' ') }}"
            BASE="${{ github.event.pull_request.base.ref }}"

            echo "ğŸ¯ Base branch: $BASE"
            echo "ğŸ·ï¸  PR labels: $LABELS"

            if [[ "$BASE" != "main" ]]; then
              echo "âŒ Base branch is not 'main' - skipping benchmarks"
              echo "run_ubuntu=false" >> $GITHUB_OUTPUT
              echo "run_moonshot=false" >> $GITHUB_OUTPUT
              echo "benchmarks_summary=none" >> $GITHUB_OUTPUT
              exit 0
            fi

            echo "âœ… Base branch check passed (main)"

            # Check for specific benchmark labels
            if echo "$LABELS" | grep -q "run bench core all"; then
              echo "âœ… Found 'run bench core all' label"
              RUN_UBUNTU="true"
              RUN_MOONSHOT="true"
              RUN_MOTHRA="true"
              BENCHMARKS_LIST="ubuntu-latest, moonshot, mothra"
            else
              if echo "$LABELS" | grep -q "run bench core ubuntu"; then
                echo "âœ… Found 'run bench core ubuntu' label"
                RUN_UBUNTU="true"
                BENCHMARKS_LIST="ubuntu-latest"
              fi
              if echo "$LABELS" | grep -q "run bench core moonshot"; then
                echo "âœ… Found 'run bench core moonshot' label"
                RUN_MOONSHOT="true"
                if [ -n "$BENCHMARKS_LIST" ]; then
                  BENCHMARKS_LIST="$BENCHMARKS_LIST, moonshot"
                else
                  BENCHMARKS_LIST="moonshot"
                fi
              fi
              if echo "$LABELS" | grep -q "run bench core mothra"; then
                echo "âœ… Found 'run bench core mothra' label"
                RUN_MOTHRA="true"
                if [ -n "$BENCHMARKS_LIST" ]; then
                  BENCHMARKS_LIST="$BENCHMARKS_LIST, mothra"
                else
                  BENCHMARKS_LIST="mothra"
                fi
              fi
            fi
            
            if [ "$RUN_UBUNTU" == "false" ] && [ "$RUN_MOONSHOT" == "false" ] && [ "$RUN_MOTHRA" == "false" ]; then
              echo "âŒ No benchmark labels found"
              echo "â„¹ï¸  Expected labels: 'run bench core ubuntu', 'run bench core moonshot', 'run bench core mothra', or 'run bench core all'"
              BENCHMARKS_LIST="none"
            fi
          else
            echo "âŒ Unexpected event type: $EVENT_NAME"
          fi
          
          # Set outputs
          echo "run_ubuntu=$RUN_UBUNTU" >> $GITHUB_OUTPUT
          echo "run_moonshot=$RUN_MOONSHOT" >> $GITHUB_OUTPUT
          echo "run_mothra=$RUN_MOTHRA" >> $GITHUB_OUTPUT
          echo "benchmarks_summary=$BENCHMARKS_LIST" >> $GITHUB_OUTPUT

      - name: ğŸ“Š Guard decision summary
        run: |
          echo "ğŸ›¡ï¸ Guard Job Summary:"
          echo "ğŸ“Š Benchmarks to run:"
          
          RUN_UBUNTU="${{ steps.check.outputs.run_ubuntu }}"
          RUN_MOONSHOT="${{ steps.check.outputs.run_moonshot }}"
          RUN_MOTHRA="${{ steps.check.outputs.run_mothra }}"
          SUMMARY="${{ steps.check.outputs.benchmarks_summary }}"
          
          if [ "$RUN_UBUNTU" == "true" ]; then
            echo "  âœ… benchmark-core-ubuntu-latest"
          fi
          if [ "$RUN_MOONSHOT" == "true" ]; then
            echo "  âœ… benchmark-core-moonshot"
          fi
          if [ "$RUN_MOTHRA" == "true" ]; then
            echo "  âœ… benchmark-core-mothra"
          fi
          if [ "$RUN_UBUNTU" != "true" ] && [ "$RUN_MOONSHOT" != "true" ] && [ "$RUN_MOTHRA" != "true" ]; then
            echo "  â­ï¸  None (conditions not met)"
            echo ""
            echo "ğŸ’¡ To run benchmarks on PRs, ensure:"
            echo "   â€¢ PR targets 'main' branch"
            echo "   â€¢ PR has one of: 'run bench core ubuntu', 'run bench core moonshot', 'run bench core mothra', or 'run bench core all'"
          else
            echo ""
            echo "âœ… Proceeding with: $SUMMARY"
          fi

  benchmark-ubuntu:
    needs: guard
    if: needs.guard.outputs.run_ubuntu == 'true'
    uses: ./.github/workflows/benchmark-core-ubuntu-latest.yml

  benchmark-moonshot:
    needs: guard
    if: needs.guard.outputs.run_moonshot == 'true'
    uses: ./.github/workflows/benchmark-core-moonshot.yml

  benchmark-mothra:
    needs: guard
    if: needs.guard.outputs.run_mothra == 'true'
    uses: ./.github/workflows/benchmark-core-mothra.yml

  docs:
    needs: [guard, benchmark-ubuntu, benchmark-moonshot, benchmark-mothra]
    if: |
      always() &&
      (needs.guard.result == 'success') &&
      (needs.benchmark-ubuntu.result != 'cancelled') &&
      (needs.benchmark-moonshot.result != 'cancelled') &&
      (needs.benchmark-mothra.result != 'cancelled') &&
      (needs.benchmark-ubuntu.result != 'failure') &&
      (needs.benchmark-moonshot.result != 'failure') &&
      (needs.benchmark-mothra.result != 'failure')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout with latest changes
        uses: actions/checkout@v5
        with:
          ref: ${{ github.head_ref || github.ref_name }}
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Pull latest changes including benchmark results
        run: |
          echo "ğŸ”„ Pulling latest changes from branch..."
          git pull origin ${{ github.head_ref || github.ref_name }}
          echo "âœ… Latest changes pulled"

      - uses: julia-actions/setup-julia@latest
      - uses: julia-actions/julia-buildpkg@latest

      - name: Install dependencies
        run: julia --project=docs/ -e 'using Pkg; Pkg.develop(PackageSpec(path=pwd())); Pkg.instantiate()'

      - name: Build and deploy
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DOCUMENTER_KEY: ${{ secrets.DOCUMENTER_KEY }}
          GKSwstype: 100
        run: |
          julia --project=docs/ -e 'ENV["GKSwstype"]="nul"; include("docs/make.jl")'

  notify-failure:
    needs: [guard, benchmark-ubuntu, benchmark-moonshot, benchmark-mothra, docs]
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Comment on PR with failure notification
        uses: actions/github-script@v8
        with:
          script: |
            console.log('ğŸš¨ Workflow failure detected - posting notification...');
            
            const prNumber = context.payload.pull_request.number;
            const failedJobs = [];
            
            console.log('ğŸ“Š Analyzing job results...');
            if (needs['benchmark-ubuntu'] && needs['benchmark-ubuntu'].result === 'failure') {
              console.log('âŒ Benchmark Ubuntu job failed');
              failedJobs.push('Benchmark Ubuntu-Latest');
            }
            if (needs['benchmark-moonshot'] && needs['benchmark-moonshot'].result === 'failure') {
              console.log('âŒ Benchmark Moonshot job failed');
              failedJobs.push('Benchmark Moonshot');
            }
            if (needs['benchmark-mothra'] && needs['benchmark-mothra'].result === 'failure') {
              console.log('âŒ Benchmark Mothra job failed');
              failedJobs.push('Benchmark Mothra');
            }
            if (needs.docs.result === 'failure') {
              console.log('âŒ Documentation job failed');
              failedJobs.push('Documentation');
            }
            
            console.log(`ğŸ“ Failed jobs: ${failedJobs.join(', ')}`);

            const comment = `
            ## âŒ Workflow Failed
            
            The benchmark and documentation workflow encountered failures:
            
            ### Failed Jobs
            ${failedJobs.map(job => `- âŒ ${job}`).join('\n')}
            
            ### ğŸ” Troubleshooting
            - Check the [workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId}) for detailed logs
            - Verify that all required dependencies are available
            - Ensure the benchmark code is functioning correctly
            
            ### ğŸ”„ Next Steps
            - Fix any issues identified in the logs
            - Push new commits to retry, or
            - Remove and re-add the benchmark label to restart
            
            ---
            *ğŸ¤– This notification was automatically generated*
            `;

            console.log('ğŸ’¬ Posting failure comment to PR...');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: comment
            });
            
            console.log('âœ… Failure notification posted successfully');

  notify-success:
    needs: [guard, benchmark-ubuntu, benchmark-moonshot, benchmark-mothra, docs]
    if: |
      always() &&
      (needs.guard.result == 'success') &&
      (needs.docs.result == 'success') &&
      (needs.benchmark-ubuntu.result != 'cancelled') &&
      (needs.benchmark-moonshot.result != 'cancelled') &&
      (needs.benchmark-mothra.result != 'cancelled') &&
      (needs.benchmark-ubuntu.result != 'failure') &&
      (needs.benchmark-moonshot.result != 'failure') &&
      (needs.benchmark-mothra.result != 'failure')
    runs-on: ubuntu-latest
    steps:
      - name: Comment on PR with success notification
        uses: actions/github-script@v8
        env:
          BENCHMARKS_SUMMARY: ${{ needs.guard.outputs.benchmarks_summary }}
        with:
          script: |
            console.log('ğŸ‰ Workflow success detected - posting notification...');

            const prNumber = context.payload.pull_request.number;
            const previewUrl = `https://control-toolbox.org/CTBenchmarks.jl/previews/PR${prNumber}/index.html`;
            const benchmarksSummary = process.env.BENCHMARKS_SUMMARY;

            console.log(`ğŸ” Checking documentation preview at: ${previewUrl}`);

            // Wait up to 30s for the preview page to exist
            async function checkPreview(url, attempts=6, delayMs=5000) {
              for (let i = 0; i < attempts; i++) {
                try {
                  const response = await fetch(url, { method: 'HEAD' });
                  if (response.ok) return true;
                } catch {}
                console.log(`â³ Preview not ready yet (attempt ${i+1}/${attempts})`);
                await new Promise(r => setTimeout(r, delayMs));
              }
              return false;
            }

            const previewReady = await checkPreview(previewUrl);

            let previewSection = '';
            if (previewReady) {
              console.log('âœ… Documentation preview is available');
              previewSection = `
            ### ğŸ“– Documentation Preview
            - ğŸŒ **[ğŸ“š View Documentation Preview](${previewUrl})** â† Click to see your changes!
                        `;
                      } else {
                        console.log('âš ï¸ Documentation preview still not available');
                        previewSection = `
            ### ğŸ“– Documentation Preview
            - â³ Documentation preview will be available shortly at: [Preview Link](${previewUrl})
                        `;
                      }

                      let comment = `
            ## âœ… Benchmark and Documentation Complete

            The automated workflow has completed successfully! ğŸ‰

            ### âœ… Completed Tasks
            - ğŸ“Š **Benchmarks**: ${benchmarksSummary} executed and results saved to your branch
            - ğŸ“š **Documentation**: Documentation updated successfully
            - ğŸ”„ **Integration**: All changes integrated properly
            ${previewSection}
            ### ğŸ“‹ Results
            - ğŸ¯ Benchmark results have been committed to your feature branch
            - ğŸ“š Documentation has been regenerated with the latest benchmark data

            ### ğŸ”— Links
            - ğŸ“Š [View workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId})
            - ğŸŒ¿ [View your feature branch](${context.payload.repository.html_url}/tree/${context.payload.pull_request.head.ref})

            ---
            *ğŸ¤– This notification was automatically generated*
            `;

            console.log('ğŸ’¬ Posting success comment to PR...');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: comment
            });

            console.log('âœ… Success notification posted successfully');

  workflow-summary:
    needs: [guard, benchmark-ubuntu, benchmark-moonshot, benchmark-mothra, docs]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“Š Final workflow summary
        run: |
          echo "ğŸ“‹ ==================================="
          echo "ğŸ“Š WORKFLOW EXECUTION SUMMARY"
          echo "ğŸ“‹ ==================================="
          echo ""
          echo "ğŸ›¡ï¸  Guard Job: âœ… PASSED"
          echo "   â””â”€ Benchmarks planned: ${{ needs.guard.outputs.benchmarks_summary }}"
          echo ""
          
          if [ "${{ needs.benchmark-ubuntu.result }}" == "success" ]; then
            echo "ğŸ“Š Benchmark Ubuntu-Latest: âœ… SUCCESS"
          elif [ "${{ needs.benchmark-ubuntu.result }}" == "failure" ]; then
            echo "ğŸ“Š Benchmark Ubuntu-Latest: âŒ FAILED"
          elif [ "${{ needs.benchmark-ubuntu.result }}" == "skipped" ]; then
            echo "ğŸ“Š Benchmark Ubuntu-Latest: â­ï¸  SKIPPED"
          fi
          
          if [ "${{ needs.benchmark-moonshot.result }}" == "success" ]; then
            echo "ğŸ“Š Benchmark Moonshot: âœ… SUCCESS"
          elif [ "${{ needs.benchmark-moonshot.result }}" == "failure" ]; then
            echo "ğŸ“Š Benchmark Moonshot: âŒ FAILED"
          elif [ "${{ needs.benchmark-moonshot.result }}" == "skipped" ]; then
            echo "ğŸ“Š Benchmark Moonshot: â­ï¸  SKIPPED"
          fi
          
          if [ "${{ needs.benchmark-mothra.result }}" == "success" ]; then
            echo "ğŸ“Š Benchmark Mothra: âœ… SUCCESS"
          elif [ "${{ needs.benchmark-mothra.result }}" == "failure" ]; then
            echo "ğŸ“Š Benchmark Mothra: âŒ FAILED"
          elif [ "${{ needs.benchmark-mothra.result }}" == "skipped" ]; then
            echo "ğŸ“Š Benchmark Mothra: â­ï¸  SKIPPED"
          fi
          
          if [ "${{ needs.docs.result }}" == "success" ]; then
            echo "ğŸ“š Documentation: âœ… SUCCESS"
            echo "   â””â”€ Docs updated successfully"
          elif [ "${{ needs.docs.result }}" == "failure" ]; then
            echo "ğŸ“š Documentation: âŒ FAILED"
            echo "   â””â”€ Check logs for details"
          else
            echo "ğŸ“š Documentation: â­ï¸  SKIPPED"
          fi
          
          echo ""
          echo "ğŸ”— Workflow URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo ""
          
          overall_status="âœ… SUCCESS"
          if [ "${{ needs.benchmark-ubuntu.result }}" == "failure" ] || [ "${{ needs.benchmark-moonshot.result }}" == "failure" ] || [ "${{ needs.benchmark-mothra.result }}" == "failure" ] || [ "${{ needs.docs.result }}" == "failure" ]; then
            overall_status="âŒ FAILED"
          fi
          
          echo "ğŸ¯ Overall Status: $overall_status"
          echo "ğŸ“‹ ==================================="