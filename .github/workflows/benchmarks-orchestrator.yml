name: Orchestrate Minimal Benchmark and Docs

on:
  push:
    branches:
      - main
  pull_request:
    types: [labeled, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write

jobs:
  guard:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
    steps:
      - name: Check if benchmark should run
        id: check
        run: |
          LABELS="${{ join(github.event.pull_request.labels.*.name, ' ') }}"
          BASE="${{ github.event.pull_request.base.ref }}"

          echo "Base branch: $BASE"
          echo "Labels: $LABELS"

          if [[ "$BASE" != "main" ]]; then
            echo "❌ Not targeting main → skip"
            echo "should_run=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          if echo "$LABELS" | grep -q "run benchmark minimal" || echo "$LABELS" | grep -q "run benchmarks all"; then
            echo "✅ Conditions met: benchmark label present"
            echo "should_run=true" >> $GITHUB_OUTPUT
          else
            echo "❌ No matching benchmark label → skip"
            echo "should_run=false" >> $GITHUB_OUTPUT
          fi

  benchmarks:
    needs: guard
    if: needs.guard.outputs.should_run == 'true'
    uses: ./.github/workflows/benchmark-minimal.yml
    permissions:
      contents: write
      pull-requests: write

  docs-artifacts:
    needs: benchmarks
    if: success() && needs.guard.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Download benchmark artifact
        uses: actions/download-artifact@v4
        with:
          name: benchmark-minimal
          path: benchmarks
        continue-on-error: true

      - name: Upload again for docs job
        if: success() # only re-upload if something was downloaded
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-minimal
          path: benchmarks

  docs:
    needs: docs-artifacts
    if: success() && needs.guard.outputs.should_run == 'true'
    uses: control-toolbox/CTActions/.github/workflows/documentation.yml@main
    permissions:
      contents: write
      pull-requests: write
    
  notify-failure:
    needs: [guard, benchmarks, docs]
    if: failure() && needs.guard.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Comment on PR with failure notification
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = context.payload.pull_request.number;
            const failedJobs = [];
            if (needs.benchmarks.result === 'failure') failedJobs.push('Benchmarks');
            if (needs.docs.result === 'failure') failedJobs.push('Documentation');

            const comment = `
            ## ❌ Workflow Failed

            The following jobs failed:
            ${failedJobs.map(job => `- ${job}`).join('\n')}

            See the [workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId}) for details.

            To retry:
            1. Remove and re-add the \`run benchmark\` label, or
            2. Push new commits to this PR
            `;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: comment
            });

  notify-success:
    needs: [guard, benchmarks, docs]
    if: success() && needs.guard.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Comment on PR with success notification
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = context.payload.pull_request.number;
            let comment = `
            ## ✅ Benchmark and Documentation Complete

            - ✅ Benchmarks executed
            - ✅ Documentation updated

            See the [workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId}) for details.
            `;

            // Construct the preview URL
            const previewUrl = `https://control-toolbox.org/CTBenchmarks.jl/previews/PR${prNumber}`;

            // Check if the preview URL exists
            const execSync = require('child_process').execSync;
            try {
              execSync(`curl -f -s ${previewUrl}`, { stdio: 'ignore' });
              // If curl succeeds, append the preview link
              comment += `\n\n🔗 [Preview Documentation](${previewUrl})`;
            } catch {
              // URL does not exist, do nothing
            }

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: comment
            });
