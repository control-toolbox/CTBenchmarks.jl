name: Benchmark Reusable

on:
  workflow_call:
    inputs:
      script_path:
        description: "Julia script to run benchmark"
        required: true
        type: string
      julia_version:
        description: "Julia version to install"
        required: true
        type: string
      julia_arch:
        description: "Julia architecture (e.g., x64, aarch64)"
        required: true
        type: string
      runs_on:
        description: "GitHub runner labels (e.g., ubuntu-latest or JSON array for self-hosted)"
        required: true
        type: string
      julia_os:
        description: "Operating system identifier for Julia/benchmark metadata"
        required: true
        type: string
      runner:
        description: "Runner identifier forwarded to benchmark script"
        required: true
        type: string
      grid_sizes:
        description: "JSON array of grid sizes (e.g., [200, 400])"
        required: true
        type: string
      grid_size_max_cpu:
        description: "Maximum grid size for CPU models"
        required: true
        type: string

permissions:
  contents: write
  pull-requests: write

jobs:
  run-benchmark:
    runs-on: ${{ fromJSON(inputs.runs_on) }}
    timeout-minutes: 180
    env:
      SCRIPT_PATH: ${{ inputs.script_path }}
      OS: ${{ inputs.julia_os }}
      GRID_SIZES: ${{ inputs.grid_sizes }}
      GRID_SIZE_MAX_CPU: ${{ inputs.grid_size_max_cpu }}
      RUNNER: ${{ inputs.runner }}

    steps:
      # ---------------------------
      # Checkout Repository
      # ---------------------------
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: ğŸ“‹ Repository checkout status
        run: |
          echo "âœ… Repository checked out successfully"
          echo "ğŸ“ Current directory: $(pwd)"
          echo "ğŸ“Š Total files: $(find . -type f | wc -l)"

      - name: ğŸ“„ Prepare benchmark output filename
        run: |
          OUTPUT_FILE="benchmark_output_path_$(date +%s)_$RANDOM.txt"
          echo "BENCHMARK_OUTPUT_FILE=$OUTPUT_FILE" >> $GITHUB_ENV
          echo "ğŸ“„ Benchmark output file will be stored in: $OUTPUT_FILE"

      # ---------------------------
      # Setup Julia Environment
      # ---------------------------
      - uses: julia-actions/setup-julia@v2
        with:
          version: ${{ inputs.julia_version }}
          arch: ${{ inputs.julia_arch }}

      - name: ğŸ”‹ Julia setup status
        run: |
          echo "âœ… Julia $(julia --version | cut -d' ' -f3) installed successfully"
          echo "ğŸ“ Julia location: $(which julia)"

      # Cache strategy: julia-actions/cache for standard runners, actions/cache for self-hosted
      - name: Cache Julia packages (standard runners)
        if: inputs.runner != 'moonshot'
        uses: julia-actions/cache@v2

      - name: Cache Julia artifacts (self-hosted runners)
        if: inputs.runner == 'moonshot'
        uses: actions/cache@v4
        env:
          cache-name: cache-artifacts
        with:
          path: ~/.julia/artifacts
          key: ${{ runner.os }}-benchmark-${{ env.cache-name }}-${{ hashFiles('**/Project.toml') }}
          restore-keys: |
            ${{ runner.os }}-benchmark-${{ env.cache-name }}-
            ${{ runner.os }}-benchmark-
            ${{ runner.os }}-

      - name: ğŸ’¾ Julia cache status
        run: |
          if [ "${{ inputs.runner }}" = "moonshot" ]; then
            echo "âœ… Julia artifacts cache configured (self-hosted strategy)"
          else
            echo "âœ… Julia package cache configured (standard strategy)"
          fi

      - uses: julia-actions/julia-buildpkg@v1
        with:
          ignore-no-cache: true

      - name: ğŸ”¨ Package build status
        run: |
          echo "âœ… Julia package built successfully"
          echo "ğŸ“¦ CTBenchmarks package ready for use"

      # ---------------------------
      # Run Benchmark Script
      # ---------------------------
      - name: Run benchmark script
        id: benchmark
        timeout-minutes: 30
        env:
          SCRIPT_PATH: ${{ env.SCRIPT_PATH }}
          OS: ${{ env.OS }}
        run: |
          echo "ğŸš€ Starting benchmark execution..."
          echo "â±ï¸  Benchmark timeout: 30 minutes"
          
          julia --color=yes -e '
            using Pkg
            Pkg.add("JSON")
            using JSON
            include(ENV["SCRIPT_PATH"])
            grid_sizes = Int.(JSON.parse(ENV["GRID_SIZES"]))
            grid_size_max_cpu = parse(Int, strip(ENV["GRID_SIZE_MAX_CPU"]))
            out = main(; runner=ENV["RUNNER"], grid_sizes=grid_sizes, grid_size_max_cpu=grid_size_max_cpu)
            println("ğŸ“„ Output file: ", out)
            open(ENV["BENCHMARK_OUTPUT_FILE"], "w") do f
              write(f, string(out))
            end
            println("ğŸ’¾ Output path saved to ", ENV["BENCHMARK_OUTPUT_FILE"])
          '
          
          echo "âœ… Benchmark execution completed"
          echo "benchmark_success=true" >> $GITHUB_OUTPUT

      - name: ğŸ“Š Benchmark results validation
        if: steps.benchmark.outputs.benchmark_success == 'true'
        run: |
          echo "ğŸ” Validating benchmark results..."
          
          if [ -f "$BENCHMARK_OUTPUT_FILE" ]; then
            OUTPUT_DIR=$(cat "$BENCHMARK_OUTPUT_FILE")
            echo "âœ… Benchmark output directory found: $OUTPUT_DIR"
            
            DATA_JSON_PATH="$OUTPUT_DIR/data.json"
            echo "ğŸ“„ Resolved JSON path: $DATA_JSON_PATH"
            
            if [ -f "$DATA_JSON_PATH" ]; then
              FILE_SIZE=$(stat -f%z "$DATA_JSON_PATH" 2>/dev/null || stat -c%s "$DATA_JSON_PATH" 2>/dev/null || echo "unknown")
              LINE_COUNT=$(wc -l < "$DATA_JSON_PATH")
              echo "âœ… Benchmark JSON file created successfully"
              echo "ğŸ“ File size: $FILE_SIZE bytes"
              echo "ğŸ“ File lines: $LINE_COUNT"
              echo "ğŸ“ File location: $DATA_JSON_PATH"

              echo "ğŸ” JSON content preview:"
              head -10 "$DATA_JSON_PATH"
              if [ $LINE_COUNT -gt 10 ]; then
                echo "   ... (truncated, $LINE_COUNT total lines)"
              fi

              for filename in Project.toml Manifest.toml; do
                FILE_PATH="$OUTPUT_DIR/$filename"
                if [ -f "$FILE_PATH" ]; then
                  echo "âœ… Found $filename alongside benchmark output"
                else
                  echo "âŒ ERROR: $filename not found in $OUTPUT_DIR"
                  exit 1
                fi
              done
            else
              echo "âŒ ERROR: Benchmark JSON file not found at $DATA_JSON_PATH"
              exit 1
            fi
          else
            echo "âŒ ERROR: $BENCHMARK_OUTPUT_FILE not found"
            exit 1
          fi

      - name: Commit benchmark results to current branch
        if: steps.benchmark.outputs.benchmark_success == 'true'
        run: |
          echo "ğŸ”§ Configuring git user..."
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          echo "âœ… Git user configured"

          echo "ğŸŒ³ Checking current git state..."
          echo "Current HEAD: $(git rev-parse --short HEAD)"
          echo "Current branch: $(git branch --show-current || echo 'DETACHED HEAD')"
          
          if [ -n "${{ github.head_ref }}" ]; then
            BRANCH_NAME="${{ github.head_ref }}"
            echo "ğŸ”„ This is a PR, switching to branch: $BRANCH_NAME"
            git checkout -B "$BRANCH_NAME"
            echo "âœ… Now on branch: $(git branch --show-current)"
          else
            BRANCH_NAME="${{ github.ref_name }}"
            echo "ğŸ”„ This is a push, switching to branch: $BRANCH_NAME"
            git checkout -B "$BRANCH_NAME"
            echo "âœ… Now on branch: $(git branch --show-current)"
          fi

          echo "ğŸ“Š Adding benchmark results to current branch..."
          
          if [ -f "$BENCHMARK_OUTPUT_FILE" ]; then
            OUTPUT_DIR=$(cat "$BENCHMARK_OUTPUT_FILE")
            echo "ğŸ“ Using benchmark output directory: $OUTPUT_DIR"
          else
            echo "âŒ ERROR: $BENCHMARK_OUTPUT_FILE not found"
            exit 1
          fi

          ARTIFACTS=(
            "$OUTPUT_DIR/data.json"
            "$OUTPUT_DIR/Project.toml"
            "$OUTPUT_DIR/Manifest.toml"
          )

          git add "${ARTIFACTS[@]}"

          STAGED_ALL=true
          for artifact in "${ARTIFACTS[@]}"; do
            if git diff --cached --name-only | grep -q "$artifact"; then
              echo "âœ… $artifact staged for commit"
            else
              echo "âš ï¸  $artifact not staged (possibly no changes)"
              STAGED_ALL=false
            fi
          done

          if [ "$STAGED_ALL" = true ]; then
            echo "ğŸ“‹ Files to be committed:"
            git diff --cached --name-status
          fi

          if ! git diff --cached --quiet; then
            echo "ğŸ“ Committing benchmark results to current branch..."
            git commit -m "ğŸ“Š Add benchmark results" -m "Generated by reusable benchmark workflow" -m "Results saved to ${OUTPUT_DIR}/data.json" -m "Includes environment TOMLs"
            echo "âœ… Benchmark results committed successfully"
            
            echo "ğŸ”„ Synchronizing with remote before push..."
            git fetch origin "$BRANCH_NAME" || echo "âš ï¸  Remote branch does not exist yet, will create it"
            
            if git rev-parse "origin/$BRANCH_NAME" >/dev/null 2>&1; then
              echo "ğŸ”€ Remote branch exists, rebasing local commits..."
              git rebase "origin/$BRANCH_NAME" || {
                echo "âŒ ERROR: Rebase failed, attempting to abort and retry with merge strategy"
                git rebase --abort
                git merge "origin/$BRANCH_NAME" -m "Merge remote changes before pushing benchmark results"
              }
              echo "âœ… Local branch synchronized with remote"
            else
              echo "â„¹ï¸  Remote branch does not exist, no synchronization needed"
            fi
            
            echo "ğŸš€ Pushing changes to branch: $BRANCH_NAME"
            git push origin "$BRANCH_NAME"
            echo "âœ… Benchmark results pushed to $BRANCH_NAME"
          else
            echo "â„¹ï¸  No changes detected in benchmark results"
            echo "ğŸ“Š Current results are identical to previous run"
          fi

      - name: ğŸ“ƒ Benchmark workflow summary
        if: steps.benchmark.outputs.benchmark_success == 'true'
        run: |
          if [ -f "$BENCHMARK_OUTPUT_FILE" ]; then
            OUTPUT_DIR=$(cat "$BENCHMARK_OUTPUT_FILE")
            echo "ğŸ“ Using benchmark output directory: $OUTPUT_DIR"
          else
            echo "âŒ ERROR: $BENCHMARK_OUTPUT_FILE not found"
            exit 1
          fi

          echo "ğŸ“Š Benchmark workflow summary:"
          echo "âœ… Benchmark execution: SUCCESS"
          echo "ğŸ“ Results saved to: $OUTPUT_DIR/data.json"
          echo "ğŸŒ³ Results committed to: ${{ github.head_ref || github.ref_name }} branch"
          echo "ğŸ“˜ Ready for documentation generation"
          echo "ğŸ‰ Reusable benchmark workflow completed successfully!"
